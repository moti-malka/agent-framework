{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "321ecba2",
   "metadata": {},
   "source": [
    "# ðŸ“§ Support Email Copilot â€” Microsoft Agent Framework\n",
    "\n",
    "**A complete learning journey:** Build an AI-powered support email system from scratch, progressively adding capabilities.\n",
    "\n",
    "---\n",
    "\n",
    "## ðŸ“š Table of Contents\n",
    "\n",
    "| # | Section | What You'll Learn |\n",
    "|---|---------|------------------|\n",
    "| **0** | [Shared Setup](#0-shared-setup) | Environment, models, sample data |\n",
    "| **1** | [Basic Agent](#1-basic-agent) | Create and run your first agent |\n",
    "| **2** | [Streaming](#2-streaming-responses) | Real-time token streaming |\n",
    "| **3** | [Multi-Turn Conversations](#3-multi-turn-conversations) | Thread-based memory |\n",
    "| **4** | [Function Tools](#4-function-tools) | Add custom capabilities |\n",
    "| **5** | [Human-in-the-Loop](#5-human-in-the-loop-approval) | Approval workflows |\n",
    "| **6** | [Middleware](#6-middleware) | Logging & observability |\n",
    "| **7** | [Memory](#7-agent-memory) | Persistent user context |\n",
    "| **8** | [Sequential Workflows](#8-sequential-workflows) | Classify â†’ Draft â†’ Review |\n",
    "| **9** | [Branching Logic](#9-branching-logic) | Spam vs. NotSpam vs. Uncertain |\n",
    "| **10** | [Fan-Out/Fan-In](#10-fan-out--fan-in) | Parallel processing |\n",
    "| **11** | [Multi-Agent Group Chat](#11-multi-agent-group-chat) | Team collaboration |\n",
    "| **12** | [Capstone Demo](#12-capstone-demo) | End-to-end system |\n",
    "\n",
    "---\n",
    "\n",
    "## ðŸŽ¯ What We Will Build By The End\n",
    "\n",
    "By completing this notebook, you'll have built a **Support Email Copilot** that:\n",
    "\n",
    "- âœ… **Classifies** incoming emails (Spam / Not Spam / Uncertain)\n",
    "- âœ… **Looks up** customer SLA and ticket status via function tools\n",
    "- âœ… **Drafts** professional responses with customizable tone\n",
    "- âœ… **Requires approval** before sending sensitive replies\n",
    "- âœ… **Remembers** user preferences (language, tone, name)\n",
    "- âœ… **Processes in parallel** for long emails (response + summary)\n",
    "- âœ… **Uses multiple reviewers** for quality control (security, tone, accuracy)\n",
    "- âœ… **Logs** every operation for observability\n",
    "\n",
    "---\n",
    "\n",
    "## Prerequisites\n",
    "\n",
    "Before running this notebook:\n",
    "\n",
    "1. âœ… **Azure subscription** with access to Azure OpenAI\n",
    "2. âœ… **Azure OpenAI resource** with a deployed model (e.g., `gpt-4o-mini`)\n",
    "3. âœ… **Azure CLI** installed and authenticated (`az login`)\n",
    "4. âœ… **`.env` file** with your configuration"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d841bbb",
   "metadata": {},
   "source": [
    "# 0. Shared Setup\n",
    "\n",
    "> **Why this matters:** A consistent foundation ensures all examples work together and reduces code duplication.\n",
    "\n",
    "## Install Python Packages\n",
    "\n",
    "```bash\n",
    "pip3.10 install agent-framework --pre python-dotenv nest_asyncio\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48335624",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Skip this cell - packages already installed in the .venv\n",
    "%pip install agent-framework --pre python-dotenv nest_asyncio"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a0e423b",
   "metadata": {},
   "source": [
    "## Load Environment & Create Chat Client\n",
    "\n",
    "The `.env` file contains your Azure OpenAI configuration. We create **one** `chat_client` instance to reuse throughout the notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d946629",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nest_asyncio\n",
    "nest_asyncio.apply()\n",
    "\n",
    "import asyncio\n",
    "from dotenv import load_dotenv\n",
    "from azure.identity import AzureCliCredential\n",
    "from agent_framework.azure import AzureOpenAIChatClient\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv()\n",
    "\n",
    "# Create ONE chat client - reused throughout the notebook\n",
    "chat_client = AzureOpenAIChatClient(credential=AzureCliCredential())\n",
    "\n",
    "print(\"âœ… Environment loaded and chat_client created\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10492593",
   "metadata": {},
   "source": [
    "## Shared Pydantic Models\n",
    "\n",
    "These models are used consistently across all sections for structured input/output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e398ef4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Literal, Annotated\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "# === Input Model ===\n",
    "class EmailInput(BaseModel):\n",
    "    \"\"\"Incoming support email.\"\"\"\n",
    "    sender: str = Field(description=\"Email sender address\")\n",
    "    subject: str = Field(description=\"Email subject line\")\n",
    "    body: str = Field(description=\"Email body content\")\n",
    "    customer_id: str | None = Field(default=None, description=\"Customer ID if known\")\n",
    "    ticket_id: str | None = Field(default=None, description=\"Related ticket ID if any\")\n",
    "\n",
    "# === Classification Model ===\n",
    "class ClassificationResult(BaseModel):\n",
    "    \"\"\"Result of email classification.\"\"\"\n",
    "    category: Literal[\"spam\", \"not_spam\", \"uncertain\"] = Field(description=\"Email category\")\n",
    "    confidence: float = Field(ge=0.0, le=1.0, description=\"Confidence score 0-1\")\n",
    "    reason: str = Field(description=\"Brief explanation of classification\")\n",
    "\n",
    "# === Draft Response Model ===\n",
    "class DraftResponse(BaseModel):\n",
    "    \"\"\"Draft reply to customer email.\"\"\"\n",
    "    subject: str = Field(description=\"Reply subject line\")\n",
    "    body: str = Field(description=\"Reply body\")\n",
    "    tone: Literal[\"formal\", \"friendly\", \"apologetic\"] = Field(description=\"Tone used\")\n",
    "    needs_review: bool = Field(default=False, description=\"Flag if needs human review\")\n",
    "\n",
    "# === Final Response Model ===\n",
    "class FinalResponse(BaseModel):\n",
    "    \"\"\"Final approved response.\"\"\"\n",
    "    classification: ClassificationResult\n",
    "    draft: DraftResponse | None = Field(default=None, description=\"Draft if not spam\")\n",
    "    review_notes: str | None = Field(default=None, description=\"Reviewer comments\")\n",
    "    approved: bool = Field(default=False, description=\"Whether approved to send\")\n",
    "\n",
    "print(\"âœ… Shared models defined: EmailInput, ClassificationResult, DraftResponse, FinalResponse\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13ca66c9",
   "metadata": {},
   "source": [
    "## Sample Emails\n",
    "\n",
    "Two example emails we'll use throughout the notebook â€” one legitimate support request, one spam."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7d68e08",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === LEGITIMATE EMAIL ===\n",
    "LEGIT_EMAIL = EmailInput(\n",
    "    sender=\"sarah.chen@acmecorp.com\",\n",
    "    subject=\"Order #12345 - Delivery Issue\",\n",
    "    body=\"\"\"Hi Support Team,\n",
    "\n",
    "I placed order #12345 last week and the tracking shows it was delivered, \n",
    "but I never received the package. I've checked with my neighbors and the building \n",
    "concierge, but no one has seen it.\n",
    "\n",
    "This is urgent as the items were needed for a client presentation on Friday.\n",
    "Can you please help me locate the package or arrange a replacement?\n",
    "\n",
    "Thank you,\n",
    "Sarah Chen\n",
    "Account: ACME-7891\n",
    "\"\"\",\n",
    "    customer_id=\"CUST-7891\",\n",
    "    ticket_id=\"TKT-2024-001\"\n",
    ")\n",
    "\n",
    "# === SPAM EMAIL ===\n",
    "SPAM_EMAIL = EmailInput(\n",
    "    sender=\"winner@prize-notifications.biz\",\n",
    "    subject=\"ðŸŽ‰ CONGRATULATIONS! You've WON $1,000,000!!!\",\n",
    "    body=\"\"\"URGENT NOTIFICATION!!!\n",
    "\n",
    "You have been selected as the WINNER of our international lottery!\n",
    "To claim your $1,000,000 prize, simply send your bank details and \n",
    "a processing fee of $500 to unlock your winnings.\n",
    "\n",
    "ACT NOW - This offer expires in 24 HOURS!!!\n",
    "\n",
    "Click here to claim: http://totally-legit-prize.com/claim\n",
    "\"\"\",\n",
    "    customer_id=None,\n",
    "    ticket_id=None\n",
    ")\n",
    "\n",
    "# === AMBIGUOUS EMAIL ===\n",
    "AMBIGUOUS_EMAIL = EmailInput(\n",
    "    sender=\"j.smith@unknown-domain.net\",\n",
    "    subject=\"Partnership Opportunity\",\n",
    "    body=\"\"\"Hello,\n",
    "\n",
    "I found your company online and I'm interested in discussing a potential \n",
    "business partnership. We have a new product line that might complement your services.\n",
    "\n",
    "Can we schedule a call this week?\n",
    "\n",
    "Best,\n",
    "J. Smith\n",
    "\"\"\",\n",
    "    customer_id=None,\n",
    "    ticket_id=None\n",
    ")\n",
    "\n",
    "print(\"âœ… Sample emails defined: LEGIT_EMAIL, SPAM_EMAIL, AMBIGUOUS_EMAIL\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26154c1d",
   "metadata": {},
   "source": [
    "# 1. Basic Agent\n",
    "\n",
    "> **Why this matters:** The agent is the core building block â€” understanding how to create and run one is essential for everything that follows.\n",
    "\n",
    "Create a support agent using `chat_client.as_agent()` with instructions for handling customer emails."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f96ea02",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the core Support Agent - we'll enhance this throughout the notebook\n",
    "support_agent = chat_client.as_agent(\n",
    "    name=\"SupportAgent\",\n",
    "    instructions=\"\"\"You are a helpful customer support agent for an e-commerce company.\n",
    "Your job is to:\n",
    "1. Understand customer issues from their emails\n",
    "2. Draft professional, empathetic responses\n",
    "3. Provide clear next steps when possible\n",
    "\n",
    "Always be polite, acknowledge the customer's frustration, and offer concrete solutions.\"\"\"\n",
    ")\n",
    "\n",
    "print(\"âœ… support_agent created\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd8f5e7f",
   "metadata": {},
   "source": [
    "## Run the Agent\n",
    "\n",
    "Call `agent.run()` with the email content. The result's `.text` property contains the response."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0324c3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the support agent on our legitimate email\n",
    "async def run_basic_agent():\n",
    "    prompt = f\"\"\"Please draft a response to this customer email:\n",
    "\n",
    "From: {LEGIT_EMAIL.sender}\n",
    "Subject: {LEGIT_EMAIL.subject}\n",
    "\n",
    "{LEGIT_EMAIL.body}\n",
    "\"\"\"\n",
    "    result = await support_agent.run(prompt)\n",
    "    print(\"ðŸ“§ Draft Response:\\n\")\n",
    "    print(result.text)\n",
    "\n",
    "asyncio.run(run_basic_agent())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6f9e31c",
   "metadata": {},
   "source": [
    "# 2. Streaming Responses\n",
    "\n",
    "> **Why this matters:** Streaming provides better UX by showing partial responses as they generate, crucial for customer-facing applications."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b03aef0",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Stream the response token by token using the SAME support_agent\n",
    "async def stream_support_response():\n",
    "    prompt = f\"\"\"Please draft a response to this customer email:\n",
    "\n",
    "From: {LEGIT_EMAIL.sender}\n",
    "Subject: {LEGIT_EMAIL.subject}\n",
    "\n",
    "{LEGIT_EMAIL.body}\n",
    "\"\"\"\n",
    "    print(\"ðŸ“§ Streaming Draft Response:\\n\")\n",
    "    async for update in support_agent.run_stream(prompt):\n",
    "        if update.text:\n",
    "            print(update.text, end=\"\", flush=True)\n",
    "    print()  # New line after streaming\n",
    "\n",
    "asyncio.run(stream_support_response())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54494e5c",
   "metadata": {},
   "source": [
    "# 3. Multi-Turn Conversations\n",
    "\n",
    "> **Why this matters:** Support interactions often require back-and-forth clarification. Threads maintain context across multiple exchanges."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42f4aa94",
   "metadata": {},
   "source": [
    "## Create a Thread\n",
    "\n",
    "Agents are **stateless** â€” use `get_new_thread()` to maintain conversation history:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92bc87f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a thread for multi-turn conversation\n",
    "thread = support_agent.get_new_thread()\n",
    "\n",
    "# Turn 1: Summarize the customer issue\n",
    "print(\"Turn 1: Summarize the issue\")\n",
    "print(\"-\" * 50)\n",
    "result1 = await support_agent.run(\n",
    "    f\"Summarize the key issues in this email in 2-3 bullet points:\\n\\n{LEGIT_EMAIL.body}\", \n",
    "    thread=thread\n",
    ")\n",
    "print(result1.text)\n",
    "print()\n",
    "\n",
    "# Turn 2: Draft a response (agent remembers the summary from Turn 1)\n",
    "print(\"Turn 2: Draft response with professional tone\")\n",
    "print(\"-\" * 50)\n",
    "result2 = await support_agent.run(\n",
    "    \"Now draft a professional response addressing each of those issues. Use a formal but empathetic tone.\",\n",
    "    thread=thread\n",
    ")\n",
    "print(result2.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b01d5c10",
   "metadata": {},
   "source": [
    "# 4. Function Tools\n",
    "\n",
    "> **Why this matters:** Real support agents need to look up customer data, check order status, and access internal systems. Tools make this possible."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb6d70fa",
   "metadata": {},
   "source": [
    "## Define Support Tools\n",
    "\n",
    "Create tools the agent can call to look up customer information:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "963debc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from agent_framework import tool\n",
    "# Simulated database of customer SLAs\n",
    "CUSTOMER_SLAS = {\n",
    "    \"CUST-7891\": {\"tier\": \"Premium\", \"response_time\": \"4 hours\", \"replacement_policy\": \"Free expedited replacement\"},\n",
    "    \"CUST-1234\": {\"tier\": \"Standard\", \"response_time\": \"24 hours\", \"replacement_policy\": \"Standard replacement\"},\n",
    "}\n",
    "\n",
    "# Simulated ticket database\n",
    "TICKET_STATUSES = {\n",
    "    \"TKT-2024-001\": {\"status\": \"Open\", \"priority\": \"High\", \"assigned_to\": \"Support Team\", \"last_update\": \"2024-01-15\"},\n",
    "    \"TKT-2024-002\": {\"status\": \"Resolved\", \"priority\": \"Low\", \"assigned_to\": \"Bot\", \"last_update\": \"2024-01-10\"},\n",
    "}\n",
    "\n",
    "@tool(name=\"lookup_customer_sla\", description=\"Look up a customer's SLA tier and policies\")\n",
    "def lookup_customer_sla(\n",
    "    customer_id: Annotated[str, Field(description=\"The customer ID to look up (e.g., CUST-7891)\")]\n",
    ") -> str:\n",
    "    \"\"\"Look up customer SLA information.\"\"\"\n",
    "    if customer_id in CUSTOMER_SLAS:\n",
    "        sla = CUSTOMER_SLAS[customer_id]\n",
    "        return f\"Customer {customer_id}: {sla['tier']} tier, {sla['response_time']} response time, {sla['replacement_policy']}\"\n",
    "    return f\"Customer {customer_id} not found in system.\"\n",
    "\n",
    "@tool(name=\"get_incident_status\", description=\"Get the current status of a support ticket\")\n",
    "def get_incident_status(\n",
    "    ticket_id: Annotated[str, Field(description=\"The ticket ID to check (e.g., TKT-2024-001)\")]\n",
    ") -> str:\n",
    "    \"\"\"Get ticket status information.\"\"\"\n",
    "    if ticket_id in TICKET_STATUSES:\n",
    "        ticket = TICKET_STATUSES[ticket_id]\n",
    "        return f\"Ticket {ticket_id}: Status={ticket['status']}, Priority={ticket['priority']}, Assigned to={ticket['assigned_to']}, Last update={ticket['last_update']}\"\n",
    "    return f\"Ticket {ticket_id} not found in system.\"\n",
    "\n",
    "print(\"âœ… Support tools defined: lookup_customer_sla, get_incident_status\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b7ee9eb",
   "metadata": {},
   "source": [
    "# Create Agent with Tools\n",
    "\n",
    "Pass tools to the agent so it can look up information when needed:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "363e4277",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create support agent with tools\n",
    "support_agent_with_tools = chat_client.as_agent(\n",
    "    name=\"SupportAgentWithTools\",\n",
    "    instructions=\"\"\"You are a customer support agent with access to internal systems.\n",
    "When handling emails:\n",
    "1. Look up the customer's SLA tier to understand their service level\n",
    "2. Check ticket status if a ticket ID is mentioned\n",
    "3. Use this information to provide appropriate responses and set expectations\n",
    "\n",
    "Always be empathetic and use the customer's SLA tier to guide your response (e.g., Premium customers get expedited service).\"\"\",\n",
    "    tools=[lookup_customer_sla, get_incident_status]\n",
    ")\n",
    "\n",
    "print(\"âœ… support_agent_with_tools created\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f461f75e",
   "metadata": {},
   "source": [
    "## Test Tool Usage\n",
    "\n",
    "The agent will automatically decide when to call tools based on the email content:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63cff641",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test with the legitimate email that has customer_id and ticket_id\n",
    "prompt = f\"\"\"Handle this customer support email. Look up their SLA and ticket status first:\n",
    "\n",
    "From: {LEGIT_EMAIL.sender}\n",
    "Subject: {LEGIT_EMAIL.subject}\n",
    "Customer ID: {LEGIT_EMAIL.customer_id}\n",
    "Ticket ID: {LEGIT_EMAIL.ticket_id}\n",
    "\n",
    "{LEGIT_EMAIL.body}\n",
    "\"\"\"\n",
    "\n",
    "result = await support_agent_with_tools.run(prompt)\n",
    "print(\"ðŸ“§ Response (with tool lookups):\\n\")\n",
    "print(result.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e530d0d1",
   "metadata": {},
   "source": [
    "# 5. Human-in-the-Loop Approval\n",
    "\n",
    "> **Why this matters:** Some actions (like sending emails, issuing refunds) need human approval before execution to prevent errors."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "479786af",
   "metadata": {},
   "source": [
    "## Define Approval-Required Tool\n",
    "\n",
    "Use `approval_mode=\"always_require\"` for sensitive actions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9cbdcca",
   "metadata": {},
   "outputs": [],
   "source": [
    "from agent_framework import ChatMessage, Content, Role\n",
    "\n",
    "# Tool that requires human approval before sending\n",
    "@tool(approval_mode=\"always_require\")\n",
    "def send_email_reply(\n",
    "    to: Annotated[str, Field(description=\"Recipient email address\")],\n",
    "    subject: Annotated[str, Field(description=\"Email subject\")],\n",
    "    body: Annotated[str, Field(description=\"Email body content\")]\n",
    ") -> str:\n",
    "    \"\"\"Send an email reply to the customer. Requires human approval.\"\"\"\n",
    "    # In production, this would actually send the email\n",
    "    return f\"âœ… Email sent to {to} with subject '{subject}'\"\n",
    "\n",
    "# Create agent with the approval-required tool\n",
    "approval_agent = chat_client.as_agent(\n",
    "    name=\"ApprovalSupportAgent\",\n",
    "    instructions=\"\"\"You are a customer support agent. After drafting a response, \n",
    "use the send_email_reply tool to send it. This will require human approval.\"\"\",\n",
    "    tools=[lookup_customer_sla, get_incident_status, send_email_reply]\n",
    ")\n",
    "\n",
    "print(\"âœ… approval_agent created with send_email_reply tool\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1de90248",
   "metadata": {},
   "source": [
    "## Request and Check for Approval\n",
    "\n",
    "When the agent tries to call an approval-required tool, it returns `user_input_requests` instead of executing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e6063ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ask the agent to handle and send a response\n",
    "prompt = f\"\"\"Handle this email and send a response:\n",
    "\n",
    "From: {LEGIT_EMAIL.sender}\n",
    "Subject: {LEGIT_EMAIL.subject}\n",
    "Customer ID: {LEGIT_EMAIL.customer_id}\n",
    "\n",
    "{LEGIT_EMAIL.body}\n",
    "\"\"\"\n",
    "\n",
    "result = await approval_agent.run(prompt)\n",
    "\n",
    "# Check if approval is needed\n",
    "if result.user_input_requests:\n",
    "    print(\"ðŸ”’ APPROVAL REQUIRED!\")\n",
    "    for user_input_needed in result.user_input_requests:\n",
    "        print(f\"  Function: {user_input_needed.function_call.name}\")\n",
    "        print(f\"  Arguments: {user_input_needed.function_call.arguments}\")\n",
    "else:\n",
    "    print(result.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8e80ab2",
   "metadata": {},
   "source": [
    "## Provide Approval and Continue\n",
    "\n",
    "Use `to_function_approval_response(True/False)` to approve or reject:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efa70478",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n--- Handling Approval ---\\n\")\n",
    "# Provide approval and continue the conversation\n",
    "if result.user_input_requests:\n",
    "    user_input_needed = result.user_input_requests[0]\n",
    "    \n",
    "    # Simulate human approval (in production, this would be interactive)\n",
    "    user_approval = True\n",
    "    print(f\"âœ… Human approved: {user_approval}\\n\")\n",
    "    \n",
    "    # Create approval response message\n",
    "    approval_message = ChatMessage(\n",
    "        role=Role.USER,\n",
    "        contents=[user_input_needed.to_function_approval_response(user_approval)]\n",
    "    )\n",
    "    \n",
    "    # Continue with approval\n",
    "    final_result = await approval_agent.run([\n",
    "        prompt,\n",
    "        ChatMessage(role=Role.ASSISTANT, contents=[user_input_needed]),\n",
    "        approval_message\n",
    "    ])\n",
    "    print(f\"ðŸ“Š Final Result:\\n{final_result.text}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bbefd9d",
   "metadata": {},
   "source": [
    "# 6. Middleware\n",
    "\n",
    "> **Why this matters:** Production systems need logging, monitoring, and observability. Middleware intercepts agent execution without modifying core logic."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8829240",
   "metadata": {},
   "source": [
    "## Create Logging Middleware\n",
    "\n",
    "Middleware receives context and a `next` function to continue execution:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eae080f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Callable, Awaitable\n",
    "from agent_framework import AgentRunContext, FunctionInvocationContext\n",
    "import time\n",
    "\n",
    "async def logging_agent_middleware(\n",
    "    context: AgentRunContext,\n",
    "    next: Callable[[AgentRunContext], Awaitable[None]],\n",
    ") -> None:\n",
    "    \"\"\"Log agent execution with timing.\"\"\"\n",
    "    print(f\"ðŸš€ Agent starting... ({len(context.messages)} message(s))\")\n",
    "    start_time = time.time()\n",
    "    \n",
    "    await next(context)  # Continue to agent execution\n",
    "    \n",
    "    elapsed = time.time() - start_time\n",
    "    print(f\"âœ… Agent finished in {elapsed:.2f}s\")\n",
    "\n",
    "async def logging_function_middleware(\n",
    "    context: FunctionInvocationContext,\n",
    "    next: Callable[[FunctionInvocationContext], Awaitable[None]],\n",
    ") -> None:\n",
    "    \"\"\"Log function tool calls.\"\"\"\n",
    "    print(f\"  ðŸ“ž Calling: {context.function.name}({context.arguments})\")\n",
    "    \n",
    "    await next(context)\n",
    "    \n",
    "    print(f\"  ðŸ“¤ Result: {context.result[:100]}...\" if len(str(context.result)) > 100 else f\"  ðŸ“¤ Result: {context.result}\")\n",
    "\n",
    "print(\"âœ… Middleware defined: logging_agent_middleware, logging_function_middleware\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e47e9a62",
   "metadata": {},
   "source": [
    "## Apply Middleware to Agent\n",
    "\n",
    "Pass middleware when creating the agent:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f92c1554",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create agent with middleware for logging\n",
    "middleware_agent = chat_client.as_agent(\n",
    "    name=\"LoggingSupportAgent\",\n",
    "    instructions=\"You are a support agent. Look up customer information when handling requests.\",\n",
    "    tools=[lookup_customer_sla, get_incident_status],\n",
    "    middleware=[logging_agent_middleware, logging_function_middleware]\n",
    ")\n",
    "\n",
    "# Test - you'll see logs for agent and function calls\n",
    "prompt = f\"Check the SLA for customer {LEGIT_EMAIL.customer_id} and ticket status for {LEGIT_EMAIL.ticket_id}\"\n",
    "result = await middleware_agent.run(prompt)\n",
    "print(f\"\\nðŸ’¬ Response: {result.text}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4ffbde4",
   "metadata": {},
   "source": [
    "# 7. Agent Memory\n",
    "\n",
    "> **Why this matters:** Support agents should remember user preferences (language, tone, name) to provide personalized service across conversations."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d89ced48",
   "metadata": {},
   "source": [
    "## Define User Preferences Model\n",
    "\n",
    "Store preferences that affect response generation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3468ebe",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SupportPreferences(BaseModel):\n",
    "    \"\"\"User preferences for support interactions.\"\"\"\n",
    "    name: str | None = None\n",
    "    preferred_language: Literal[\"English\", \"Hebrew\", \"Spanish\"] = \"English\"\n",
    "    preferred_tone: Literal[\"formal\", \"friendly\", \"brief\"] = \"formal\"\n",
    "\n",
    "print(\"âœ… SupportPreferences model defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2fdd4af",
   "metadata": {},
   "source": [
    "## Implement ContextProvider\n",
    "\n",
    "The `ContextProvider` has two key methods:\n",
    "- `invoking`: Inject context before each agent call\n",
    "- `invoked`: Update state after each call"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "082eefb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections.abc import MutableSequence, Sequence\n",
    "from typing import Any\n",
    "import re\n",
    "\n",
    "from agent_framework import ContextProvider, Context, ChatAgent\n",
    "\n",
    "\n",
    "class SupportMemory(ContextProvider):\n",
    "    \"\"\"Memory that tracks user preferences for support interactions.\"\"\"\n",
    "    \n",
    "    def __init__(self, preferences: SupportPreferences | None = None):\n",
    "        self.preferences = preferences or SupportPreferences()\n",
    "    \n",
    "    def _extract_name(self, text: str) -> str | None:\n",
    "        \"\"\"Extract name from text patterns.\"\"\"\n",
    "        patterns = [\n",
    "            r\"(?:my name is|i'm|i am|call me)\\s+([A-Z][a-z]+)\",\n",
    "            r\"(?:name is|name's)\\s+([A-Z][a-z]+)\",\n",
    "        ]\n",
    "        for pattern in patterns:\n",
    "            match = re.search(pattern, text, re.IGNORECASE)\n",
    "            if match:\n",
    "                return match.group(1).capitalize()\n",
    "        return None\n",
    "    \n",
    "    def _extract_preferences(self, text: str) -> None:\n",
    "        \"\"\"Extract tone and language preferences from text.\"\"\"\n",
    "        text_lower = text.lower()\n",
    "        \n",
    "        # Detect tone preferences\n",
    "        if any(word in text_lower for word in [\"friendly\", \"casual\", \"informal\"]):\n",
    "            self.preferences.preferred_tone = \"friendly\"\n",
    "            print(f\"   ðŸ§  Memory updated: tone = friendly\")\n",
    "        elif any(word in text_lower for word in [\"brief\", \"short\", \"concise\"]):\n",
    "            self.preferences.preferred_tone = \"brief\"\n",
    "            print(f\"   ðŸ§  Memory updated: tone = brief\")\n",
    "        elif any(word in text_lower for word in [\"formal\", \"professional\"]):\n",
    "            self.preferences.preferred_tone = \"formal\"\n",
    "            print(f\"   ðŸ§  Memory updated: tone = formal\")\n",
    "        \n",
    "        # Detect language preferences\n",
    "        if \"hebrew\" in text_lower or \"×¢×‘×¨×™×ª\" in text:\n",
    "            self.preferences.preferred_language = \"Hebrew\"\n",
    "            print(f\"   ðŸ§  Memory updated: language = Hebrew\")\n",
    "        elif \"spanish\" in text_lower or \"espaÃ±ol\" in text_lower:\n",
    "            self.preferences.preferred_language = \"Spanish\"\n",
    "            print(f\"   ðŸ§  Memory updated: language = Spanish\")\n",
    "    \n",
    "    async def invoked(\n",
    "        self,\n",
    "        request_messages: ChatMessage | Sequence[ChatMessage],\n",
    "        response_messages: ChatMessage | Sequence[ChatMessage] | None = None,\n",
    "        invoke_exception: Exception | None = None,\n",
    "        **kwargs: Any,\n",
    "    ) -> None:\n",
    "        \"\"\"Extract preferences from user messages after each call.\"\"\"\n",
    "        messages_list = [request_messages] if isinstance(request_messages, ChatMessage) else list(request_messages)\n",
    "        \n",
    "        for msg in messages_list:\n",
    "            if msg.role.value == \"user\":\n",
    "                text = \"\"\n",
    "                if msg.contents:\n",
    "                    for content in msg.contents:\n",
    "                        if hasattr(content, 'text'):\n",
    "                            text += content.text + \" \"\n",
    "                \n",
    "                # Extract name if not known\n",
    "                if self.preferences.name is None:\n",
    "                    name = self._extract_name(text)\n",
    "                    if name:\n",
    "                        self.preferences.name = name\n",
    "                        print(f\"   ðŸ§  Memory updated: name = {name}\")\n",
    "                \n",
    "                # Extract other preferences\n",
    "                self._extract_preferences(text)\n",
    "    \n",
    "    async def invoking(self, messages: ChatMessage | MutableSequence[ChatMessage], **kwargs: Any) -> Context:\n",
    "        \"\"\"Provide preference context before each agent call.\"\"\"\n",
    "        instructions = []\n",
    "        \n",
    "        if self.preferences.name:\n",
    "            instructions.append(f\"The user's name is {self.preferences.name}. Address them by name.\")\n",
    "        \n",
    "        instructions.append(f\"Respond in {self.preferences.preferred_language}.\")\n",
    "        instructions.append(f\"Use a {self.preferences.preferred_tone} tone.\")\n",
    "        \n",
    "        return Context(instructions=\" \".join(instructions))\n",
    "    \n",
    "    def serialize(self) -> str:\n",
    "        \"\"\"Serialize for persistence.\"\"\"\n",
    "        return self.preferences.model_dump_json()\n",
    "\n",
    "print(\"âœ… SupportMemory ContextProvider defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70b8489c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Callable, Awaitable\n",
    "from agent_framework import AgentRunContext\n",
    "import time\n",
    "\n",
    "async def logging_agent_middleware(\n",
    "    context: AgentRunContext,\n",
    "    next: Callable[[AgentRunContext], Awaitable[None]],\n",
    ") -> None:\n",
    "    \"\"\"Simple middleware that logs agent execution with timing.\"\"\"\n",
    "    # context.messages contains the input messages\n",
    "    print(f\"ðŸš€ Agent starting... (messages: {len(context.messages)} message(s))\")\n",
    "    start_time = time.time()\n",
    "\n",
    "    # Continue to agent execution\n",
    "    await next(context)\n",
    "\n",
    "    elapsed = time.time() - start_time\n",
    "    print(f\"âœ… Agent finished! (took {elapsed:.2f}s)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e2d6fd8",
   "metadata": {},
   "source": [
    "## Test Memory in Action\n",
    "\n",
    "Watch how the agent adapts based on remembered preferences:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "417d9431",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create memory and agent\n",
    "support_memory = SupportMemory()\n",
    "\n",
    "memory_agent = ChatAgent(\n",
    "    name=\"MemorySupportAgent\",\n",
    "    instructions=\"You are a friendly support agent. Adapt your responses based on user preferences.\",\n",
    "    chat_client=chat_client,\n",
    "    context_providers=support_memory,\n",
    ")\n",
    "\n",
    "memory_thread = memory_agent.get_new_thread()\n",
    "\n",
    "# Turn 1: User introduces themselves\n",
    "print(\"Turn 1: User introduction\")\n",
    "print(\"-\" * 50)\n",
    "result1 = await memory_agent.run(\"Hi, my name is David\", thread=memory_thread)\n",
    "print(f\"Agent: {result1.text}\\n\")\n",
    "\n",
    "# Turn 2: User sets preference\n",
    "print(\"Turn 2: Setting preference\")\n",
    "print(\"-\" * 50)\n",
    "result2 = await memory_agent.run(\"Please keep responses brief and casual\", thread=memory_thread)\n",
    "print(f\"Agent: {result2.text}\\n\")\n",
    "\n",
    "# Turn 3: Ask a question - agent should use name and brief/casual tone\n",
    "print(\"Turn 3: Question with preferences applied\")\n",
    "print(\"-\" * 50)\n",
    "result3 = await memory_agent.run(\"What's your return policy?\", thread=memory_thread)\n",
    "print(f\"Agent: {result3.text}\\n\")\n",
    "\n",
    "# Show memory state\n",
    "print(\"ðŸ§  Memory State:\")\n",
    "print(f\"   Name: {support_memory.preferences.name}\")\n",
    "print(f\"   Language: {support_memory.preferences.preferred_language}\")\n",
    "print(f\"   Tone: {support_memory.preferences.preferred_tone}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9429fcad",
   "metadata": {},
   "source": [
    "# 8. Sequential Workflows\n",
    "\n",
    "> **Why this matters:** Real support pipelines need multiple steps: classify â†’ draft â†’ review. Workflows orchestrate this flow with clear separation of concerns."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6274db5",
   "metadata": {},
   "source": [
    "## Workflow Building Blocks\n",
    "\n",
    "| Concept | Description |\n",
    "|---------|-------------|\n",
    "| **Executor** | A unit of work (class with `@handler` OR function with `@executor`) |\n",
    "| **WorkflowBuilder** | Connects executors with `add_edge()` |\n",
    "| `ctx.send_message()` | Pass data to next executor |\n",
    "| `ctx.yield_output()` | Return final workflow result |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc80541f",
   "metadata": {},
   "source": [
    "## Define Workflow Executors\n",
    "\n",
    "Create executors for: Classify â†’ Draft â†’ Review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "276a9eab",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing_extensions import Never\n",
    "from agent_framework import (\n",
    "    WorkflowBuilder, WorkflowContext, WorkflowOutputEvent,\n",
    "    Executor, executor, handler, AgentExecutor, AgentExecutorRequest, AgentExecutorResponse\n",
    ")\n",
    "\n",
    "# === CLASSIFIER AGENT ===\n",
    "classifier_agent = AgentExecutor(\n",
    "    chat_client.as_agent(\n",
    "        name=\"Classifier\",\n",
    "        instructions=\"\"\"Classify incoming emails. Return JSON with:\n",
    "- category: \"spam\", \"not_spam\", or \"uncertain\"\n",
    "- confidence: float 0-1\n",
    "- reason: brief explanation\"\"\",\n",
    "        response_format=ClassificationResult,\n",
    "    ),\n",
    "    id=\"classifier\",\n",
    ")\n",
    "\n",
    "# === DRAFT WRITER AGENT ===\n",
    "writer_agent = AgentExecutor(\n",
    "    chat_client.as_agent(\n",
    "        name=\"DraftWriter\",\n",
    "        instructions=\"\"\"Draft professional support responses. Return JSON with:\n",
    "- subject: reply subject line\n",
    "- body: reply body\n",
    "- tone: \"formal\", \"friendly\", or \"apologetic\"\n",
    "- needs_review: true if sensitive or complex\"\"\",\n",
    "        response_format=DraftResponse,\n",
    "    ),\n",
    "    id=\"writer\",\n",
    ")\n",
    "\n",
    "# === REVIEWER AGENT ===\n",
    "reviewer_agent = AgentExecutor(\n",
    "    chat_client.as_agent(\n",
    "        name=\"Reviewer\",\n",
    "        instructions=\"\"\"Review draft responses for quality. Check:\n",
    "- Professionalism and tone\n",
    "- Accuracy of information\n",
    "- Completeness\n",
    "Return approval decision with notes.\"\"\",\n",
    "    ),\n",
    "    id=\"reviewer\",\n",
    ")\n",
    "\n",
    "print(\"âœ… Workflow agents defined: classifier, writer, reviewer\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e3f78d8",
   "metadata": {},
   "source": [
    "## Build and Run Sequential Workflow\n",
    "\n",
    "Connect executors: Classifier â†’ Writer â†’ Reviewer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94b511c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build sequential workflow\n",
    "sequential_support_workflow = (\n",
    "    WorkflowBuilder()\n",
    "    .set_start_executor(classifier_agent)\n",
    "    .add_edge(classifier_agent, writer_agent)\n",
    "    .add_edge(writer_agent, reviewer_agent)\n",
    "    .build()\n",
    ")\n",
    "\n",
    "# Run with legitimate email\n",
    "async def run_sequential_workflow():\n",
    "    email_prompt = f\"\"\"Process this support email:\n",
    "\n",
    "From: {LEGIT_EMAIL.sender}\n",
    "Subject: {LEGIT_EMAIL.subject}\n",
    "Customer ID: {LEGIT_EMAIL.customer_id}\n",
    "\n",
    "{LEGIT_EMAIL.body}\n",
    "\"\"\"\n",
    "    \n",
    "    print(\"ðŸ“§ Processing email through workflow: Classify â†’ Draft â†’ Review\\n\")\n",
    "    print(\"-\" * 60)\n",
    "    \n",
    "    request = AgentExecutorRequest(\n",
    "        messages=[ChatMessage(Role.USER, text=email_prompt)],\n",
    "        should_respond=True\n",
    "    )\n",
    "    \n",
    "    from agent_framework._workflows._events import ExecutorCompletedEvent\n",
    "    \n",
    "    async for event in sequential_support_workflow.run_stream(request):\n",
    "        if isinstance(event, ExecutorCompletedEvent) and event.data:\n",
    "            data = event.data[0] if isinstance(event.data, list) else event.data\n",
    "            if hasattr(data, 'agent_response'):\n",
    "                print(f\"\\nâœ… [{event.executor_id}]:\")\n",
    "                print(f\"   {data.agent_response.text[:300]}...\")\n",
    "        elif isinstance(event, WorkflowOutputEvent):\n",
    "            print(f\"\\nðŸŽ¯ FINAL OUTPUT:\")\n",
    "            if isinstance(event.data, list) and event.data:\n",
    "                final = event.data[0]\n",
    "                if hasattr(final, 'agent_response'):\n",
    "                    print(final.agent_response.text)\n",
    "\n",
    "await run_sequential_workflow()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f37a59d",
   "metadata": {},
   "source": [
    "# 9. Branching Logic\n",
    "\n",
    "> **Why this matters:** Different email types need different handling â€” spam should be blocked, uncertain emails need human review. Branching enables intelligent routing."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cec9cf6",
   "metadata": {},
   "source": [
    "## Three Routing Patterns\n",
    "\n",
    "| Pattern | Use Case | Targets |\n",
    "|---------|----------|---------|\n",
    "| **Conditional Edge** | Binary decision (if/else) | Exactly 1 |\n",
    "| **Switch-Case** | Multi-way routing (enum) | Exactly 1 |\n",
    "| **Multi-Selection** | Dynamic fan-out | 1 or more |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e60db70",
   "metadata": {},
   "source": [
    "## Define Branching Executors\n",
    "\n",
    "Handle Spam / NotSpam / Uncertain paths:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38082206",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "from uuid import uuid4\n",
    "from agent_framework import Case, Default\n",
    "\n",
    "# Internal payload for routing\n",
    "@dataclass\n",
    "class ClassifiedEmail:\n",
    "    email_id: str\n",
    "    category: str  # spam, not_spam, uncertain\n",
    "    confidence: float\n",
    "    reason: str\n",
    "    original_content: str\n",
    "\n",
    "# Shared state keys\n",
    "EMAIL_KEY = \"current_email\"\n",
    "\n",
    "# Transform classification result to routable payload\n",
    "@executor(id=\"extract_classification\")\n",
    "async def extract_classification(response: Any, ctx: WorkflowContext[ClassifiedEmail]) -> None:\n",
    "    \"\"\"Extract classification from agent response for routing.\"\"\"\n",
    "    if isinstance(response, list):\n",
    "        response = response[0]\n",
    "    \n",
    "    classification = ClassificationResult.model_validate_json(response.agent_response.text)\n",
    "    \n",
    "    # Get original email from shared state\n",
    "    original_content = await ctx.get_shared_state(EMAIL_KEY) or \"Unknown\"\n",
    "    \n",
    "    payload = ClassifiedEmail(\n",
    "        email_id=str(uuid4()),\n",
    "        category=classification.category,\n",
    "        confidence=classification.confidence,\n",
    "        reason=classification.reason,\n",
    "        original_content=original_content\n",
    "    )\n",
    "    await ctx.send_message(payload)\n",
    "\n",
    "# Route conditions\n",
    "def is_spam(message: Any) -> bool:\n",
    "    return isinstance(message, ClassifiedEmail) and message.category == \"spam\"\n",
    "\n",
    "def is_not_spam(message: Any) -> bool:\n",
    "    return isinstance(message, ClassifiedEmail) and message.category == \"not_spam\"\n",
    "\n",
    "def is_uncertain(message: Any) -> bool:\n",
    "    return isinstance(message, ClassifiedEmail) and message.category == \"uncertain\"\n",
    "\n",
    "# Terminal handlers\n",
    "@executor(id=\"handle_spam\")\n",
    "async def handle_spam_terminal(email: ClassifiedEmail, ctx: WorkflowContext[Never, str]) -> None:\n",
    "    \"\"\"Handle spam: block and log.\"\"\"\n",
    "    await ctx.yield_output(f\"ðŸš« SPAM BLOCKED: {email.reason} (confidence: {email.confidence:.0%})\")\n",
    "\n",
    "@executor(id=\"handle_not_spam\")\n",
    "async def handle_not_spam_continue(email: ClassifiedEmail, ctx: WorkflowContext[AgentExecutorRequest]) -> None:\n",
    "    \"\"\"Handle not_spam: forward to writer.\"\"\"\n",
    "    await ctx.send_message(AgentExecutorRequest(\n",
    "        messages=[ChatMessage(Role.USER, text=f\"Draft a response to: {email.original_content}\")],\n",
    "        should_respond=True\n",
    "    ))\n",
    "\n",
    "@executor(id=\"finalize_draft\")\n",
    "async def finalize_draft(response: Any, ctx: WorkflowContext[Never, str]) -> None:\n",
    "    \"\"\"Output the final draft.\"\"\"\n",
    "    if isinstance(response, list):\n",
    "        response = response[0]\n",
    "    draft = DraftResponse.model_validate_json(response.agent_response.text)\n",
    "    await ctx.yield_output(f\"âœ‰ï¸ DRAFT READY:\\nSubject: {draft.subject}\\n\\n{draft.body}\")\n",
    "\n",
    "@executor(id=\"handle_uncertain\")\n",
    "async def handle_uncertain_terminal(email: ClassifiedEmail, ctx: WorkflowContext[Never, str]) -> None:\n",
    "    \"\"\"Handle uncertain: flag for human review.\"\"\"\n",
    "    await ctx.yield_output(f\"âš ï¸ NEEDS HUMAN REVIEW: {email.reason} (confidence: {email.confidence:.0%})\\n\\nOriginal: {email.original_content[:200]}...\")\n",
    "\n",
    "print(\"âœ… Branching executors defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70f06000",
   "metadata": {},
   "source": [
    "## Build Branching Workflow\n",
    "\n",
    "Use switch-case to route: Spam â†’ Block, NotSpam â†’ Draft, Uncertain â†’ Review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "840d3b84",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store email and start classification\n",
    "@executor(id=\"start_classification\")\n",
    "async def start_classification(email_text: str, ctx: WorkflowContext[AgentExecutorRequest]) -> None:\n",
    "    \"\"\"Store email and send for classification.\"\"\"\n",
    "    await ctx.set_shared_state(EMAIL_KEY, email_text)\n",
    "    await ctx.send_message(AgentExecutorRequest(\n",
    "        messages=[ChatMessage(Role.USER, text=f\"Classify this email:\\n\\n{email_text}\")],\n",
    "        should_respond=True\n",
    "    ))\n",
    "\n",
    "# Build branching workflow\n",
    "branching_workflow = (\n",
    "    WorkflowBuilder()\n",
    "    .set_start_executor(start_classification)\n",
    "    .add_edge(start_classification, classifier_agent)\n",
    "    .add_edge(classifier_agent, extract_classification)\n",
    "    # Switch-case routing\n",
    "    .add_switch_case_edge_group(\n",
    "        extract_classification,\n",
    "        [\n",
    "            Case(condition=is_spam, target=handle_spam_terminal),\n",
    "            Case(condition=is_not_spam, target=handle_not_spam_continue),\n",
    "            Default(target=handle_uncertain_terminal),  # Catches uncertain + unexpected\n",
    "        ],\n",
    "    )\n",
    "    # Continue not_spam path to draft\n",
    "    .add_edge(handle_not_spam_continue, writer_agent)\n",
    "    .add_edge(writer_agent, finalize_draft)\n",
    "    .build()\n",
    ")\n",
    "\n",
    "print(\"âœ… Branching workflow built\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7e6f304",
   "metadata": {},
   "source": [
    "## Test All Branches\n",
    "\n",
    "Run all three email types to see different paths:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59110839",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test all three paths\n",
    "async def test_branching():\n",
    "    test_cases = [\n",
    "        (\"LEGITIMATE\", LEGIT_EMAIL),\n",
    "        (\"SPAM\", SPAM_EMAIL),\n",
    "        (\"AMBIGUOUS\", AMBIGUOUS_EMAIL),\n",
    "    ]\n",
    "    \n",
    "    for label, email in test_cases:\n",
    "        print(f\"\\nðŸ“§ Testing {label} email...\")\n",
    "        print(\"-\" * 50)\n",
    "        \n",
    "        email_text = f\"From: {email.sender}\\nSubject: {email.subject}\\n\\n{email.body}\"\n",
    "        \n",
    "        async for event in branching_workflow.run_stream(email_text):\n",
    "            if isinstance(event, WorkflowOutputEvent):\n",
    "                print(event.data)\n",
    "\n",
    "await test_branching()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09ecb767",
   "metadata": {},
   "source": [
    "# 10. Fan-Out / Fan-In\n",
    "\n",
    "> **Why this matters:** Long emails benefit from parallel processing â€” draft a response AND create a summary simultaneously, then combine results."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c863e4e6",
   "metadata": {},
   "source": [
    "## Define Parallel Processing Executors\n",
    "\n",
    "For long emails: respond AND summarize in parallel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d8e251d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summary model\n",
    "class EmailSummary(BaseModel):\n",
    "    \"\"\"Concise email summary.\"\"\"\n",
    "    key_points: list[str] = Field(description=\"Main points from the email\")\n",
    "    urgency: Literal[\"low\", \"medium\", \"high\"] = Field(description=\"Urgency level\")\n",
    "    action_required: str = Field(description=\"Primary action needed\")\n",
    "\n",
    "# Summarizer agent\n",
    "summarizer_agent = AgentExecutor(\n",
    "    chat_client.as_agent(\n",
    "        name=\"Summarizer\",\n",
    "        instructions=\"\"\"Summarize emails concisely. Return JSON with:\n",
    "- key_points: list of main points\n",
    "- urgency: low/medium/high\n",
    "- action_required: primary action needed\"\"\",\n",
    "        response_format=EmailSummary,\n",
    "    ),\n",
    "    id=\"summarizer\",\n",
    ")\n",
    "\n",
    "# Threshold for \"long\" emails\n",
    "LONG_EMAIL_THRESHOLD = 200  # characters\n",
    "\n",
    "@dataclass\n",
    "class EnrichedEmail:\n",
    "    \"\"\"Email with metadata for routing.\"\"\"\n",
    "    email_id: str\n",
    "    content: str\n",
    "    is_long: bool\n",
    "    category: str\n",
    "\n",
    "# Selection function for multi-selection routing\n",
    "def select_parallel_paths(email: EnrichedEmail, target_ids: list[str]) -> list[str]:\n",
    "    \"\"\"Select paths based on email length.\"\"\"\n",
    "    # target_ids order: [respond_path, summarize_path]\n",
    "    respond_id, summarize_id = target_ids\n",
    "    \n",
    "    if email.is_long:\n",
    "        return [respond_id, summarize_id]  # Both paths in parallel\n",
    "    else:\n",
    "        return [respond_id]  # Only respond for short emails\n",
    "\n",
    "# Executors for parallel paths\n",
    "@executor(id=\"prepare_parallel\")\n",
    "async def prepare_parallel(classified: ClassifiedEmail, ctx: WorkflowContext[EnrichedEmail]) -> None:\n",
    "    \"\"\"Prepare email for parallel processing.\"\"\"\n",
    "    enriched = EnrichedEmail(\n",
    "        email_id=classified.email_id,\n",
    "        content=classified.original_content,\n",
    "        is_long=len(classified.original_content) > LONG_EMAIL_THRESHOLD,\n",
    "        category=classified.category\n",
    "    )\n",
    "    await ctx.send_message(enriched)\n",
    "\n",
    "@executor(id=\"respond_path\")\n",
    "async def respond_path(email: EnrichedEmail, ctx: WorkflowContext[AgentExecutorRequest]) -> None:\n",
    "    \"\"\"Send to writer for response.\"\"\"\n",
    "    await ctx.send_message(AgentExecutorRequest(\n",
    "        messages=[ChatMessage(Role.USER, text=f\"Draft a response to:\\n{email.content}\")],\n",
    "        should_respond=True\n",
    "    ))\n",
    "\n",
    "@executor(id=\"summarize_path\")\n",
    "async def summarize_path(email: EnrichedEmail, ctx: WorkflowContext[AgentExecutorRequest]) -> None:\n",
    "    \"\"\"Send to summarizer.\"\"\"\n",
    "    await ctx.send_message(AgentExecutorRequest(\n",
    "        messages=[ChatMessage(Role.USER, text=f\"Summarize this email:\\n{email.content}\")],\n",
    "        should_respond=True\n",
    "    ))\n",
    "\n",
    "# Aggregator to combine parallel results\n",
    "class ParallelAggregator(Executor):\n",
    "    def __init__(self):\n",
    "        super().__init__(id=\"parallel_aggregator\")\n",
    "    \n",
    "    @handler\n",
    "    async def aggregate(self, results: list[Any], ctx: WorkflowContext[Never, str]) -> None:\n",
    "        \"\"\"Combine response and summary.\"\"\"\n",
    "        output_parts = []\n",
    "        \n",
    "        for result in results:\n",
    "            if isinstance(result, AgentExecutorResponse):\n",
    "                try:\n",
    "                    draft = DraftResponse.model_validate_json(result.agent_response.text)\n",
    "                    output_parts.append(f\"ðŸ“§ DRAFT RESPONSE:\\nSubject: {draft.subject}\\n{draft.body}\")\n",
    "                except:\n",
    "                    try:\n",
    "                        summary = EmailSummary.model_validate_json(result.agent_response.text)\n",
    "                        points = \"\\n\".join(f\"  â€¢ {p}\" for p in summary.key_points)\n",
    "                        output_parts.append(f\"ðŸ“‹ SUMMARY:\\n{points}\\nUrgency: {summary.urgency}\\nAction: {summary.action_required}\")\n",
    "                    except:\n",
    "                        output_parts.append(f\"Result: {result.agent_response.text[:200]}...\")\n",
    "        \n",
    "        await ctx.yield_output(\"\\n\\n\" + \"=\"*40 + \"\\n\\n\".join(output_parts))\n",
    "\n",
    "aggregator = ParallelAggregator()\n",
    "\n",
    "print(\"âœ… Parallel processing executors defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f19ef984",
   "metadata": {},
   "source": [
    "## Build Fan-Out/Fan-In Workflow\n",
    "\n",
    "Short emails â†’ respond only. Long emails â†’ respond + summarize in parallel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e887adc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from agent_framework import WorkflowBuilder\n",
    "from agent_framework._workflows._events import ExecutorCompletedEvent\n",
    "\n",
    "# Constants\n",
    "LONG_EMAIL_THRESHOLD = 200  # Characters\n",
    "\n",
    "# Start executor - entry point stores email and passes it forward\n",
    "@executor(id=\"fanout_start\")\n",
    "async def fanout_start(email_text: str, ctx: WorkflowContext[str]) -> None:\n",
    "    \"\"\"Entry point: store email length, forward email text.\"\"\"\n",
    "    # Store email length in shared state for selection\n",
    "    await ctx.set_shared_state(\"email_length\", len(email_text))\n",
    "    await ctx.send_message(email_text)\n",
    "\n",
    "# Selection function that uses shared state\n",
    "def fanout_select_paths(email_text: str, target_ids: list[str]) -> list[str]:\n",
    "    \"\"\"Select paths based on email length (stored in text).\"\"\"\n",
    "    # The email_text is still the raw string at this point\n",
    "    if len(email_text) > LONG_EMAIL_THRESHOLD:\n",
    "        return target_ids  # Both paths for long emails\n",
    "    return [target_ids[0]]  # Only response path for short emails\n",
    "\n",
    "# Response path preparer\n",
    "@executor(id=\"fanout_respond_prep\")\n",
    "async def fanout_respond_prep(email_text: str, ctx: WorkflowContext[AgentExecutorRequest]) -> None:\n",
    "    \"\"\"Prepare email for writer agent.\"\"\"\n",
    "    await ctx.send_message(AgentExecutorRequest(\n",
    "        messages=[ChatMessage(Role.USER, text=f\"Draft a response to:\\n{email_text}\")],\n",
    "        should_respond=True\n",
    "    ))\n",
    "\n",
    "# Summary path preparer\n",
    "@executor(id=\"fanout_summarize_prep\")\n",
    "async def fanout_summarize_prep(email_text: str, ctx: WorkflowContext[AgentExecutorRequest]) -> None:\n",
    "    \"\"\"Prepare email for summarizer agent.\"\"\"\n",
    "    await ctx.send_message(AgentExecutorRequest(\n",
    "        messages=[ChatMessage(Role.USER, text=f\"Summarize this email:\\n{email_text}\")],\n",
    "        should_respond=True\n",
    "    ))\n",
    "\n",
    "# Aggregator - combines results from parallel paths\n",
    "@executor(id=\"fanout_aggregator\")\n",
    "async def fanout_aggregator(results: list[Any], ctx: WorkflowContext[Never, str]) -> None:\n",
    "    \"\"\"Combine response and summary results.\"\"\"\n",
    "    output_parts = []\n",
    "    for result in results:\n",
    "        if isinstance(result, AgentExecutorResponse):\n",
    "            try:\n",
    "                draft = DraftResponse.model_validate_json(result.agent_response.text)\n",
    "                output_parts.append(f\"ðŸ“¬ RESPONSE:\\nSubject: {draft.subject}\\n{draft.body}\")\n",
    "            except:\n",
    "                try:\n",
    "                    summary = EmailSummary.model_validate_json(result.agent_response.text)\n",
    "                    points = \"\\n\".join(f\"  â€¢ {p}\" for p in summary.key_points)\n",
    "                    output_parts.append(f\"ðŸ“‹ SUMMARY:\\n{points}\\nUrgency: {summary.urgency}\\nAction: {summary.action_required}\")\n",
    "                except:\n",
    "                    output_parts.append(f\"Result: {result.agent_response.text[:200]}...\")\n",
    "    \n",
    "    await ctx.yield_output(\"\\n\\n\" + \"=\"*50 + \"\\n\\n\".join(output_parts))\n",
    "\n",
    "# Build the fan-out workflow\n",
    "# Pattern: start -> [fanout to preparers] -> [agents] -> aggregator\n",
    "fanout_workflow = (\n",
    "    WorkflowBuilder()\n",
    "    .set_start_executor(fanout_start)\n",
    "    # Fan-out from start directly to path preparers based on email length\n",
    "    .add_multi_selection_edge_group(\n",
    "        fanout_start,\n",
    "        targets=[fanout_respond_prep, fanout_summarize_prep],\n",
    "        selection_func=fanout_select_paths,\n",
    "    )\n",
    "    # Each preparer sends to its agent\n",
    "    .add_edge(fanout_respond_prep, writer_agent)\n",
    "    .add_edge(fanout_summarize_prep, summarizer_agent)\n",
    "    # Fan-in: collect all results\n",
    "    .add_fan_in_edges([writer_agent, summarizer_agent], fanout_aggregator)\n",
    "    .build()\n",
    ")\n",
    "\n",
    "print(\"âœ… Fan-out/fan-in workflow built\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b962d58",
   "metadata": {},
   "source": [
    "## Test Parallel Processing\n",
    "\n",
    "Compare short vs long email processing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7492286",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test with long legitimate email\n",
    "async def test_fanout():\n",
    "    email_text = f\"From: {LEGIT_EMAIL.sender}\\nSubject: {LEGIT_EMAIL.subject}\\n\\n{LEGIT_EMAIL.body}\"\n",
    "    \n",
    "    print(f\"ðŸ“§ Testing LONG email ({len(email_text)} chars > {LONG_EMAIL_THRESHOLD} threshold)\")\n",
    "    print(\"Expected: Response AND Summary in parallel\\n\")\n",
    "    print(\"-\" * 60)\n",
    "    \n",
    "    async for event in fanout_workflow.run_stream(email_text):\n",
    "        if isinstance(event, WorkflowOutputEvent):\n",
    "            print(event.data)\n",
    "\n",
    "await test_fanout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d85a7439",
   "metadata": {},
   "source": [
    "# 11. Multi-Agent Group Chat\n",
    "\n",
    "> **Why this matters:** Complex quality control needs multiple perspectives â€” security, tone, accuracy. Group chat enables collaborative review."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38398cec",
   "metadata": {},
   "source": [
    "## Group Chat Patterns\n",
    "\n",
    "| Pattern | Builder | How it Works |\n",
    "|---------|---------|--------------|\n",
    "| **Sequential** | `SequentialBuilder` | Agents take turns (round-robin) |\n",
    "| **Concurrent** | `ConcurrentBuilder` | All agents process in parallel |\n",
    "| **Magentic** | `MagenticBuilder` | Manager orchestrates who speaks |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1105e4d2",
   "metadata": {},
   "source": [
    "## Create Reviewer Team (Concurrent)\n",
    "\n",
    "Three reviewers analyze drafts in parallel:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74b41c3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from agent_framework import ConcurrentBuilder, SequentialBuilder, MagenticBuilder\n",
    "\n",
    "# Three specialized reviewers\n",
    "security_reviewer = ChatAgent(\n",
    "    name=\"SecurityReviewer\",\n",
    "    description=\"Checks for security and compliance issues\",\n",
    "    instructions=\"Review support responses for security issues: no sensitive data exposed, no phishing risks, compliance with policies. List top concerns. Be brief.\",\n",
    "    chat_client=chat_client,\n",
    ")\n",
    "\n",
    "tone_reviewer = ChatAgent(\n",
    "    name=\"ToneReviewer\",\n",
    "    description=\"Checks tone and empathy\",\n",
    "    instructions=\"Review support responses for appropriate tone: professional, empathetic, not defensive. List suggestions. Be brief.\",\n",
    "    chat_client=chat_client,\n",
    ")\n",
    "\n",
    "accuracy_reviewer = ChatAgent(\n",
    "    name=\"AccuracyReviewer\",\n",
    "    description=\"Checks factual accuracy\",\n",
    "    instructions=\"Review support responses for accuracy: no false promises, realistic timelines, correct information. List concerns. Be brief.\",\n",
    "    chat_client=chat_client,\n",
    ")\n",
    "\n",
    "# Build concurrent review team\n",
    "review_team = (\n",
    "    ConcurrentBuilder()\n",
    "    .participants([security_reviewer, tone_reviewer, accuracy_reviewer])\n",
    "    .build()\n",
    ")\n",
    "\n",
    "print(\"âœ… Concurrent review team created: Security || Tone || Accuracy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27452e67",
   "metadata": {},
   "source": [
    "## Test Concurrent Review\n",
    "\n",
    "All three reviewers analyze the draft simultaneously:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4ab3019",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample draft response to review\n",
    "draft_to_review = \"\"\"\n",
    "Subject: Re: Order #12345 - Delivery Issue\n",
    "\n",
    "Dear Sarah,\n",
    "\n",
    "I'm so sorry to hear about the missing package! This must be incredibly frustrating.\n",
    "\n",
    "I've located your order and can confirm it was marked as delivered on Monday. Here's what I'll do:\n",
    "\n",
    "1. I've opened an investigation with our shipping partner (Case #INV-789)\n",
    "2. As a Premium customer, I'm expediting a replacement shipment TODAY\n",
    "3. The replacement will arrive by Thursday, well before your Friday presentation\n",
    "\n",
    "Your account has also been credited $50 for the inconvenience.\n",
    "\n",
    "If you need anything else, reply directly to this email - I'm here to help!\n",
    "\n",
    "Best regards,\n",
    "Support Team\n",
    "\"\"\"\n",
    "\n",
    "async def test_concurrent_review():\n",
    "    print(\"ðŸ“ Draft to review:\")\n",
    "    print(draft_to_review)\n",
    "    print(\"-\" * 60)\n",
    "    print(\"\\nðŸ” PARALLEL REVIEWS (all running simultaneously):\\n\")\n",
    "    \n",
    "    async for event in review_team.run_stream(f\"Review this support response:\\n{draft_to_review}\"):\n",
    "        if isinstance(event, WorkflowOutputEvent):\n",
    "            messages = event.data\n",
    "            for msg in messages:\n",
    "                if msg.role.value == \"assistant\":\n",
    "                    print(f\"\\n{msg.text}\")\n",
    "                    print(\"-\" * 40)\n",
    "\n",
    "await test_concurrent_review()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d7588de",
   "metadata": {},
   "source": [
    "## Magentic Team (Manager-Orchestrated)\n",
    "\n",
    "For complex cases, a manager decides which specialists to involve:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4794a908",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Manager agent for orchestrated review\n",
    "review_manager = ChatAgent(\n",
    "    name=\"ReviewManager\",\n",
    "    description=\"Coordinates the review process\",\n",
    "    instructions=\"\"\"You manage a team reviewing support responses. \n",
    "Delegate to specialists based on the content:\n",
    "- SecurityReviewer for compliance/data concerns\n",
    "- ToneReviewer for customer experience\n",
    "- AccuracyReviewer for factual correctness\n",
    "\n",
    "Synthesize feedback into a final approval decision.\"\"\",\n",
    "    chat_client=chat_client,\n",
    ")\n",
    "\n",
    "# Magentic team with manager\n",
    "magentic_review_team = (\n",
    "    MagenticBuilder()\n",
    "    .participants([security_reviewer, tone_reviewer, accuracy_reviewer])\n",
    "    .with_manager(\n",
    "        agent=review_manager,\n",
    "        max_round_count=6,\n",
    "        max_stall_count=2,\n",
    "    )\n",
    "    .build()\n",
    ")\n",
    "\n",
    "print(\"âœ… Magentic review team created: Manager â†’ [Security, Tone, Accuracy]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5350b545",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test magentic review team\n",
    "from typing import cast\n",
    "\n",
    "async def test_magentic_review():\n",
    "    print(\"ðŸŽ¯ Manager-orchestrated review of draft response:\\n\")\n",
    "    print(\"-\" * 60)\n",
    "    \n",
    "    output = None\n",
    "    async for event in magentic_review_team.run_stream(f\"Review this support response and provide final approval decision:\\n{draft_to_review}\"):\n",
    "        if isinstance(event, WorkflowOutputEvent):\n",
    "            output_messages = cast(list[ChatMessage], event.data)\n",
    "            if output_messages:\n",
    "                output = output_messages[-1].text\n",
    "    \n",
    "    print(\"\\nðŸ“‹ FINAL REVIEW DECISION:\")\n",
    "    print(output)\n",
    "\n",
    "await test_magentic_review()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fff4e052",
   "metadata": {},
   "source": [
    "# 12. Capstone Demo\n",
    "\n",
    "> **Putting it all together:** Run the complete Support Email Copilot system end-to-end on both a legitimate and spam email."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19b0d883",
   "metadata": {},
   "source": [
    "## Complete Support Email Pipeline\n",
    "\n",
    "This demo shows the full flow:\n",
    "1. **Classify** the email (Spam/NotSpam/Uncertain)\n",
    "2. **Route** based on classification\n",
    "3. **Lookup** customer info (for legitimate emails)\n",
    "4. **Draft** a response\n",
    "5. **Review** with multi-agent team\n",
    "6. **Output** final result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f64fd4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def run_capstone_demo():\n",
    "    \"\"\"Complete end-to-end demo of the Support Email Copilot.\"\"\"\n",
    "    \n",
    "    print(\"=\" * 70)\n",
    "    print(\"ðŸš€ SUPPORT EMAIL COPILOT - CAPSTONE DEMO\")\n",
    "    print(\"=\" * 70)\n",
    "    \n",
    "    test_emails = [\n",
    "        (\"LEGITIMATE SUPPORT REQUEST\", LEGIT_EMAIL),\n",
    "        (\"SPAM\", SPAM_EMAIL),\n",
    "    ]\n",
    "    \n",
    "    for label, email in test_emails:\n",
    "        print(f\"\\n\\n{'='*70}\")\n",
    "        print(f\"ðŸ“§ PROCESSING: {label}\")\n",
    "        print(f\"{'='*70}\")\n",
    "        print(f\"From: {email.sender}\")\n",
    "        print(f\"Subject: {email.subject}\")\n",
    "        print(f\"Customer ID: {email.customer_id}\")\n",
    "        print(\"-\" * 50)\n",
    "        \n",
    "        email_text = f\"From: {email.sender}\\nSubject: {email.subject}\\n\\n{email.body}\"\n",
    "        \n",
    "        # Step 1: Classification\n",
    "        print(\"\\nðŸ“Š Step 1: CLASSIFICATION\")\n",
    "        classification_result = await classifier_agent.agent.run(\n",
    "            f\"Classify this email:\\n\\n{email_text}\"\n",
    "        )\n",
    "        classification = ClassificationResult.model_validate_json(classification_result.text)\n",
    "        print(f\"   Category: {classification.category}\")\n",
    "        print(f\"   Confidence: {classification.confidence:.0%}\")\n",
    "        print(f\"   Reason: {classification.reason}\")\n",
    "        \n",
    "        # Step 2: Route based on classification\n",
    "        if classification.category == \"spam\":\n",
    "            print(\"\\nðŸš« Step 2: ROUTED TO SPAM HANDLER\")\n",
    "            print(\"   Result: Email blocked and logged\")\n",
    "            continue\n",
    "        \n",
    "        if classification.category == \"uncertain\":\n",
    "            print(\"\\nâš ï¸ Step 2: ROUTED TO HUMAN REVIEW\")\n",
    "            print(\"   Result: Flagged for manual review\")\n",
    "            continue\n",
    "        \n",
    "        # Step 3: For legitimate emails - lookup customer info\n",
    "        print(\"\\nðŸ” Step 3: CUSTOMER LOOKUP\")\n",
    "        if email.customer_id:\n",
    "            sla_info = lookup_customer_sla(email.customer_id)\n",
    "            print(f\"   SLA: {sla_info}\")\n",
    "        if email.ticket_id:\n",
    "            ticket_info = get_incident_status(email.ticket_id)\n",
    "            print(f\"   Ticket: {ticket_info}\")\n",
    "        \n",
    "        # Step 4: Draft response\n",
    "        print(\"\\nâœï¸ Step 4: DRAFTING RESPONSE\")\n",
    "        draft_result = await writer_agent.agent.run(\n",
    "            f\"Draft a professional support response for this email. Customer is Premium tier.\\n\\n{email_text}\"\n",
    "        )\n",
    "        draft = DraftResponse.model_validate_json(draft_result.text)\n",
    "        print(f\"   Subject: {draft.subject}\")\n",
    "        print(f\"   Tone: {draft.tone}\")\n",
    "        print(f\"   Body preview: {draft.body[:200]}...\")\n",
    "        \n",
    "        # Step 5: Concurrent review\n",
    "        print(\"\\nðŸ” Step 5: MULTI-AGENT REVIEW (parallel)\")\n",
    "        review_results = []\n",
    "        async for event in review_team.run_stream(f\"Review this draft:\\n{draft.body}\"):\n",
    "            if isinstance(event, WorkflowOutputEvent):\n",
    "                messages = event.data\n",
    "                for msg in messages:\n",
    "                    if msg.role.value == \"assistant\":\n",
    "                        review_results.append(msg.text[:150])\n",
    "        \n",
    "        for i, review in enumerate(review_results[:3], 1):\n",
    "            print(f\"   Reviewer {i}: {review}...\")\n",
    "        \n",
    "        # Step 6: Final output\n",
    "        print(\"\\nâœ… Step 6: FINAL OUTPUT\")\n",
    "        print(f\"   Status: Ready for approval\")\n",
    "        print(f\"   Draft approved for sending to: {email.sender}\")\n",
    "    \n",
    "    print(\"\\n\\n\" + \"=\" * 70)\n",
    "    print(\"ðŸŽ‰ CAPSTONE DEMO COMPLETE\")\n",
    "    print(\"=\" * 70)\n",
    "    print(\"\\nYou've seen the complete Support Email Copilot system:\")\n",
    "    print(\"â€¢ Classification with routing (Spam/NotSpam/Uncertain)\")\n",
    "    print(\"â€¢ Customer lookup via function tools\")\n",
    "    print(\"â€¢ Response drafting with structured output\")\n",
    "    print(\"â€¢ Multi-agent concurrent review\")\n",
    "    print(\"â€¢ End-to-end processing pipeline\")\n",
    "\n",
    "await run_capstone_demo()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
