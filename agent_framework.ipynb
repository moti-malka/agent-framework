{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "321ecba2",
   "metadata": {},
   "source": [
    "# Microsoft Agent Framework - Learning Notebook\n",
    "\n",
    "**Purpose:** This notebook is designed to explore all the capabilities of the Microsoft Agent Framework for learning and experimentation.\n",
    "\n",
    "---\n",
    "\n",
    "## What is Microsoft Agent Framework?\n",
    "\n",
    "Microsoft Agent Framework is an **open-source development kit** for building AI agents and multi-agent workflows for .NET and Python. It brings together and extends ideas from **Semantic Kernel** and **AutoGen** projects, combining their strengths while adding new capabilities.\n",
    "\n",
    "### Key Capabilities\n",
    "\n",
    "| Category | Description |\n",
    "|----------|-------------|\n",
    "| **AI Agents** | Individual agents that use LLMs to process user inputs, call tools and MCP servers to perform actions, and generate responses |\n",
    "| **Workflows** | Graph-based workflows that connect multiple agents and functions to perform complex, multi-step tasks |\n",
    "\n",
    "### Building Blocks\n",
    "\n",
    "The framework provides foundational components:\n",
    "- **Model Clients** - Chat completions and responses (Azure OpenAI, OpenAI, Azure AI)\n",
    "- **Agent Session** - State management for conversations\n",
    "- **Context Providers** - Agent memory capabilities\n",
    "- **Middleware** - Intercepting agent actions\n",
    "- **MCP Clients** - Tool integration via Model Context Protocol\n",
    "\n",
    "### When to Use AI Agents\n",
    "\n",
    "AI agents excel at:\n",
    "- ðŸŽ§ **Customer Support** - Multi-modal queries with tool lookups\n",
    "- ðŸ“š **Education & Tutoring** - Personalized learning with knowledge bases\n",
    "- ðŸ’» **Code Generation** - Implementation, reviews, and debugging\n",
    "- ðŸ”¬ **Research Assistance** - Web search, document summarization\n",
    "\n",
    "### When NOT to Use AI Agents\n",
    "\n",
    "> *\"If you can write a function to handle the task, do that instead of using an AI agent.\"*\n",
    "\n",
    "Avoid agents for:\n",
    "- Highly structured tasks with predefined rules\n",
    "- Well-defined sequences of operations\n",
    "- Tasks requiring more than ~20 tools (use workflows instead)\n",
    "\n",
    "---\n",
    "\n",
    "## Prerequisites\n",
    "\n",
    "Before running this notebook:\n",
    "\n",
    "1. âœ… **Azure subscription** with access to Azure OpenAI\n",
    "2. âœ… **Azure OpenAI resource** with a deployed model (e.g., `gpt-4o-mini`)\n",
    "3. âœ… **Azure CLI** installed and authenticated (`az login`)\n",
    "4. âœ… **`.env` file** with your configuration (see README.md)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d841bbb",
   "metadata": {},
   "source": [
    "## Install Python Packages\n",
    "\n",
    "To use Microsoft Agent Framework with Azure OpenAI, install the following Python packages:\n",
    "\n",
    "```bash\n",
    "pip install agent-framework --pre python-dotenv nest_asyncio\n",
    "```\n",
    "\n",
    "> **Note:** `nest_asyncio` is required for Python 3.10 compatibility to allow nested event loops in Jupyter notebooks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48335624",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install agent-framework --pre python-dotenv nest_asyncio"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a0e423b",
   "metadata": {},
   "source": [
    "## Load Environment Variables\n",
    "\n",
    "The `.env` file contains your Azure OpenAI configuration. The `python-dotenv` library loads these variables into the environment so the SDK can access them automatically.\n",
    "\n",
    "Required variables:\n",
    "- `AZURE_OPENAI_CHAT_DEPLOYMENT_NAME` - Your deployed model name\n",
    "- `AZURE_OPENAI_ENDPOINT` - Your Azure OpenAI endpoint URL\n",
    "- `AZURE_OPENAI_API_KEY` - Your API key (optional if using Azure CLI auth)\n",
    "- `API_VERSION` - The API version to use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d946629",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nest_asyncio\n",
    "nest_asyncio.apply()\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load environment variables from .env file\n",
    "load_dotenv()\n",
    "\n",
    "print(\"Environment variables loaded successfully\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10492593",
   "metadata": {},
   "source": [
    "## Create the Agent\n",
    "\n",
    "First, create a chat client for communicating with Azure OpenAI using the environment variables configured earlier.\n",
    "\n",
    "Then, create the agent by providing instructions and a name for the agent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e398ef4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import asyncio\n",
    "from agent_framework.azure import AzureOpenAIChatClient\n",
    "from azure.identity import AzureCliCredential\n",
    "\n",
    "agent = AzureOpenAIChatClient(credential=AzureCliCredential()).as_agent(\n",
    "    instructions=\"You are good at telling jokes.\",\n",
    "    name=\"Joker\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13ca66c9",
   "metadata": {},
   "source": [
    "## Run the Agent\n",
    "\n",
    "To run the agent, call the `run` method on the agent instance, providing the user input. The agent will return a response object, and accessing the `.text` property provides the text result from the agent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7d68e08",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def run_agent():\n",
    "    result = await agent.run(\"Tell me a joke about a pirate.\")\n",
    "    print(result.text)\n",
    "\n",
    "asyncio.run(run_agent())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26154c1d",
   "metadata": {},
   "source": [
    "```markdown\n",
    "## Run the Agent with Streaming\n",
    "\n",
    "To run the agent with streaming, call the `run_stream` method on the agent instance, providing the user input. The agent will stream a list of update objects, and accessing the `.text` property on each update object provides the part of the text result contained in that update.\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f96ea02",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stream the response token by token\n",
    "async def stream_agent():\n",
    "    async for update in agent.run_stream(\"Tell me a joke about a pirate.\"):\n",
    "        if update.text:\n",
    "            print(update.text, end=\"\", flush=True)\n",
    "    print()  # New line after streaming is complete\n",
    "\n",
    "asyncio.run(stream_agent())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd8f5e7f",
   "metadata": {},
   "source": [
    "## Multimodal Input with ChatMessage\n",
    "\n",
    "You can pass `ChatMessage` objects with multiple content types, including text and images, to enable multimodal interactions with the agent. This is useful when you want the agent to analyze or respond to visual content along with textual instructions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0324c3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from agent_framework import ChatMessage, Content, Role\n",
    "\n",
    "message = ChatMessage(\n",
    "    role=Role.USER,\n",
    "    contents=[\n",
    "        Content.from_text(\"Tell me a joke about this image?\"),\n",
    "        Content.from_uri(\"https://media.gettyimages.com/id/1195994877/vector/democratic-donkey-and-republican-elephant-in-tv-debate.jpg?s=612x612&w=gi&k=20&c=1K-OwflyABXdG_xIbo_n7Ph3CRzI63vGx5G_sKmQz-Y=\", media_type=\"image/jpg\")\n",
    "    ]\n",
    ")\n",
    "\n",
    "result = await agent.run(message)\n",
    "print(result.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6f9e31c",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0e628d73",
   "metadata": {},
   "source": [
    "## Multi-Turn Conversations\n",
    "\n",
    "Agents are **stateless** and do not maintain any state internally between calls. To have a multi-turn conversation with an agent, you need to create an object to hold the conversation state and pass this object to the agent when running it.\n",
    "\n",
    "### Creating a Thread\n",
    "\n",
    "To create the conversation state object, call the `get_new_thread()` method on the agent instance:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54494e5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "thread = agent.get_new_thread()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42f4aa94",
   "metadata": {},
   "source": [
    "### Running with a Thread\n",
    "\n",
    "You can then pass this thread object to the `run` and `run_stream` methods on the agent instance, along with the user input. This maintains the conversation state between calls, allowing the agent to refer to previous messages:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92bc87f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# First turn\n",
    "result1 = await agent.run(\"Tell me a joke about a pirate.\", thread=thread)\n",
    "print(\"Turn 1:\")\n",
    "print(result1.text)\n",
    "print()\n",
    "\n",
    "# Second turn - agent remembers the previous joke\n",
    "result2 = await agent.run(\"Now add some emojis to the joke and tell it in the voice of a pirate's parrot.\", thread=thread)\n",
    "print(\"Turn 2:\")\n",
    "print(result2.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b01d5c10",
   "metadata": {},
   "source": [
    "### How Conversation History Works\n",
    "\n",
    "> âš ï¸ **Important:** The type of service used by the agent determines how conversation history is stored:\n",
    "> \n",
    "> - **Chat Completion service** (like this example): Conversation history is stored in the `AgentThread` object and sent to the service on each call.\n",
    "> - **Azure AI Agent service**: Conversation history is stored in the Azure AI Agent service and only a reference to the conversation is sent on each call.\n",
    "\n",
    "### Multiple Independent Conversations\n",
    "\n",
    "It's possible to have multiple, independent conversations with the same agent instance by creating multiple `AgentThread` objects. Since the agent doesn't maintain any state internally, these conversations will be fully independent:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb6d70fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create two separate conversation threads\n",
    "thread1 = agent.get_new_thread()\n",
    "thread2 = agent.get_new_thread()\n",
    "\n",
    "# Start conversation 1 - about pirates\n",
    "result1 = await agent.run(\"Tell me a joke about a pirate.\", thread=thread1)\n",
    "print(\"Thread 1 - Turn 1:\")\n",
    "print(result1.text)\n",
    "print()\n",
    "\n",
    "# Start conversation 2 - about robots (independent)\n",
    "result2 = await agent.run(\"Tell me a joke about a robot.\", thread=thread2)\n",
    "print(\"Thread 2 - Turn 1:\")\n",
    "print(result2.text)\n",
    "print()\n",
    "\n",
    "# Continue conversation 1 - agent remembers the pirate joke\n",
    "result3 = await agent.run(\"Now add some emojis to the joke and tell it in the voice of a pirate's parrot.\", thread=thread1)\n",
    "print(\"Thread 1 - Turn 2:\")\n",
    "print(result3.text)\n",
    "print()\n",
    "\n",
    "# Continue conversation 2 - agent remembers the robot joke\n",
    "result4 = await agent.run(\"Now add some emojis to the joke and tell it in the voice of a robot.\", thread=thread2)\n",
    "print(\"Thread 2 - Turn 2:\")\n",
    "print(result4.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "963debc8",
   "metadata": {},
   "source": [
    "## Using Function Tools with an Agent\n",
    "\n",
    "Function tools allow agents to call custom code when needed. You can turn any Python function into a function tool by passing it to the agent's `tools` parameter.\n",
    "\n",
    "> âš ï¸ **Important:** Not all agent types support function tools. Some might only support custom built-in tools. Agents created via chat clients (like this example) do support function tools.\n",
    "\n",
    "### Creating a Simple Function Tool\n",
    "\n",
    "Use Python's type annotations with `Annotated` and Pydantic's `Field` to provide descriptions that help the agent choose between different functions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b7ee9eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Annotated\n",
    "from pydantic import Field\n",
    "\n",
    "def get_weather(\n",
    "    location: Annotated[str, Field(description=\"The location to get the weather for.\")],\n",
    ") -> str:\n",
    "    \"\"\"Get the weather for a given location.\"\"\"\n",
    "    return f\"The weather in {location} is cloudy with a high of 15Â°C.\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "363e4277",
   "metadata": {},
   "source": [
    "### Using the @tool Decorator\n",
    "\n",
    "You can also use the `@tool` decorator to explicitly specify the function's name and description. If you don't specify them, the framework will automatically use the function's name and docstring as fallbacks:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f461f75e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from agent_framework import tool\n",
    "\n",
    "@tool(name=\"weather_tool\", description=\"Retrieves weather information for any location\")\n",
    "def get_weather_with_decorator(\n",
    "    location: Annotated[str, Field(description=\"The location to get the weather for.\")],\n",
    ") -> str:\n",
    "    return f\"The weather in {location} is cloudy with a high of 15Â°C.\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63cff641",
   "metadata": {},
   "source": [
    "### Creating an Agent with Tools\n",
    "\n",
    "When creating the agent, pass the function tool to the `tools` parameter:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e530d0d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an agent with the weather tool\n",
    "weather_agent = AzureOpenAIChatClient(credential=AzureCliCredential()).as_agent(\n",
    "    instructions=\"You are a helpful assistant that can check the weather.\",\n",
    "    tools=get_weather\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "479786af",
   "metadata": {},
   "source": [
    "### Running the Agent with Tools\n",
    "\n",
    "The agent will automatically call the `get_weather` function when needed:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9cbdcca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ask about the weather - the agent will call our function tool\n",
    "result = await weather_agent.run(\"What is the weather like in Amsterdam?\")\n",
    "print(result.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1de90248",
   "metadata": {},
   "source": [
    "### Class with Multiple Function Tools\n",
    "\n",
    "You can create a class containing multiple function tools as methods. This is useful for organizing related functions together or when you want to share state between them:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e6063ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "class WeatherTools:\n",
    "    def __init__(self):\n",
    "        self.last_location = None\n",
    "\n",
    "    def get_weather(\n",
    "        self,\n",
    "        location: Annotated[str, Field(description=\"The location to get the weather for.\")],\n",
    "    ) -> str:\n",
    "        \"\"\"Get the weather for a given location.\"\"\"\n",
    "        self.last_location = location\n",
    "        return f\"The weather in {location} is cloudy with a high of 15Â°C.\"\n",
    "\n",
    "    def get_weather_details(self) -> str:\n",
    "        \"\"\"Get the detailed weather for the last requested location.\"\"\"\n",
    "        if self.last_location is None:\n",
    "            return \"No location specified yet.\"\n",
    "        return f\"The detailed weather in {self.last_location} is cloudy with a high of 15Â°C, low of 7Â°C, and 60% humidity.\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8e80ab2",
   "metadata": {},
   "source": [
    "### Using Class Methods as Tools\n",
    "\n",
    "Create an instance of the class and pass its methods to the agent's `tools` parameter:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efa70478",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create instance and agent with multiple tools\n",
    "weather_tools = WeatherTools()\n",
    "\n",
    "multi_tool_agent = AzureOpenAIChatClient(credential=AzureCliCredential()).as_agent(\n",
    "    instructions=\"You are a helpful weather assistant. You can get basic weather info and detailed weather info.\",\n",
    "    tools=[weather_tools.get_weather, weather_tools.get_weather_details]\n",
    ")\n",
    "\n",
    "# Test the multi-tool agent\n",
    "result = await multi_tool_agent.run(\"What's the weather in Tokyo? Then give me the detailed forecast.\")\n",
    "print(result.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bbefd9d",
   "metadata": {},
   "source": [
    "## Human-in-the-Loop: Function Tools Requiring Approval\n",
    "\n",
    "When agents require user input (e.g., to approve a function call), this is called a **human-in-the-loop** pattern. An agent run that requires user input will complete with a response indicating what input is needed, instead of completing with a final answer.\n",
    "\n",
    "The caller is responsible for getting the required input from the user and passing it back to the agent in a new run.\n",
    "\n",
    "### Creating Tools with Approval Requirements\n",
    "\n",
    "Use the `approval_mode=\"always_require\"` parameter in the `@tool` decorator to indicate a function requires human approval:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8829240",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard tool - no approval needed\n",
    "@tool\n",
    "def get_basic_weather(location: Annotated[str, \"The city and state, e.g. San Francisco, CA\"]) -> str:\n",
    "    \"\"\"Get the current weather for a given location.\"\"\"\n",
    "    return f\"The weather in {location} is cloudy with a high of 15Â°C.\"\n",
    "\n",
    "# Tool that requires approval before execution\n",
    "@tool(approval_mode=\"always_require\")\n",
    "def get_detailed_weather(location: Annotated[str, \"The city and state, e.g. San Francisco, CA\"]) -> str:\n",
    "    \"\"\"Get detailed weather information for a given location (requires approval).\"\"\"\n",
    "    return f\"The weather in {location} is cloudy with a high of 15Â°C, humidity 88%, wind 12 km/h NW.\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eae080f2",
   "metadata": {},
   "source": [
    "### Creating the Agent with Approval-Required Tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e47e9a62",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an agent with both regular and approval-required tools\n",
    "approval_agent = AzureOpenAIChatClient(credential=AzureCliCredential()).as_agent(\n",
    "    instructions=\"You are a helpful weather assistant. Use get_detailed_weather for detailed forecasts.\",\n",
    "    tools=[get_basic_weather, get_detailed_weather]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f92c1554",
   "metadata": {},
   "source": [
    "### Checking for Approval Requests\n",
    "\n",
    "When the agent needs to call an approval-required function, it returns a response with `user_input_requests` instead of executing the function directly:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4ffbde4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ask for detailed weather - this will trigger an approval request\n",
    "result = await approval_agent.run(\"What is the detailed weather like in Amsterdam?\")\n",
    "\n",
    "# Check if approval is needed\n",
    "if result.user_input_requests:\n",
    "    print(\"ðŸ”’ Approval Required!\")\n",
    "    for user_input_needed in result.user_input_requests:\n",
    "        print(f\"  Function: {user_input_needed.function_call.name}\")\n",
    "        print(f\"  Arguments: {user_input_needed.function_call.arguments}\")\n",
    "else:\n",
    "    print(result.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d89ced48",
   "metadata": {},
   "source": [
    "### Providing Approval and Continuing\n",
    "\n",
    "Once you have the approval request, use `to_function_approval_response()` on the Content object - pass `True` to approve or `False` to reject. Then continue the conversation with the approval:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3468ebe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# If there was an approval request, provide approval and continue\n",
    "if result.user_input_requests:\n",
    "    user_input_needed = result.user_input_requests[0]\n",
    "    \n",
    "    # Simulate user approval (in a real app, this would be interactive)\n",
    "    user_approval = True  # Set to False to reject\n",
    "    print(f\"âœ… User approved: {user_approval}\")\n",
    "    \n",
    "    # Create the approval response message using to_function_approval_response()\n",
    "    approval_message = ChatMessage(\n",
    "        role=Role.USER,\n",
    "        contents=[user_input_needed.to_function_approval_response(user_approval)]\n",
    "    )\n",
    "    \n",
    "    # Continue the conversation with the approval\n",
    "    final_result = await approval_agent.run([\n",
    "        \"What is the detailed weather like in Amsterdam?\",\n",
    "        ChatMessage(role=Role.ASSISTANT, contents=[user_input_needed]),\n",
    "        approval_message\n",
    "    ])\n",
    "    print(f\"\\nðŸ“Š Final Result:\\n{final_result.text}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2fdd4af",
   "metadata": {},
   "source": [
    "## Adding Middleware to Agents\n",
    "\n",
    "Middleware allows you to **intercept and modify agent interactions** at different points in the execution pipeline. This is a powerful pattern for implementing cross-cutting concerns without modifying your core agent logic.\n",
    "\n",
    "### Why Use Middleware?\n",
    "\n",
    "| Use Case | Description |\n",
    "|----------|-------------|\n",
    "| **Logging & Monitoring** | Track all agent runs and function calls for debugging and analytics |\n",
    "| **Security** | Validate inputs, sanitize outputs, enforce access controls |\n",
    "| **Rate Limiting** | Control how often agents or functions can be called |\n",
    "| **Caching** | Cache expensive function results to improve performance |\n",
    "| **Error Handling** | Implement retry logic or graceful degradation |\n",
    "| **Metrics & Telemetry** | Collect timing data and usage statistics |\n",
    "\n",
    "### Real-World Example Use Cases\n",
    "\n",
    "1. **Production Logging**: Log every agent interaction to a monitoring system (e.g., Azure Monitor, Datadog)\n",
    "2. **Cost Control**: Track token usage and enforce budget limits per user\n",
    "3. **Compliance**: Audit all AI interactions for regulated industries (healthcare, finance)\n",
    "4. **A/B Testing**: Route requests to different model versions and compare results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "082eefb0",
   "metadata": {},
   "source": [
    "### Creating Agent Middleware\n",
    "\n",
    "Agent middleware intercepts the entire agent execution. It receives an `AgentRunContext` and a `next` function to continue execution:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70b8489c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Callable, Awaitable\n",
    "from agent_framework import AgentRunContext\n",
    "import time\n",
    "\n",
    "async def logging_agent_middleware(\n",
    "    context: AgentRunContext,\n",
    "    next: Callable[[AgentRunContext], Awaitable[None]],\n",
    ") -> None:\n",
    "    \"\"\"Simple middleware that logs agent execution with timing.\"\"\"\n",
    "    # context.messages contains the input messages\n",
    "    print(f\"ðŸš€ Agent starting... (messages: {len(context.messages)} message(s))\")\n",
    "    start_time = time.time()\n",
    "\n",
    "    # Continue to agent execution\n",
    "    await next(context)\n",
    "\n",
    "    elapsed = time.time() - start_time\n",
    "    print(f\"âœ… Agent finished! (took {elapsed:.2f}s)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e2d6fd8",
   "metadata": {},
   "source": [
    "### Adding Middleware to Your Agent\n",
    "\n",
    "Pass the middleware function to the `middleware` parameter when creating your agent:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "417d9431",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an agent with the logging middleware\n",
    "middleware_agent = AzureOpenAIChatClient(credential=AzureCliCredential()).as_agent(\n",
    "    name=\"GreetingAgent\",\n",
    "    instructions=\"You are a friendly greeting assistant.\",\n",
    "    middleware=[logging_agent_middleware]  # Add middleware here (must be a list)\n",
    ")\n",
    "\n",
    "# Test the agent - you'll see the middleware logs\n",
    "result = await middleware_agent.run(\"Hello! How are you today?\")\n",
    "print(f\"\\nðŸ’¬ Response: {result.text}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9429fcad",
   "metadata": {},
   "source": [
    "### Function Middleware\n",
    "\n",
    "If your agent uses function tools, you can intercept function calls with `FunctionInvocationContext`. This is useful for logging function usage, validating inputs, or caching results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6274db5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from agent_framework import FunctionInvocationContext\n",
    "from datetime import datetime\n",
    "\n",
    "def get_current_time() -> str:\n",
    "    \"\"\"Get the current time.\"\"\"\n",
    "    return datetime.now().strftime(\"%H:%M:%S\")\n",
    "\n",
    "async def logging_function_middleware(\n",
    "    context: FunctionInvocationContext,\n",
    "    next: Callable[[FunctionInvocationContext], Awaitable[None]],\n",
    ") -> None:\n",
    "    \"\"\"Middleware that logs function calls with inputs and outputs.\"\"\"\n",
    "    print(f\"ðŸ“ž Calling function: {context.function.name}\")\n",
    "    print(f\"   Arguments: {context.arguments}\")\n",
    "\n",
    "    await next(context)\n",
    "\n",
    "    print(f\"   Result: {context.result}\")\n",
    "\n",
    "# Create agent with both the function tool and function middleware\n",
    "time_agent = AzureOpenAIChatClient(credential=AzureCliCredential()).as_agent(\n",
    "    name=\"TimeAgent\",\n",
    "    instructions=\"You can tell the current time when asked.\",\n",
    "    tools=[get_current_time],\n",
    "    middleware=[logging_function_middleware]  # Function middleware\n",
    ")\n",
    "\n",
    "# Test the agent - you'll see function call logs\n",
    "result = await time_agent.run(\"What time is it right now?\")\n",
    "print(f\"\\nðŸ’¬ Response: {result.text}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc80541f",
   "metadata": {},
   "source": [
    "## Adding Memory to an Agent\n",
    "\n",
    "Memory allows agents to **remember information across conversations** and provide personalized responses. This is implemented using `ContextProvider`, which can run custom logic before and after agent invocations.\n",
    "\n",
    "### Why Use Memory?\n",
    "\n",
    "| Use Case | Description |\n",
    "|----------|-------------|\n",
    "| **User Personalization** | Remember user preferences, name, settings |\n",
    "| **Conversation Context** | Track topics discussed across sessions |\n",
    "| **Learning & Adaptation** | Build knowledge about user over time |\n",
    "| **State Management** | Persist important information between runs |\n",
    "\n",
    "### Real-World Example Use Cases\n",
    "\n",
    "1. **Customer Support Bot** - Remember customer's order history and preferences\n",
    "2. **Personal Assistant** - Learn user's schedule, preferences, and communication style\n",
    "3. **Educational Tutor** - Track student's progress and areas needing improvement\n",
    "4. **Healthcare Assistant** - Remember patient's medical history and medications\n",
    "\n",
    "> âš ï¸ **Important:** Not all agent types support `ContextProvider`. The `ChatAgent` used in this example does support it.\n",
    "\n",
    "### How ContextProvider Works\n",
    "\n",
    "The `ContextProvider` class has two key methods:\n",
    "\n",
    "| Method | When Called | Purpose |\n",
    "|--------|-------------|---------|\n",
    "| `invoking` | Before inference | Provide additional context (instructions, tools, messages) |\n",
    "| `invoked` | After inference | Inspect request/response and update state |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "276a9eab",
   "metadata": {},
   "source": [
    "### Step 1: Create a Model for Memories\n",
    "\n",
    "First, define a Pydantic model to hold the information you want to remember:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3994939",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel\n",
    "\n",
    "class UserInfo(BaseModel):\n",
    "    \"\"\"Model to store user information in memory.\"\"\"\n",
    "    name: str | None = None\n",
    "    age: int | None = None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e3f78d8",
   "metadata": {},
   "source": [
    "### Step 2: Implement the ContextProvider\n",
    "\n",
    "Create a custom `ContextProvider` that:\n",
    "- **Extracts** user information from messages after each call (`invoked`)\n",
    "- **Provides** remembered context before each call (`invoking`)\n",
    "- **Serializes** state for persistence (`serialize`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94b511c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections.abc import MutableSequence, Sequence\n",
    "from typing import Any\n",
    "import re\n",
    "\n",
    "from agent_framework import ContextProvider, Context, ChatAgent, ChatClientProtocol, ChatMessage\n",
    "\n",
    "\n",
    "class UserInfoMemory(ContextProvider):\n",
    "    \"\"\"A memory component that remembers user's name and age.\"\"\"\n",
    "    \n",
    "    def __init__(self, chat_client: ChatClientProtocol, user_info: UserInfo | None = None, **kwargs: Any):\n",
    "        \"\"\"Create the memory.\n",
    "        \n",
    "        Args:\n",
    "            chat_client: The chat client to use for extracting information\n",
    "            user_info: Optional pre-existing user info\n",
    "            **kwargs: Optional fields to initialize UserInfo with\n",
    "        \"\"\"\n",
    "        self._chat_client = chat_client\n",
    "        if user_info:\n",
    "            self.user_info = user_info\n",
    "        elif kwargs:\n",
    "            self.user_info = UserInfo.model_validate(kwargs)\n",
    "        else:\n",
    "            self.user_info = UserInfo()\n",
    "\n",
    "    def _extract_name(self, text: str) -> str | None:\n",
    "        \"\"\"Extract name from text using patterns.\"\"\"\n",
    "        patterns = [\n",
    "            r\"(?:my name is|i'm|i am|call me)\\s+([A-Z][a-z]+)\",\n",
    "            r\"(?:name is|name's)\\s+([A-Z][a-z]+)\",\n",
    "        ]\n",
    "        for pattern in patterns:\n",
    "            match = re.search(pattern, text, re.IGNORECASE)\n",
    "            if match:\n",
    "                return match.group(1).capitalize()\n",
    "        return None\n",
    "\n",
    "    def _extract_age(self, text: str) -> int | None:\n",
    "        \"\"\"Extract age from text using patterns.\"\"\"\n",
    "        patterns = [\n",
    "            r\"(?:i'm|i am|am)\\s+(\\d{1,3})\\s*(?:years? old|yrs? old)?\",\n",
    "            r\"(\\d{1,3})\\s*years? old\",\n",
    "            r\"age\\s*(?:is)?\\s*(\\d{1,3})\",\n",
    "        ]\n",
    "        for pattern in patterns:\n",
    "            match = re.search(pattern, text, re.IGNORECASE)\n",
    "            if match:\n",
    "                age = int(match.group(1))\n",
    "                if 0 < age < 150:  # Reasonable age range\n",
    "                    return age\n",
    "        return None\n",
    "\n",
    "    async def invoked(\n",
    "        self,\n",
    "        request_messages: ChatMessage | Sequence[ChatMessage],\n",
    "        response_messages: ChatMessage | Sequence[ChatMessage] | None = None,\n",
    "        invoke_exception: Exception | None = None,\n",
    "        **kwargs: Any,\n",
    "    ) -> None:\n",
    "        \"\"\"Extract user information from messages after each agent call.\"\"\"\n",
    "        # Ensure request_messages is a list\n",
    "        messages_list = [request_messages] if isinstance(request_messages, ChatMessage) else list(request_messages)\n",
    "\n",
    "        # Look for user messages and extract info\n",
    "        for msg in messages_list:\n",
    "            if msg.role.value == \"user\":\n",
    "                # Get the text content from the message\n",
    "                text = \"\"\n",
    "                if msg.contents:\n",
    "                    for content in msg.contents:\n",
    "                        if hasattr(content, 'text'):\n",
    "                            text += content.text + \" \"\n",
    "                \n",
    "                # Try to extract name if not already known\n",
    "                if self.user_info.name is None:\n",
    "                    extracted_name = self._extract_name(text)\n",
    "                    if extracted_name:\n",
    "                        self.user_info.name = extracted_name\n",
    "                        print(f\"   ðŸ§  Memory updated: name = {extracted_name}\")\n",
    "                \n",
    "                # Try to extract age if not already known\n",
    "                if self.user_info.age is None:\n",
    "                    extracted_age = self._extract_age(text)\n",
    "                    if extracted_age:\n",
    "                        self.user_info.age = extracted_age\n",
    "                        print(f\"   ðŸ§  Memory updated: age = {extracted_age}\")\n",
    "\n",
    "    async def invoking(self, messages: ChatMessage | MutableSequence[ChatMessage], **kwargs: Any) -> Context:\n",
    "        \"\"\"Provide user information context before each agent call.\"\"\"\n",
    "        instructions: list[str] = []\n",
    "\n",
    "        if self.user_info.name is None:\n",
    "            instructions.append(\n",
    "                \"Ask the user for their name and politely decline to answer any questions until they provide it.\"\n",
    "            )\n",
    "        else:\n",
    "            instructions.append(f\"The user's name is {self.user_info.name}.\")\n",
    "\n",
    "        if self.user_info.age is None:\n",
    "            instructions.append(\n",
    "                \"Ask the user for their age and politely decline to answer any questions until they provide it.\"\n",
    "            )\n",
    "        else:\n",
    "            instructions.append(f\"The user's age is {self.user_info.age}.\")\n",
    "\n",
    "        # Return context with additional instructions\n",
    "        return Context(instructions=\" \".join(instructions))\n",
    "\n",
    "    def serialize(self) -> str:\n",
    "        \"\"\"Serialize the user info for thread persistence.\"\"\"\n",
    "        return self.user_info.model_dump_json()\n",
    "\n",
    "print(\"âœ… UserInfoMemory class defined with regex-based extraction\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f37a59d",
   "metadata": {},
   "source": [
    "### Step 3: Create an Agent with Memory\n",
    "\n",
    "Attach the `ContextProvider` to the agent using the `context_providers` parameter:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cec9cf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a chat client for the memory provider to use\n",
    "chat_client = AzureOpenAIChatClient(credential=AzureCliCredential())\n",
    "\n",
    "# Create the memory provider\n",
    "memory_provider = UserInfoMemory(chat_client)\n",
    "\n",
    "# Create the agent with memory using ChatAgent\n",
    "memory_agent = ChatAgent(\n",
    "    chat_client=chat_client,\n",
    "    instructions=\"You are a friendly assistant. Always address the user by their name when known.\",\n",
    "    context_providers=memory_provider,\n",
    ")\n",
    "\n",
    "print(\"âœ… Agent with memory created!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e60db70",
   "metadata": {},
   "source": [
    "### Step 4: Test the Memory in Action\n",
    "\n",
    "Watch how the agent remembers information across the conversation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38082206",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new thread for the conversation\n",
    "memory_thread = memory_agent.get_new_thread()\n",
    "\n",
    "# Turn 1: Ask a question without providing name/age\n",
    "print(\"Turn 1: Asking a question without providing info\")\n",
    "print(\"-\" * 50)\n",
    "result1 = await memory_agent.run(\"Hello, what is the square root of 9?\", thread=memory_thread)\n",
    "print(f\"Agent: {result1.text}\")\n",
    "print()\n",
    "\n",
    "# Turn 2: Provide name\n",
    "print(\"Turn 2: Providing name\")\n",
    "print(\"-\" * 50)\n",
    "result2 = await memory_agent.run(\"My name is Alex\", thread=memory_thread)\n",
    "print(f\"Agent: {result2.text}\")\n",
    "print()\n",
    "\n",
    "# Turn 3: Provide age\n",
    "print(\"Turn 3: Providing age\")\n",
    "print(\"-\" * 50)\n",
    "result3 = await memory_agent.run(\"I am 25 years old\", thread=memory_thread)\n",
    "print(f\"Agent: {result3.text}\")\n",
    "print()\n",
    "\n",
    "# Turn 4: Now ask the original question - agent should use our name!\n",
    "print(\"Turn 4: Asking the original question again\")\n",
    "print(\"-\" * 50)\n",
    "result4 = await memory_agent.run(\"Now can you tell me the square root of 9?\", thread=memory_thread)\n",
    "print(f\"Agent: {result4.text}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70f06000",
   "metadata": {},
   "source": [
    "### Step 5: Inspect the Memory State\n",
    "\n",
    "You can access the memory provider through the thread to see what was remembered:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "840d3b84",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Access the memory component and inspect what was remembered\n",
    "print(\"ðŸ§  Memory State:\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"   Name: {memory_provider.user_info.name}\")\n",
    "print(f\"   Age: {memory_provider.user_info.age}\")\n",
    "print()\n",
    "\n",
    "# Show serialized state (useful for persistence)\n",
    "print(\"ðŸ“¦ Serialized State (for persistence):\")\n",
    "print(f\"   {memory_provider.serialize()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7e6f304",
   "metadata": {},
   "source": [
    "### Pre-Populated Memory\n",
    "\n",
    "You can also create a memory provider with pre-existing information:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59110839",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create memory with pre-existing user info\n",
    "pre_populated_memory = UserInfoMemory(\n",
    "    chat_client=chat_client,\n",
    "    user_info=UserInfo(name=\"Jordan\", age=30)\n",
    ")\n",
    "\n",
    "# Create agent with pre-populated memory\n",
    "pre_populated_agent = ChatAgent(\n",
    "    chat_client=chat_client,\n",
    "    instructions=\"You are a friendly assistant. Always address the user by their name.\",\n",
    "    context_providers=pre_populated_memory,\n",
    ")\n",
    "\n",
    "# The agent already knows the user!\n",
    "result = await pre_populated_agent.run(\"What's 2 + 2?\")\n",
    "print(f\"Agent (with pre-populated memory): {result.text}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09ecb767",
   "metadata": {},
   "source": [
    "## Sequential Workflows\n",
    "\n",
    "Workflows connect multiple **executors** (processing nodes) into a pipeline.\n",
    "\n",
    "| Concept | Description |\n",
    "|---------|-------------|\n",
    "| **Executor** | A unit of work (class with `@handler` OR function with `@executor`) |\n",
    "| **WorkflowBuilder** | Connects executors with `add_edge()` |\n",
    "| `ctx.send_message()` | Pass data to next executor |\n",
    "| `ctx.yield_output()` | Return final workflow result |\n",
    "\n",
    "### Two Ways to Define Executors\n",
    "\n",
    "1. **Class-based** - `class MyExecutor(Executor)` with `@handler` method\n",
    "2. **Function-based** - `@executor` decorator on async function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c863e4e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing_extensions import Never\n",
    "from agent_framework import WorkflowBuilder, WorkflowContext, WorkflowOutputEvent, Executor, executor, handler\n",
    "\n",
    "# Method 1: Class-based executor\n",
    "class UpperCase(Executor):\n",
    "    def __init__(self, id: str):\n",
    "        super().__init__(id=id)\n",
    "\n",
    "    @handler\n",
    "    async def to_upper_case(self, text: str, ctx: WorkflowContext[str]) -> None:\n",
    "        \"\"\"Convert text to uppercase and send to next executor.\"\"\"\n",
    "        result = text.upper()\n",
    "        await ctx.send_message(result)  # Pass to next node\n",
    "\n",
    "# Method 2: Function-based executor\n",
    "@executor(id=\"reverse_text_executor\")\n",
    "async def reverse_text(text: str, ctx: WorkflowContext[Never, str]) -> None:\n",
    "    \"\"\"Reverse text and yield final output.\"\"\"\n",
    "    result = text[::-1]\n",
    "    await ctx.yield_output(result)  # Final workflow output\n",
    "\n",
    "print(\"âœ… Executors defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d8e251d",
   "metadata": {},
   "source": [
    "### Build & Run the Workflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22d91107",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the workflow: UpperCase -> ReverseText\n",
    "upper_case = UpperCase(id=\"upper_case_executor\")\n",
    "\n",
    "workflow = (\n",
    "    WorkflowBuilder()\n",
    "    .add_edge(upper_case, reverse_text)  # Connect executors\n",
    "    .set_start_executor(upper_case)       # Entry point\n",
    "    .build()\n",
    ")\n",
    "\n",
    "# Run with streaming events\n",
    "async for event in workflow.run_stream(\"hello world\"):\n",
    "    print(f\"Event: {event}\")\n",
    "    if isinstance(event, WorkflowOutputEvent):\n",
    "        print(f\"\\nðŸŽ¯ Final Result: {event.data}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f19ef984",
   "metadata": {},
   "source": [
    "### Quick Reference\n",
    "\n",
    "```\n",
    "WorkflowContext[T_Out]           â†’ sends T_Out to next node via send_message()\n",
    "WorkflowContext[T_Out, T_W_Out]  â†’ also yields T_W_Out as workflow output\n",
    "WorkflowContext[Never, str]      â†’ terminal node, yields str output only\n",
    "```\n",
    "\n",
    "**Events:** `ExecutorInvokedEvent` â†’ `ExecutorCompletedEvent` â†’ `WorkflowOutputEvent`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70913ba2",
   "metadata": {},
   "source": [
    "## Concurrent Workflows (Fan-Out/Fan-In)\n",
    "\n",
    "Process data in **parallel** using fan-out/fan-in patterns:\n",
    "\n",
    "| Pattern | Method | Description |\n",
    "|---------|--------|-------------|\n",
    "| **Fan-Out** | `add_fan_out_edges(src, [a, b])` | Send same input to multiple executors |\n",
    "| **Fan-In** | `add_fan_in_edges([a, b], dest)` | Collect results into a list |\n",
    "\n",
    "```\n",
    "         â”Œâ”€â–º Average â”€â”\n",
    "Input â”€â–º Dispatcher â”€â”¤              â”œâ”€â–º Aggregator â”€â–º Output\n",
    "         â””â”€â–º Sum â”€â”€â”€â”€â”€â”˜\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d801fdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "# Dispatcher: sends input to parallel executors\n",
    "class Dispatcher(Executor):\n",
    "    @handler\n",
    "    async def handle(self, numbers: list[int], ctx: WorkflowContext[list[int]]):\n",
    "        await ctx.send_message(numbers)\n",
    "\n",
    "# Parallel executors (run concurrently)\n",
    "class Average(Executor):\n",
    "    @handler\n",
    "    async def handle(self, numbers: list[int], ctx: WorkflowContext[float]):\n",
    "        await ctx.send_message(sum(numbers) / len(numbers))\n",
    "\n",
    "class Sum(Executor):\n",
    "    @handler\n",
    "    async def handle(self, numbers: list[int], ctx: WorkflowContext[int]):\n",
    "        await ctx.send_message(sum(numbers))\n",
    "\n",
    "# Aggregator: collects results as list[int | float]\n",
    "class Aggregator(Executor):\n",
    "    @handler\n",
    "    async def handle(self, results: list[int | float], ctx: WorkflowContext[Never, list[int | float]]):\n",
    "        await ctx.yield_output(results)\n",
    "\n",
    "print(\"âœ… Concurrent executors defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "767a3736",
   "metadata": {},
   "source": [
    "### Build & Run Concurrent Workflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e23903f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create executors\n",
    "dispatcher = Dispatcher(id=\"dispatcher\")\n",
    "average = Average(id=\"average\")\n",
    "summation = Sum(id=\"sum\")\n",
    "aggregator = Aggregator(id=\"aggregator\")\n",
    "\n",
    "# Build workflow with fan-out and fan-in\n",
    "concurrent_workflow = (\n",
    "    WorkflowBuilder()\n",
    "    .set_start_executor(dispatcher)\n",
    "    .add_fan_out_edges(dispatcher, [average, summation])  # Fan-out: 1 â†’ many\n",
    "    .add_fan_in_edges([average, summation], aggregator)   # Fan-in: many â†’ 1\n",
    "    .build()\n",
    ")\n",
    "\n",
    "# Run with random numbers\n",
    "numbers = [random.randint(1, 100) for _ in range(5)]\n",
    "print(f\"Input: {numbers}\")\n",
    "\n",
    "async for event in concurrent_workflow.run_stream(numbers):\n",
    "    if isinstance(event, WorkflowOutputEvent):\n",
    "        print(f\"ðŸŽ¯ Results: {event.data}\")  # [average, sum]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38398cec",
   "metadata": {},
   "source": [
    "## Agents in Workflows\n",
    "\n",
    "Combine **AI agents** with workflows for complex multi-agent collaboration.\n",
    "\n",
    "### Why Use Agents in Workflows?\n",
    "\n",
    "| Problem | Solution |\n",
    "|---------|----------|\n",
    "| Single agent can't do everything well | **Specialized agents** - each agent excels at one task |\n",
    "| Need quality control on AI output | **Review pipelines** - Writer â†’ Reviewer â†’ Editor |\n",
    "| Complex tasks need multiple perspectives | **Collaborative agents** - Research â†’ Analyze â†’ Summarize |\n",
    "| Repetitive multi-step AI processes | **Automated pipelines** - consistent, scalable execution |\n",
    "\n",
    "### Use Cases\n",
    "\n",
    "| Use Case | Agents | Flow |\n",
    "|----------|--------|------|\n",
    "| **Content Creation** | Writer â†’ Reviewer â†’ Publisher | Draft â†’ Feedback â†’ Final |\n",
    "| **Code Review** | Developer â†’ Reviewer â†’ Security | Write â†’ Review â†’ Audit |\n",
    "| **Research** | Researcher â†’ Analyst â†’ Summarizer | Gather â†’ Analyze â†’ Report |\n",
    "| **Customer Support** | Classifier â†’ Specialist â†’ QA | Route â†’ Handle â†’ Verify |\n",
    "\n",
    "> **Key Insight:** Agents can be used directly as workflow executors!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1105e4d2",
   "metadata": {},
   "source": [
    "### Example: Writer â†’ Reviewer Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74b41c3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from agent_framework import AgentRunUpdateEvent\n",
    "\n",
    "# Create specialized agents\n",
    "writer_agent = AzureOpenAIChatClient(credential=AzureCliCredential()).as_agent(\n",
    "    name=\"Writer\",\n",
    "    instructions=\"You are an excellent content writer. Create engaging content based on prompts.\"\n",
    ")\n",
    "\n",
    "reviewer_agent = AzureOpenAIChatClient(credential=AzureCliCredential()).as_agent(\n",
    "    name=\"Reviewer\", \n",
    "    instructions=\"You are a content reviewer. Provide concise, actionable feedback on the content.\"\n",
    ")\n",
    "\n",
    "# Build workflow: Writer â†’ Reviewer (agents ARE executors!)\n",
    "agent_workflow = (\n",
    "    WorkflowBuilder()\n",
    "    .set_start_executor(writer_agent)\n",
    "    .add_edge(writer_agent, reviewer_agent)\n",
    "    .build()\n",
    ")\n",
    "\n",
    "print(\"âœ… Agent workflow created: Writer â†’ Reviewer\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27452e67",
   "metadata": {},
   "source": [
    "### Run with Streaming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4ab3019",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the agent workflow with streaming\n",
    "last_executor_id = None\n",
    "\n",
    "async for event in agent_workflow.run_stream(\"Create a slogan for an affordable electric SUV\"):\n",
    "    if isinstance(event, AgentRunUpdateEvent):\n",
    "        # Show which agent is responding\n",
    "        if event.executor_id != last_executor_id:\n",
    "            if last_executor_id:\n",
    "                print(\"\\n\")\n",
    "            print(f\"ðŸ“ {event.executor_id}:\", end=\" \", flush=True)\n",
    "            last_executor_id = event.executor_id\n",
    "        if event.data:\n",
    "            print(event.data, end=\"\", flush=True)\n",
    "    elif isinstance(event, WorkflowOutputEvent):\n",
    "        print(\"\\n\\nðŸŽ¯ Final Output:\")\n",
    "        print(event.data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d7588de",
   "metadata": {},
   "source": [
    "## 13. Workflow with Branching Logic\n",
    "\n",
    "**Why Branching?** Real workflows need decisions - route emails differently if spam, escalate tickets by priority, process orders based on type. Branching logic enables dynamic routing based on runtime conditions.\n",
    "\n",
    "### Three Routing Patterns:\n",
    "| Pattern | Use Case | Targets |\n",
    "|---------|----------|---------|\n",
    "| **Conditional Edge** | Binary decision (if/else) | Exactly 1 |\n",
    "| **Switch-Case** | Multi-way routing (enum values) | Exactly 1 |\n",
    "| **Multi-Selection** | Dynamic fan-out (parallel paths) | 1 or more |\n",
    "\n",
    "### 13.1 Conditional Edges - Binary Routing\n",
    "\n",
    "**Scenario:** Email spam detection â†’ route to spam handler OR email assistant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4794a908",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Conditional Edges - Email Spam Detection Workflow\n",
    "from dataclasses import dataclass\n",
    "from typing import Any, Literal\n",
    "from uuid import uuid4\n",
    "from pydantic import BaseModel\n",
    "\n",
    "from agent_framework import (\n",
    "    AgentExecutor,\n",
    "    AgentExecutorRequest,\n",
    "    AgentExecutorResponse,\n",
    "    ChatMessage,\n",
    "    Role,\n",
    "    WorkflowBuilder,\n",
    "    WorkflowContext,\n",
    "    executor,\n",
    ")\n",
    "\n",
    "# Data Models\n",
    "class DetectionResult(BaseModel):\n",
    "    \"\"\"Spam detection result with routing flag.\"\"\"\n",
    "    is_spam: bool\n",
    "    reason: str\n",
    "    email_content: str  # Pass original content downstream\n",
    "\n",
    "class EmailResponse(BaseModel):\n",
    "    \"\"\"Email assistant response.\"\"\"\n",
    "    response: str\n",
    "\n",
    "# Condition Function - creates predicate for routing\n",
    "def get_condition(expected_result: bool):\n",
    "    \"\"\"Factory: returns predicate matching is_spam value.\"\"\"\n",
    "    def condition(message: Any) -> bool:\n",
    "        # Handle list wrapper if present\n",
    "        if isinstance(message, list) and len(message) > 0:\n",
    "            message = message[0]\n",
    "        if not isinstance(message, AgentExecutorResponse):\n",
    "            return False\n",
    "        try:\n",
    "            # AgentExecutorResponse has .agent_response (not agent_run_response)\n",
    "            detection = DetectionResult.model_validate_json(message.agent_response.text)\n",
    "            return detection.is_spam == expected_result\n",
    "        except Exception:\n",
    "            return False\n",
    "    return condition\n",
    "\n",
    "# Handler Executors\n",
    "@executor(id=\"send_email\")\n",
    "async def handle_email_response(response: Any, ctx: WorkflowContext[Never, str]) -> None:\n",
    "    \"\"\"Handle legitimate emails - draft response.\"\"\"\n",
    "    if isinstance(response, list):\n",
    "        response = response[0]\n",
    "    email_response = EmailResponse.model_validate_json(response.agent_response.text)\n",
    "    await ctx.yield_output(f\"âœ‰ï¸ Email sent:\\n{email_response.response}\")\n",
    "\n",
    "@executor(id=\"handle_spam\")\n",
    "async def handle_spam_response(response: Any, ctx: WorkflowContext[Never, str]) -> None:\n",
    "    \"\"\"Handle spam emails - mark as spam.\"\"\"\n",
    "    if isinstance(response, list):\n",
    "        response = response[0]\n",
    "    detection = DetectionResult.model_validate_json(response.agent_response.text)\n",
    "    await ctx.yield_output(f\"ðŸš« Marked as SPAM: {detection.reason}\")\n",
    "\n",
    "@executor(id=\"to_email_assistant_request\")\n",
    "async def to_email_assistant_request(response: Any, ctx: WorkflowContext[AgentExecutorRequest]) -> None:\n",
    "    \"\"\"Transform spam detection response â†’ email assistant request.\"\"\"\n",
    "    if isinstance(response, list):\n",
    "        response = response[0]\n",
    "    detection = DetectionResult.model_validate_json(response.agent_response.text)\n",
    "    request = AgentExecutorRequest(\n",
    "        messages=[ChatMessage(Role.USER, text=detection.email_content)],\n",
    "        should_respond=True\n",
    "    )\n",
    "    await ctx.send_message(request)\n",
    "\n",
    "print(\"âœ… Conditional edge components defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5350b545",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build and run the Conditional Edge workflow\n",
    "from agent_framework import WorkflowOutputEvent\n",
    "from agent_framework._workflows._events import ExecutorCompletedEvent\n",
    "\n",
    "async def run_conditional_workflow():\n",
    "    # Create agents with structured output\n",
    "    spam_detector = AgentExecutor(\n",
    "        chat_client.as_agent(\n",
    "            instructions=(\n",
    "                \"You are a spam detection assistant. \"\n",
    "                \"Return JSON with: is_spam (bool), reason (string), email_content (string). \"\n",
    "                \"Always include the original email in email_content.\"\n",
    "            ),\n",
    "            response_format=DetectionResult,\n",
    "        ),\n",
    "        id=\"spam_detector\",\n",
    "    )\n",
    "    \n",
    "    email_assistant = AgentExecutor(\n",
    "        chat_client.as_agent(\n",
    "            instructions=(\n",
    "                \"You are an email assistant that drafts professional responses. \"\n",
    "                \"Return JSON with: response (string) containing the drafted reply.\"\n",
    "            ),\n",
    "            response_format=EmailResponse,\n",
    "        ),\n",
    "        id=\"email_assistant\",\n",
    "    )\n",
    "    \n",
    "    # Build workflow with conditional routing\n",
    "    workflow = (\n",
    "        WorkflowBuilder()\n",
    "        .set_start_executor(spam_detector)\n",
    "        # Not spam â†’ transform â†’ assistant â†’ send\n",
    "        .add_edge(spam_detector, to_email_assistant_request, condition=get_condition(False))\n",
    "        .add_edge(to_email_assistant_request, email_assistant)\n",
    "        .add_edge(email_assistant, handle_email_response)\n",
    "        # Spam â†’ handle directly\n",
    "        .add_edge(spam_detector, handle_spam_response, condition=get_condition(True))\n",
    "        .build()\n",
    "    )\n",
    "    \n",
    "    # Test with legitimate email\n",
    "    legit_email = \"Hi, I wanted to follow up on our meeting yesterday. Can we schedule a call this week?\"\n",
    "    print(\"ðŸ“§ Testing LEGITIMATE email...\")\n",
    "    request = AgentExecutorRequest(messages=[ChatMessage(Role.USER, text=legit_email)], should_respond=True)\n",
    "    events = await workflow.run(request)\n",
    "    \n",
    "    # Show agent responses and final output\n",
    "    for event in events:\n",
    "        if isinstance(event, ExecutorCompletedEvent) and event.data:\n",
    "            data = event.data[0] if isinstance(event.data, list) else event.data\n",
    "            if hasattr(data, 'agent_response'):\n",
    "                print(f\"  [{event.executor_id}]: {data.agent_response.text[:150]}...\")\n",
    "        elif isinstance(event, WorkflowOutputEvent):\n",
    "            print(f\"\\nâœ… {event.data}\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*50 + \"\\n\")\n",
    "    \n",
    "    # Test with spam email\n",
    "    spam_email = \"CONGRATULATIONS! You've won $1,000,000! Click here NOW to claim your prize!\"\n",
    "    print(\"ðŸ“§ Testing SPAM email...\")\n",
    "    request = AgentExecutorRequest(messages=[ChatMessage(Role.USER, text=spam_email)], should_respond=True)\n",
    "    events = await workflow.run(request)\n",
    "    \n",
    "    for event in events:\n",
    "        if isinstance(event, ExecutorCompletedEvent) and event.data:\n",
    "            data = event.data[0] if isinstance(event.data, list) else event.data\n",
    "            if hasattr(data, 'agent_response'):\n",
    "                print(f\"  [{event.executor_id}]: {data.agent_response.text[:150]}...\")\n",
    "        elif isinstance(event, WorkflowOutputEvent):\n",
    "            print(f\"\\nâœ… {event.data}\")\n",
    "\n",
    "await run_conditional_workflow()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fff4e052",
   "metadata": {},
   "source": [
    "### 13.2 Switch-Case Edges - Multi-Way Routing\n",
    "\n",
    "**Why Switch-Case?** When you need 3+ routing options (not just if/else). Cleaner than multiple conditional edges.\n",
    "\n",
    "**Scenario:** Email classification â†’ NotSpam | Spam | Uncertain (needs human review)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6cd79ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Switch-Case Edges - Three-Way Email Classification\n",
    "from agent_framework import Case, Default\n",
    "\n",
    "# Enhanced models for 3-way classification\n",
    "class ThreeWayDetectionResult(BaseModel):\n",
    "    \"\"\"Three-way spam classification.\"\"\"\n",
    "    spam_decision: Literal[\"NotSpam\", \"Spam\", \"Uncertain\"]\n",
    "    reason: str\n",
    "\n",
    "@dataclass\n",
    "class DetectionPayload:\n",
    "    \"\"\"Internal payload for routing.\"\"\"\n",
    "    spam_decision: str\n",
    "    reason: str\n",
    "    email_id: str\n",
    "\n",
    "@dataclass\n",
    "class StoredEmail:\n",
    "    \"\"\"Email stored in shared state.\"\"\"\n",
    "    email_id: str\n",
    "    content: str\n",
    "\n",
    "# Shared state keys\n",
    "EMAIL_PREFIX = \"email:\"\n",
    "CURRENT_EMAIL_KEY = \"current_email_id\"\n",
    "\n",
    "# Condition factory for switch-case\n",
    "def get_case(expected_decision: str):\n",
    "    \"\"\"Factory: returns predicate matching spam_decision value.\"\"\"\n",
    "    def condition(message: Any) -> bool:\n",
    "        return isinstance(message, DetectionPayload) and message.spam_decision == expected_decision\n",
    "    return condition\n",
    "\n",
    "# Executors for switch-case workflow\n",
    "@executor(id=\"store_and_analyze\")\n",
    "async def store_and_analyze(email_text: str, ctx: WorkflowContext[AgentExecutorRequest]) -> None:\n",
    "    \"\"\"Store email in shared state and send for analysis.\"\"\"\n",
    "    email = StoredEmail(email_id=str(uuid4()), content=email_text)\n",
    "    await ctx.set_shared_state(f\"{EMAIL_PREFIX}{email.email_id}\", email)\n",
    "    await ctx.set_shared_state(CURRENT_EMAIL_KEY, email.email_id)\n",
    "    await ctx.send_message(\n",
    "        AgentExecutorRequest(messages=[ChatMessage(Role.USER, text=email.content)], should_respond=True)\n",
    "    )\n",
    "\n",
    "@executor(id=\"to_detection_payload\")\n",
    "async def to_detection_payload(response: Any, ctx: WorkflowContext[DetectionPayload]) -> None:\n",
    "    \"\"\"Transform agent response â†’ typed payload for routing.\"\"\"\n",
    "    if isinstance(response, list):\n",
    "        response = response[0]\n",
    "    # Use agent_response (not agent_run_response)\n",
    "    parsed = ThreeWayDetectionResult.model_validate_json(response.agent_response.text)\n",
    "    email_id = await ctx.get_shared_state(CURRENT_EMAIL_KEY)\n",
    "    await ctx.send_message(DetectionPayload(\n",
    "        spam_decision=parsed.spam_decision,\n",
    "        reason=parsed.reason,\n",
    "        email_id=email_id\n",
    "    ))\n",
    "\n",
    "@executor(id=\"handle_not_spam_sc\")\n",
    "async def handle_not_spam(detection: DetectionPayload, ctx: WorkflowContext[AgentExecutorRequest]) -> None:\n",
    "    \"\"\"Handle NotSpam â†’ forward to email assistant.\"\"\"\n",
    "    email: StoredEmail = await ctx.get_shared_state(f\"{EMAIL_PREFIX}{detection.email_id}\")\n",
    "    await ctx.send_message(\n",
    "        AgentExecutorRequest(messages=[ChatMessage(Role.USER, text=email.content)], should_respond=True)\n",
    "    )\n",
    "\n",
    "@executor(id=\"finalize_response\")\n",
    "async def finalize_response(response: Any, ctx: WorkflowContext[Never, str]) -> None:\n",
    "    \"\"\"Finalize email assistant response.\"\"\"\n",
    "    if isinstance(response, list):\n",
    "        response = response[0]\n",
    "    parsed = EmailResponse.model_validate_json(response.agent_response.text)\n",
    "    await ctx.yield_output(f\"âœ‰ï¸ Response drafted: {parsed.response}\")\n",
    "\n",
    "@executor(id=\"handle_spam_sc\")\n",
    "async def handle_spam_sc(detection: DetectionPayload, ctx: WorkflowContext[Never, str]) -> None:\n",
    "    \"\"\"Handle Spam emails.\"\"\"\n",
    "    await ctx.yield_output(f\"ðŸš« Marked as SPAM: {detection.reason}\")\n",
    "\n",
    "@executor(id=\"handle_uncertain\")\n",
    "async def handle_uncertain(detection: DetectionPayload, ctx: WorkflowContext[Never, str]) -> None:\n",
    "    \"\"\"Handle Uncertain - flag for human review.\"\"\"\n",
    "    email: StoredEmail = await ctx.get_shared_state(f\"{EMAIL_PREFIX}{detection.email_id}\")\n",
    "    await ctx.yield_output(f\"âš ï¸ NEEDS REVIEW: {detection.reason}\\nContent: {email.content[:100]}...\")\n",
    "\n",
    "print(\"âœ… Switch-case components defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f64fd4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build and run the Switch-Case workflow\n",
    "async def run_switch_case_workflow():\n",
    "    # Three-way classification agent\n",
    "    classifier = AgentExecutor(\n",
    "        chat_client.as_agent(\n",
    "            instructions=(\n",
    "                \"You are an email classifier. Be LESS confident - use Uncertain when not sure. \"\n",
    "                \"Return JSON with: spam_decision (NotSpam, Spam, or Uncertain), reason (string).\"\n",
    "            ),\n",
    "            response_format=ThreeWayDetectionResult,\n",
    "        ),\n",
    "        id=\"classifier\",\n",
    "    )\n",
    "    \n",
    "    email_assistant = AgentExecutor(\n",
    "        chat_client.as_agent(\n",
    "            instructions=\"Draft professional email responses. Return JSON with: response (string).\",\n",
    "            response_format=EmailResponse,\n",
    "        ),\n",
    "        id=\"email_assistant_sc\",\n",
    "    )\n",
    "    \n",
    "    # Build workflow with switch-case routing\n",
    "    workflow = (\n",
    "        WorkflowBuilder()\n",
    "        .set_start_executor(store_and_analyze)\n",
    "        .add_edge(store_and_analyze, classifier)\n",
    "        .add_edge(classifier, to_detection_payload)\n",
    "        # Switch-case: one edge group, multiple targets\n",
    "        .add_switch_case_edge_group(\n",
    "            to_detection_payload,\n",
    "            [\n",
    "                Case(condition=get_case(\"NotSpam\"), target=handle_not_spam),\n",
    "                Case(condition=get_case(\"Spam\"), target=handle_spam_sc),\n",
    "                Default(target=handle_uncertain),  # Catches Uncertain + unexpected values\n",
    "            ],\n",
    "        )\n",
    "        # Continue NotSpam path\n",
    "        .add_edge(handle_not_spam, email_assistant)\n",
    "        .add_edge(email_assistant, finalize_response)\n",
    "        .build()\n",
    "    )\n",
    "    \n",
    "    # Test all three paths\n",
    "    test_emails = [\n",
    "        (\"LEGITIMATE\", \"Hi team, please review the Q4 report attached. Thanks!\"),\n",
    "        (\"SPAM\", \"URGENT: Your account will be SUSPENDED! Click NOW to verify!!!\"),\n",
    "        (\"AMBIGUOUS\", \"Hey, saw your profile and thought we could connect. Let me know if interested.\"),\n",
    "    ]\n",
    "    \n",
    "    for label, email in test_emails:\n",
    "        print(f\"ðŸ“§ Testing {label} email...\")\n",
    "        events = await workflow.run(email)\n",
    "        for event in events:\n",
    "            if isinstance(event, ExecutorCompletedEvent) and event.data:\n",
    "                data = event.data[0] if isinstance(event.data, list) else event.data\n",
    "                if hasattr(data, 'agent_response'):\n",
    "                    print(f\"  [{event.executor_id}]: {data.agent_response.text[:100]}...\")\n",
    "            elif isinstance(event, WorkflowOutputEvent):\n",
    "                print(f\"  âœ… {event.data}\")\n",
    "        print()\n",
    "\n",
    "await run_switch_case_workflow()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e81dcc00",
   "metadata": {},
   "source": [
    "### 13.3 Multi-Selection Edges - Dynamic Fan-Out\n",
    "\n",
    "**Why Multi-Selection?** When one input should trigger **multiple parallel paths** based on content. Unlike switch-case (exactly 1 target), multi-selection can activate 0 to N targets.\n",
    "\n",
    "**Scenario:** Long emails â†’ email assistant + summarizer (parallel). Short emails â†’ email assistant only."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59474cbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Multi-Selection Edges - Parallel Processing for Long Emails\n",
    "from agent_framework._workflows._events import WorkflowEvent\n",
    "\n",
    "# Additional models\n",
    "class AnalysisResult(BaseModel):\n",
    "    \"\"\"Analysis result from classifier.\"\"\"\n",
    "    spam_decision: Literal[\"NotSpam\", \"Spam\", \"Uncertain\"]\n",
    "    reason: str\n",
    "\n",
    "class EmailSummary(BaseModel):\n",
    "    \"\"\"Summary of long email.\"\"\"\n",
    "    summary: str\n",
    "\n",
    "@dataclass\n",
    "class AnalysisPayload:\n",
    "    \"\"\"Enriched payload with email metadata for routing.\"\"\"\n",
    "    spam_decision: str\n",
    "    reason: str\n",
    "    email_length: int  # Used for conditional fan-out\n",
    "    email_id: str\n",
    "\n",
    "# Custom event for tracking\n",
    "class DatabaseEvent(WorkflowEvent):\n",
    "    \"\"\"Track database operations.\"\"\"\n",
    "    pass\n",
    "\n",
    "# Selection function - heart of multi-selection\n",
    "LONG_EMAIL_THRESHOLD = 100  # characters\n",
    "\n",
    "def select_targets(payload: AnalysisPayload, target_ids: list[str]) -> list[str]:\n",
    "    \"\"\"\n",
    "    Intelligent routing based on spam decision + email length.\n",
    "    Returns LIST of target IDs to activate (can be multiple).\n",
    "    \"\"\"\n",
    "    # Target order: [handle_spam_ms, respond_to_email, summarize_email, handle_uncertain_ms]\n",
    "    handle_spam_id, respond_id, summarize_id, uncertain_id = target_ids\n",
    "    \n",
    "    if payload.spam_decision == \"Spam\":\n",
    "        return [handle_spam_id]\n",
    "    elif payload.spam_decision == \"NotSpam\":\n",
    "        targets = [respond_id]  # Always respond\n",
    "        if payload.email_length > LONG_EMAIL_THRESHOLD:\n",
    "            targets.append(summarize_id)  # Also summarize if long\n",
    "        return targets\n",
    "    else:  # Uncertain\n",
    "        return [uncertain_id]\n",
    "\n",
    "# Executors for multi-selection\n",
    "@executor(id=\"analyze_email\")\n",
    "async def analyze_email(email_text: str, ctx: WorkflowContext[AgentExecutorRequest]) -> None:\n",
    "    \"\"\"Store email and start analysis.\"\"\"\n",
    "    email = StoredEmail(email_id=str(uuid4()), content=email_text)\n",
    "    await ctx.set_shared_state(f\"{EMAIL_PREFIX}{email.email_id}\", email)\n",
    "    await ctx.set_shared_state(CURRENT_EMAIL_KEY, email.email_id)\n",
    "    await ctx.send_message(\n",
    "        AgentExecutorRequest(messages=[ChatMessage(Role.USER, text=email.content)], should_respond=True)\n",
    "    )\n",
    "\n",
    "@executor(id=\"to_analysis_payload\")\n",
    "async def to_analysis_payload(response: Any, ctx: WorkflowContext[AnalysisPayload]) -> None:\n",
    "    \"\"\"Create enriched payload with email metadata.\"\"\"\n",
    "    if isinstance(response, list):\n",
    "        response = response[0]\n",
    "    # Use agent_response (not agent_run_response)\n",
    "    parsed = AnalysisResult.model_validate_json(response.agent_response.text)\n",
    "    email_id = await ctx.get_shared_state(CURRENT_EMAIL_KEY)\n",
    "    email: StoredEmail = await ctx.get_shared_state(f\"{EMAIL_PREFIX}{email_id}\")\n",
    "    await ctx.send_message(AnalysisPayload(\n",
    "        spam_decision=parsed.spam_decision,\n",
    "        reason=parsed.reason,\n",
    "        email_length=len(email.content),\n",
    "        email_id=email_id\n",
    "    ))\n",
    "\n",
    "@executor(id=\"respond_to_email\")\n",
    "async def respond_to_email(payload: AnalysisPayload, ctx: WorkflowContext[AgentExecutorRequest]) -> None:\n",
    "    \"\"\"Forward to email assistant (always for NotSpam).\"\"\"\n",
    "    email: StoredEmail = await ctx.get_shared_state(f\"{EMAIL_PREFIX}{payload.email_id}\")\n",
    "    await ctx.send_message(\n",
    "        AgentExecutorRequest(messages=[ChatMessage(Role.USER, text=email.content)], should_respond=True)\n",
    "    )\n",
    "\n",
    "@executor(id=\"finalize_email_ms\")\n",
    "async def finalize_email_ms(response: Any, ctx: WorkflowContext[Never, str]) -> None:\n",
    "    \"\"\"Output email response.\"\"\"\n",
    "    if isinstance(response, list):\n",
    "        response = response[0]\n",
    "    parsed = EmailResponse.model_validate_json(response.agent_response.text)\n",
    "    await ctx.yield_output(f\"âœ‰ï¸ Response: {parsed.response[:100]}...\")\n",
    "\n",
    "@executor(id=\"summarize_email\")\n",
    "async def summarize_email(payload: AnalysisPayload, ctx: WorkflowContext[AgentExecutorRequest]) -> None:\n",
    "    \"\"\"Summarize long emails (parallel with respond).\"\"\"\n",
    "    email: StoredEmail = await ctx.get_shared_state(f\"{EMAIL_PREFIX}{payload.email_id}\")\n",
    "    await ctx.send_message(\n",
    "        AgentExecutorRequest(messages=[ChatMessage(Role.USER, text=f\"Summarize: {email.content}\")], should_respond=True)\n",
    "    )\n",
    "\n",
    "@executor(id=\"output_summary\")\n",
    "async def output_summary(response: Any, ctx: WorkflowContext[Never, str]) -> None:\n",
    "    \"\"\"Output email summary.\"\"\"\n",
    "    if isinstance(response, list):\n",
    "        response = response[0]\n",
    "    parsed = EmailSummary.model_validate_json(response.agent_response.text)\n",
    "    await ctx.yield_output(f\"ðŸ“‹ Summary: {parsed.summary}\")\n",
    "\n",
    "@executor(id=\"handle_spam_ms\")\n",
    "async def handle_spam_ms(payload: AnalysisPayload, ctx: WorkflowContext[Never, str]) -> None:\n",
    "    \"\"\"Handle spam.\"\"\"\n",
    "    await ctx.yield_output(f\"ðŸš« SPAM: {payload.reason}\")\n",
    "\n",
    "@executor(id=\"handle_uncertain_ms\")\n",
    "async def handle_uncertain_ms(payload: AnalysisPayload, ctx: WorkflowContext[Never, str]) -> None:\n",
    "    \"\"\"Handle uncertain.\"\"\"\n",
    "    await ctx.yield_output(f\"âš ï¸ UNCERTAIN: {payload.reason}\")\n",
    "\n",
    "print(\"âœ… Multi-selection components defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "338b8a56",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build and run the Multi-Selection workflow\n",
    "async def run_multi_selection_workflow():\n",
    "    # Classifier agent\n",
    "    analyzer = AgentExecutor(\n",
    "        chat_client.as_agent(\n",
    "            instructions=(\n",
    "                \"Classify emails. Return JSON with: spam_decision (NotSpam, Spam, Uncertain), reason (string).\"\n",
    "            ),\n",
    "            response_format=AnalysisResult,\n",
    "        ),\n",
    "        id=\"analyzer\",\n",
    "    )\n",
    "    \n",
    "    # Email assistant\n",
    "    responder = AgentExecutor(\n",
    "        chat_client.as_agent(\n",
    "            instructions=\"Draft professional responses. Return JSON with: response (string).\",\n",
    "            response_format=EmailResponse,\n",
    "        ),\n",
    "        id=\"responder\",\n",
    "    )\n",
    "    \n",
    "    # Summarizer\n",
    "    summarizer = AgentExecutor(\n",
    "        chat_client.as_agent(\n",
    "            instructions=\"Summarize emails concisely. Return JSON with: summary (string).\",\n",
    "            response_format=EmailSummary,\n",
    "        ),\n",
    "        id=\"summarizer\",\n",
    "    )\n",
    "    \n",
    "    # Build workflow with multi-selection\n",
    "    workflow = (\n",
    "        WorkflowBuilder()\n",
    "        .set_start_executor(analyze_email)\n",
    "        .add_edge(analyze_email, analyzer)\n",
    "        .add_edge(analyzer, to_analysis_payload)\n",
    "        # Multi-selection: one input â†’ multiple targets based on selection_func\n",
    "        .add_multi_selection_edge_group(\n",
    "            to_analysis_payload,\n",
    "            [handle_spam_ms, respond_to_email, summarize_email, handle_uncertain_ms],\n",
    "            selection_func=select_targets,\n",
    "        )\n",
    "        # Response path\n",
    "        .add_edge(respond_to_email, responder)\n",
    "        .add_edge(responder, finalize_email_ms)\n",
    "        # Summary path (parallel with response for long emails)\n",
    "        .add_edge(summarize_email, summarizer)\n",
    "        .add_edge(summarizer, output_summary)\n",
    "        .build()\n",
    "    )\n",
    "    \n",
    "    # Test: Short email (only response)\n",
    "    short_email = \"Quick question: What time is the meeting?\"\n",
    "    print(f\"ðŸ“§ SHORT email ({len(short_email)} chars < {LONG_EMAIL_THRESHOLD} threshold)\")\n",
    "    print(\"Expected: Response ONLY\\n\")\n",
    "    events = await workflow.run(short_email)\n",
    "    for event in events:\n",
    "        if isinstance(event, ExecutorCompletedEvent) and event.data:\n",
    "            data = event.data[0] if isinstance(event.data, list) else event.data\n",
    "            if hasattr(data, 'agent_response'):\n",
    "                print(f\"  [{event.executor_id}]: {data.agent_response.text[:80]}...\")\n",
    "        elif isinstance(event, WorkflowOutputEvent):\n",
    "            print(f\"  âœ… {event.data}\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*50 + \"\\n\")\n",
    "    \n",
    "    # Test: Long email (response + summary in parallel)\n",
    "    long_email = \"\"\"\n",
    "    Dear Team,\n",
    "    \n",
    "    I wanted to provide a comprehensive update on our Q4 initiatives. First, the product launch \n",
    "    has been rescheduled to November 15th due to supply chain delays. Second, our marketing \n",
    "    campaign will begin two weeks prior with a focus on social media engagement. Third, the \n",
    "    budget allocation has been approved by finance with a 15% increase for digital advertising.\n",
    "    \n",
    "    Additionally, we need to finalize the vendor contracts by end of this week. Please review\n",
    "    the attached proposals and provide your feedback. The legal team has already completed their\n",
    "    preliminary review and flagged a few items that need attention.\n",
    "    \n",
    "    Let's schedule a follow-up meeting to discuss action items.\n",
    "    \n",
    "    Best regards,\n",
    "    Sarah\n",
    "    \"\"\"\n",
    "    print(f\"ðŸ“§ LONG email ({len(long_email)} chars > {LONG_EMAIL_THRESHOLD} threshold)\")\n",
    "    print(\"Expected: Response AND Summary (parallel)\\n\")\n",
    "    events = await workflow.run(long_email)\n",
    "    for event in events:\n",
    "        if isinstance(event, ExecutorCompletedEvent) and event.data:\n",
    "            data = event.data[0] if isinstance(event.data, list) else event.data\n",
    "            if hasattr(data, 'agent_response'):\n",
    "                print(f\"  [{event.executor_id}]: {data.agent_response.text[:80]}...\")\n",
    "        elif isinstance(event, WorkflowOutputEvent):\n",
    "            print(f\"  âœ… {event.data}\")\n",
    "\n",
    "await run_multi_selection_workflow()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
