{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "321ecba2",
      "metadata": {},
      "source": [
        "<h1 align=\"center\">Welcome to the InboxOps Agent Framework Demo</h1>\n",
        "\n",
        "<p align=\"start\">\n",
        "InboxOps is an e-commerce operations company handling thousands of inbound support emails per day.\n",
        "In this notebook, we'll build a production-minded multi-agent Support Email Copilot using the\n",
        "<strong>Microsoft Agent Framework (Python SDK)</strong>.\n",
        "</p>\n",
        "\n",
        "---\n",
        "\n",
        "## The InboxOps Problem\n",
        "\n",
        "InboxOps started with a simple goal:\n",
        "\n",
        "\u2705 Reply faster  \n",
        "\u2705 Reduce agent workload  \n",
        "\u2705 Maintain consistent tone and quality  \n",
        "\u2705 Avoid risky or incorrect customer promises  \n",
        "\n",
        "But as volume increased, we discovered that **a single LLM prompt is not enough**.\n",
        "\n",
        "So we evolve the system step-by-step:\n",
        "\n",
        "**V0 \u2192 V1 \u2192 V2 \u2192 Production-Ready Multi-Agent Workflows**\n",
        "\n",
        "---\n",
        "\n",
        "## What is an Agent?\n",
        "\n",
        "![What is an Agent](images/what-is-agent.png)\n",
        "\n",
        "Unlike traditional LLM deployments that simply respond to prompts, agents follow the **ReAct pattern** (Reasoning + Acting):\n",
        "\n",
        "| Traditional LLM | Agent (ReAct) |\n",
        "|-----------------|---------------|\n",
        "| Input \u2192 Output | Input \u2192 Reason \u2192 Act \u2192 Observe \u2192 Repeat |\n",
        "| Single response | Multi-step execution |\n",
        "| No tool access | Tool integration |\n",
        "| Stateless | Memory & context |\n",
        "\n",
        "Agents autonomously decide *what* to do, *which* tools to use, and *when* to stop.\n",
        "\n",
        "---\n",
        "\n",
        "## Workflows & Multi-Agent Orchestration\n",
        "\n",
        "![Workflow Example](images/workflow-example.png)\n",
        "\n",
        "Complex tasks require coordination between multiple specialized agents. The Agent Framework provides workflow primitives:\n",
        "\n",
        "- **Sequential** \u2014 Agents execute in order (A \u2192 B \u2192 C)\n",
        "- **Parallel (Fan-out/Fan-in)** \u2014 Concurrent execution with result aggregation\n",
        "- **Branching** \u2014 Conditional routing based on outputs\n",
        "- **Group Chat** \u2014 Collaborative multi-agent discussions\n",
        "\n",
        "---\n",
        "\n",
        "## Demo Overview\n",
        "\n",
        "We'll build the **InboxOps Support Email Copilot** that demonstrates core framework concepts:\n",
        "\n",
        "| Section | Concept |\n",
        "|---------|---------|\n",
        "| 1-2 | V0: Basic Agent & Streaming |\n",
        "| 3-4 | V1: Threads & Tools |\n",
        "| 5-7 | V2: Approvals, Middleware, Memory |\n",
        "| 8-10 | Workflows: Sequential, Branching, Parallel |\n",
        "| 11-12 | Multi-Agent: Group Chat & Magentic |\n",
        "\n",
        "---\n",
        "\n",
        "## Prerequisites\n",
        "\n",
        "- Azure subscription with Azure OpenAI access\n",
        "- Azure OpenAI resource with deployed model (e.g., `gpt-4o-mini`)\n",
        "- Azure CLI installed and authenticated (`az login`)\n",
        "- Python 3.10+"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4d841bbb",
      "metadata": {},
      "source": [
        "# Environment Setup (InboxOps Internal Dev Environment)\n",
        "\n",
        "InboxOps is prototyping a Support Email Copilot using Azure OpenAI and the Microsoft Agent Framework.\n",
        "\n",
        "This notebook assumes:\n",
        "- You have access to an Azure OpenAI resource\n",
        "- A model deployment exists (example: `gpt-4o-mini`)\n",
        "- You can authenticate with Azure CLI (`az login`)\n",
        "- Python 3.10+\n",
        "\n",
        "> The goal is to keep the demo reproducible for developers and consistent across environments.\n",
        "\n",
        "## Create Virtual Environment\n",
        "\n",
        "Run the following in your terminal to set up the environment:\n",
        "\n",
        "```bash\n",
        "python3.10 -m venv .venv\n",
        "source .venv/bin/activate\n",
        "pip install -r requirements.txt\n",
        "```\n",
        "\n",
        "Or run the cell below to install dependencies directly."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "fe0f53fc",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u2705 Found Python 3.12: /Users/glswht/Desktop/magentic-workflow/agent-framework/.venv/bin/python3.12\n",
            "Requirement already satisfied: agent-framework in ./.venv/lib/python3.12/site-packages (from -r requirements.txt (line 4)) (1.0.0b260130)\n",
            "Requirement already satisfied: python-dotenv>=1.0.0 in ./.venv/lib/python3.12/site-packages (from -r requirements.txt (line 7)) (1.2.1)\n",
            "Requirement already satisfied: nest-asyncio>=1.5.0 in ./.venv/lib/python3.12/site-packages (from -r requirements.txt (line 10)) (1.6.0)\n",
            "Requirement already satisfied: azure-identity>=1.15.0 in ./.venv/lib/python3.12/site-packages (from -r requirements.txt (line 13)) (1.26.0b1)\n",
            "Requirement already satisfied: pydantic>=2.0.0 in ./.venv/lib/python3.12/site-packages (from -r requirements.txt (line 16)) (2.12.5)\n",
            "Requirement already satisfied: agent-framework-core==1.0.0b260130 in ./.venv/lib/python3.12/site-packages (from agent-framework-core[all]==1.0.0b260130->agent-framework->-r requirements.txt (line 4)) (1.0.0b260130)\n",
            "Requirement already satisfied: typing-extensions in ./.venv/lib/python3.12/site-packages (from agent-framework-core==1.0.0b260130->agent-framework-core[all]==1.0.0b260130->agent-framework->-r requirements.txt (line 4)) (4.15.0)\n",
            "Requirement already satisfied: pydantic-settings<3,>=2 in ./.venv/lib/python3.12/site-packages (from agent-framework-core==1.0.0b260130->agent-framework-core[all]==1.0.0b260130->agent-framework->-r requirements.txt (line 4)) (2.12.0)\n",
            "Requirement already satisfied: opentelemetry-api>=1.39.0 in ./.venv/lib/python3.12/site-packages (from agent-framework-core==1.0.0b260130->agent-framework-core[all]==1.0.0b260130->agent-framework->-r requirements.txt (line 4)) (1.39.1)\n",
            "Requirement already satisfied: opentelemetry-sdk>=1.39.0 in ./.venv/lib/python3.12/site-packages (from agent-framework-core==1.0.0b260130->agent-framework-core[all]==1.0.0b260130->agent-framework->-r requirements.txt (line 4)) (1.39.1)\n",
            "Requirement already satisfied: opentelemetry-semantic-conventions-ai>=0.4.13 in ./.venv/lib/python3.12/site-packages (from agent-framework-core==1.0.0b260130->agent-framework-core[all]==1.0.0b260130->agent-framework->-r requirements.txt (line 4)) (0.4.13)\n",
            "Requirement already satisfied: openai>=1.99.0 in ./.venv/lib/python3.12/site-packages (from agent-framework-core==1.0.0b260130->agent-framework-core[all]==1.0.0b260130->agent-framework->-r requirements.txt (line 4)) (2.16.0)\n",
            "Requirement already satisfied: mcp<2,>=1.24.0 in ./.venv/lib/python3.12/site-packages (from mcp[ws]<2,>=1.24.0->agent-framework-core==1.0.0b260130->agent-framework-core[all]==1.0.0b260130->agent-framework->-r requirements.txt (line 4)) (1.26.0)\n",
            "Requirement already satisfied: packaging>=24.1 in ./.venv/lib/python3.12/site-packages (from agent-framework-core==1.0.0b260130->agent-framework-core[all]==1.0.0b260130->agent-framework->-r requirements.txt (line 4)) (26.0)\n",
            "Requirement already satisfied: agent-framework-a2a in ./.venv/lib/python3.12/site-packages (from agent-framework-core[all]==1.0.0b260130->agent-framework->-r requirements.txt (line 4)) (1.0.0b260130)\n",
            "Requirement already satisfied: agent-framework-ag-ui in ./.venv/lib/python3.12/site-packages (from agent-framework-core[all]==1.0.0b260130->agent-framework->-r requirements.txt (line 4)) (1.0.0b260130)\n",
            "Requirement already satisfied: agent-framework-azure-ai-search in ./.venv/lib/python3.12/site-packages (from agent-framework-core[all]==1.0.0b260130->agent-framework->-r requirements.txt (line 4)) (1.0.0b260130)\n",
            "Requirement already satisfied: agent-framework-anthropic in ./.venv/lib/python3.12/site-packages (from agent-framework-core[all]==1.0.0b260130->agent-framework->-r requirements.txt (line 4)) (1.0.0b260130)\n",
            "Requirement already satisfied: agent-framework-azure-ai in ./.venv/lib/python3.12/site-packages (from agent-framework-core[all]==1.0.0b260130->agent-framework->-r requirements.txt (line 4)) (1.0.0b260130)\n",
            "Requirement already satisfied: agent-framework-azurefunctions in ./.venv/lib/python3.12/site-packages (from agent-framework-core[all]==1.0.0b260130->agent-framework->-r requirements.txt (line 4)) (1.0.0b260130)\n",
            "Requirement already satisfied: agent-framework-chatkit in ./.venv/lib/python3.12/site-packages (from agent-framework-core[all]==1.0.0b260130->agent-framework->-r requirements.txt (line 4)) (1.0.0b260130)\n",
            "Requirement already satisfied: agent-framework-copilotstudio in ./.venv/lib/python3.12/site-packages (from agent-framework-core[all]==1.0.0b260130->agent-framework->-r requirements.txt (line 4)) (1.0.0b260130)\n",
            "Requirement already satisfied: agent-framework-declarative in ./.venv/lib/python3.12/site-packages (from agent-framework-core[all]==1.0.0b260130->agent-framework->-r requirements.txt (line 4)) (1.0.0b260130)\n",
            "Requirement already satisfied: agent-framework-devui in ./.venv/lib/python3.12/site-packages (from agent-framework-core[all]==1.0.0b260130->agent-framework->-r requirements.txt (line 4)) (1.0.0b260130)\n",
            "Requirement already satisfied: agent-framework-durabletask in ./.venv/lib/python3.12/site-packages (from agent-framework-core[all]==1.0.0b260130->agent-framework->-r requirements.txt (line 4)) (1.0.0b260130)\n",
            "Requirement already satisfied: agent-framework-github-copilot in ./.venv/lib/python3.12/site-packages (from agent-framework-core[all]==1.0.0b260130->agent-framework->-r requirements.txt (line 4)) (1.0.0b260130)\n",
            "Requirement already satisfied: agent-framework-lab in ./.venv/lib/python3.12/site-packages (from agent-framework-core[all]==1.0.0b260130->agent-framework->-r requirements.txt (line 4)) (1.0.0b251024)\n",
            "Requirement already satisfied: agent-framework-mem0 in ./.venv/lib/python3.12/site-packages (from agent-framework-core[all]==1.0.0b260130->agent-framework->-r requirements.txt (line 4)) (1.0.0b260130)\n",
            "Requirement already satisfied: agent-framework-ollama in ./.venv/lib/python3.12/site-packages (from agent-framework-core[all]==1.0.0b260130->agent-framework->-r requirements.txt (line 4)) (1.0.0b260130)\n",
            "Requirement already satisfied: agent-framework-purview in ./.venv/lib/python3.12/site-packages (from agent-framework-core[all]==1.0.0b260130->agent-framework->-r requirements.txt (line 4)) (1.0.0b260130)\n",
            "Requirement already satisfied: agent-framework-redis in ./.venv/lib/python3.12/site-packages (from agent-framework-core[all]==1.0.0b260130->agent-framework->-r requirements.txt (line 4)) (1.0.0b260130)\n",
            "Requirement already satisfied: azure-core>=1.31.0 in ./.venv/lib/python3.12/site-packages (from azure-identity>=1.15.0->-r requirements.txt (line 13)) (1.38.0)\n",
            "Requirement already satisfied: cryptography>=2.5 in ./.venv/lib/python3.12/site-packages (from azure-identity>=1.15.0->-r requirements.txt (line 13)) (46.0.4)\n",
            "Requirement already satisfied: msal>=1.30.0 in ./.venv/lib/python3.12/site-packages (from azure-identity>=1.15.0->-r requirements.txt (line 13)) (1.35.0b1)\n",
            "Requirement already satisfied: msal-extensions>=1.2.0 in ./.venv/lib/python3.12/site-packages (from azure-identity>=1.15.0->-r requirements.txt (line 13)) (1.3.1)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in ./.venv/lib/python3.12/site-packages (from pydantic>=2.0.0->-r requirements.txt (line 16)) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.41.5 in ./.venv/lib/python3.12/site-packages (from pydantic>=2.0.0->-r requirements.txt (line 16)) (2.41.5)\n",
            "Requirement already satisfied: typing-inspection>=0.4.2 in ./.venv/lib/python3.12/site-packages (from pydantic>=2.0.0->-r requirements.txt (line 16)) (0.4.2)\n",
            "Requirement already satisfied: anyio>=4.5 in ./.venv/lib/python3.12/site-packages (from mcp<2,>=1.24.0->mcp[ws]<2,>=1.24.0->agent-framework-core==1.0.0b260130->agent-framework-core[all]==1.0.0b260130->agent-framework->-r requirements.txt (line 4)) (4.12.1)\n",
            "Requirement already satisfied: httpx-sse>=0.4 in ./.venv/lib/python3.12/site-packages (from mcp<2,>=1.24.0->mcp[ws]<2,>=1.24.0->agent-framework-core==1.0.0b260130->agent-framework-core[all]==1.0.0b260130->agent-framework->-r requirements.txt (line 4)) (0.4.3)\n",
            "Requirement already satisfied: httpx>=0.27.1 in ./.venv/lib/python3.12/site-packages (from mcp<2,>=1.24.0->mcp[ws]<2,>=1.24.0->agent-framework-core==1.0.0b260130->agent-framework-core[all]==1.0.0b260130->agent-framework->-r requirements.txt (line 4)) (0.28.1)\n",
            "Requirement already satisfied: jsonschema>=4.20.0 in ./.venv/lib/python3.12/site-packages (from mcp<2,>=1.24.0->mcp[ws]<2,>=1.24.0->agent-framework-core==1.0.0b260130->agent-framework-core[all]==1.0.0b260130->agent-framework->-r requirements.txt (line 4)) (4.26.0)\n",
            "Requirement already satisfied: pyjwt>=2.10.1 in ./.venv/lib/python3.12/site-packages (from pyjwt[crypto]>=2.10.1->mcp<2,>=1.24.0->mcp[ws]<2,>=1.24.0->agent-framework-core==1.0.0b260130->agent-framework-core[all]==1.0.0b260130->agent-framework->-r requirements.txt (line 4)) (2.11.0)\n",
            "Requirement already satisfied: python-multipart>=0.0.9 in ./.venv/lib/python3.12/site-packages (from mcp<2,>=1.24.0->mcp[ws]<2,>=1.24.0->agent-framework-core==1.0.0b260130->agent-framework-core[all]==1.0.0b260130->agent-framework->-r requirements.txt (line 4)) (0.0.22)\n",
            "Requirement already satisfied: sse-starlette>=1.6.1 in ./.venv/lib/python3.12/site-packages (from mcp<2,>=1.24.0->mcp[ws]<2,>=1.24.0->agent-framework-core==1.0.0b260130->agent-framework-core[all]==1.0.0b260130->agent-framework->-r requirements.txt (line 4)) (3.2.0)\n",
            "Requirement already satisfied: starlette>=0.27 in ./.venv/lib/python3.12/site-packages (from mcp<2,>=1.24.0->mcp[ws]<2,>=1.24.0->agent-framework-core==1.0.0b260130->agent-framework-core[all]==1.0.0b260130->agent-framework->-r requirements.txt (line 4)) (0.50.0)\n",
            "Requirement already satisfied: uvicorn>=0.31.1 in ./.venv/lib/python3.12/site-packages (from mcp<2,>=1.24.0->mcp[ws]<2,>=1.24.0->agent-framework-core==1.0.0b260130->agent-framework-core[all]==1.0.0b260130->agent-framework->-r requirements.txt (line 4)) (0.40.0)\n",
            "Requirement already satisfied: websockets>=15.0.1 in ./.venv/lib/python3.12/site-packages (from mcp[ws]<2,>=1.24.0->agent-framework-core==1.0.0b260130->agent-framework-core[all]==1.0.0b260130->agent-framework->-r requirements.txt (line 4)) (16.0)\n",
            "Requirement already satisfied: idna>=2.8 in ./.venv/lib/python3.12/site-packages (from anyio>=4.5->mcp<2,>=1.24.0->mcp[ws]<2,>=1.24.0->agent-framework-core==1.0.0b260130->agent-framework-core[all]==1.0.0b260130->agent-framework->-r requirements.txt (line 4)) (3.11)\n",
            "Requirement already satisfied: requests>=2.21.0 in ./.venv/lib/python3.12/site-packages (from azure-core>=1.31.0->azure-identity>=1.15.0->-r requirements.txt (line 13)) (2.32.5)\n",
            "Requirement already satisfied: cffi>=2.0.0 in ./.venv/lib/python3.12/site-packages (from cryptography>=2.5->azure-identity>=1.15.0->-r requirements.txt (line 13)) (2.0.0)\n",
            "Requirement already satisfied: pycparser in ./.venv/lib/python3.12/site-packages (from cffi>=2.0.0->cryptography>=2.5->azure-identity>=1.15.0->-r requirements.txt (line 13)) (3.0)\n",
            "Requirement already satisfied: certifi in ./.venv/lib/python3.12/site-packages (from httpx>=0.27.1->mcp<2,>=1.24.0->mcp[ws]<2,>=1.24.0->agent-framework-core==1.0.0b260130->agent-framework-core[all]==1.0.0b260130->agent-framework->-r requirements.txt (line 4)) (2026.1.4)\n",
            "Requirement already satisfied: httpcore==1.* in ./.venv/lib/python3.12/site-packages (from httpx>=0.27.1->mcp<2,>=1.24.0->mcp[ws]<2,>=1.24.0->agent-framework-core==1.0.0b260130->agent-framework-core[all]==1.0.0b260130->agent-framework->-r requirements.txt (line 4)) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in ./.venv/lib/python3.12/site-packages (from httpcore==1.*->httpx>=0.27.1->mcp<2,>=1.24.0->mcp[ws]<2,>=1.24.0->agent-framework-core==1.0.0b260130->agent-framework-core[all]==1.0.0b260130->agent-framework->-r requirements.txt (line 4)) (0.16.0)\n",
            "Requirement already satisfied: attrs>=22.2.0 in ./.venv/lib/python3.12/site-packages (from jsonschema>=4.20.0->mcp<2,>=1.24.0->mcp[ws]<2,>=1.24.0->agent-framework-core==1.0.0b260130->agent-framework-core[all]==1.0.0b260130->agent-framework->-r requirements.txt (line 4)) (25.4.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in ./.venv/lib/python3.12/site-packages (from jsonschema>=4.20.0->mcp<2,>=1.24.0->mcp[ws]<2,>=1.24.0->agent-framework-core==1.0.0b260130->agent-framework-core[all]==1.0.0b260130->agent-framework->-r requirements.txt (line 4)) (2025.9.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in ./.venv/lib/python3.12/site-packages (from jsonschema>=4.20.0->mcp<2,>=1.24.0->mcp[ws]<2,>=1.24.0->agent-framework-core==1.0.0b260130->agent-framework-core[all]==1.0.0b260130->agent-framework->-r requirements.txt (line 4)) (0.37.0)\n",
            "Requirement already satisfied: rpds-py>=0.25.0 in ./.venv/lib/python3.12/site-packages (from jsonschema>=4.20.0->mcp<2,>=1.24.0->mcp[ws]<2,>=1.24.0->agent-framework-core==1.0.0b260130->agent-framework-core[all]==1.0.0b260130->agent-framework->-r requirements.txt (line 4)) (0.30.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in ./.venv/lib/python3.12/site-packages (from requests>=2.21.0->azure-core>=1.31.0->azure-identity>=1.15.0->-r requirements.txt (line 13)) (3.4.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in ./.venv/lib/python3.12/site-packages (from requests>=2.21.0->azure-core>=1.31.0->azure-identity>=1.15.0->-r requirements.txt (line 13)) (2.6.3)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in ./.venv/lib/python3.12/site-packages (from openai>=1.99.0->agent-framework-core==1.0.0b260130->agent-framework-core[all]==1.0.0b260130->agent-framework->-r requirements.txt (line 4)) (1.9.0)\n",
            "Requirement already satisfied: jiter<1,>=0.10.0 in ./.venv/lib/python3.12/site-packages (from openai>=1.99.0->agent-framework-core==1.0.0b260130->agent-framework-core[all]==1.0.0b260130->agent-framework->-r requirements.txt (line 4)) (0.13.0)\n",
            "Requirement already satisfied: sniffio in ./.venv/lib/python3.12/site-packages (from openai>=1.99.0->agent-framework-core==1.0.0b260130->agent-framework-core[all]==1.0.0b260130->agent-framework->-r requirements.txt (line 4)) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in ./.venv/lib/python3.12/site-packages (from openai>=1.99.0->agent-framework-core==1.0.0b260130->agent-framework-core[all]==1.0.0b260130->agent-framework->-r requirements.txt (line 4)) (4.67.3)\n",
            "Requirement already satisfied: importlib-metadata<8.8.0,>=6.0 in ./.venv/lib/python3.12/site-packages (from opentelemetry-api>=1.39.0->agent-framework-core==1.0.0b260130->agent-framework-core[all]==1.0.0b260130->agent-framework->-r requirements.txt (line 4)) (8.7.1)\n",
            "Requirement already satisfied: zipp>=3.20 in ./.venv/lib/python3.12/site-packages (from importlib-metadata<8.8.0,>=6.0->opentelemetry-api>=1.39.0->agent-framework-core==1.0.0b260130->agent-framework-core[all]==1.0.0b260130->agent-framework->-r requirements.txt (line 4)) (3.23.0)\n",
            "Requirement already satisfied: opentelemetry-semantic-conventions==0.60b1 in ./.venv/lib/python3.12/site-packages (from opentelemetry-sdk>=1.39.0->agent-framework-core==1.0.0b260130->agent-framework-core[all]==1.0.0b260130->agent-framework->-r requirements.txt (line 4)) (0.60b1)\n",
            "Requirement already satisfied: click>=7.0 in ./.venv/lib/python3.12/site-packages (from uvicorn>=0.31.1->mcp<2,>=1.24.0->mcp[ws]<2,>=1.24.0->agent-framework-core==1.0.0b260130->agent-framework-core[all]==1.0.0b260130->agent-framework->-r requirements.txt (line 4)) (8.3.1)\n",
            "Requirement already satisfied: a2a-sdk>=0.3.5 in ./.venv/lib/python3.12/site-packages (from agent-framework-a2a->agent-framework-core[all]==1.0.0b260130->agent-framework->-r requirements.txt (line 4)) (0.3.22)\n",
            "Requirement already satisfied: google-api-core>=1.26.0 in ./.venv/lib/python3.12/site-packages (from a2a-sdk>=0.3.5->agent-framework-a2a->agent-framework-core[all]==1.0.0b260130->agent-framework->-r requirements.txt (line 4)) (2.29.0)\n",
            "Requirement already satisfied: protobuf>=5.29.5 in ./.venv/lib/python3.12/site-packages (from a2a-sdk>=0.3.5->agent-framework-a2a->agent-framework-core[all]==1.0.0b260130->agent-framework->-r requirements.txt (line 4)) (5.29.5)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0.0,>=1.56.2 in ./.venv/lib/python3.12/site-packages (from google-api-core>=1.26.0->a2a-sdk>=0.3.5->agent-framework-a2a->agent-framework-core[all]==1.0.0b260130->agent-framework->-r requirements.txt (line 4)) (1.72.0)\n",
            "Requirement already satisfied: proto-plus<2.0.0,>=1.22.3 in ./.venv/lib/python3.12/site-packages (from google-api-core>=1.26.0->a2a-sdk>=0.3.5->agent-framework-a2a->agent-framework-core[all]==1.0.0b260130->agent-framework->-r requirements.txt (line 4)) (1.27.1)\n",
            "Requirement already satisfied: google-auth<3.0.0,>=2.14.1 in ./.venv/lib/python3.12/site-packages (from google-api-core>=1.26.0->a2a-sdk>=0.3.5->agent-framework-a2a->agent-framework-core[all]==1.0.0b260130->agent-framework->-r requirements.txt (line 4)) (2.49.0.dev0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in ./.venv/lib/python3.12/site-packages (from google-auth<3.0.0,>=2.14.1->google-api-core>=1.26.0->a2a-sdk>=0.3.5->agent-framework-a2a->agent-framework-core[all]==1.0.0b260130->agent-framework->-r requirements.txt (line 4)) (0.4.2)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.6.1 in ./.venv/lib/python3.12/site-packages (from pyasn1-modules>=0.2.1->google-auth<3.0.0,>=2.14.1->google-api-core>=1.26.0->a2a-sdk>=0.3.5->agent-framework-a2a->agent-framework-core[all]==1.0.0b260130->agent-framework->-r requirements.txt (line 4)) (0.6.2)\n",
            "Requirement already satisfied: ag-ui-protocol>=0.1.9 in ./.venv/lib/python3.12/site-packages (from agent-framework-ag-ui->agent-framework-core[all]==1.0.0b260130->agent-framework->-r requirements.txt (line 4)) (0.1.10)\n",
            "Requirement already satisfied: fastapi>=0.115.0 in ./.venv/lib/python3.12/site-packages (from agent-framework-ag-ui->agent-framework-core[all]==1.0.0b260130->agent-framework->-r requirements.txt (line 4)) (0.128.0)\n",
            "Requirement already satisfied: annotated-doc>=0.0.2 in ./.venv/lib/python3.12/site-packages (from fastapi>=0.115.0->agent-framework-ag-ui->agent-framework-core[all]==1.0.0b260130->agent-framework->-r requirements.txt (line 4)) (0.0.4)\n",
            "Requirement already satisfied: anthropic<1,>=0.70.0 in ./.venv/lib/python3.12/site-packages (from agent-framework-anthropic->agent-framework-core[all]==1.0.0b260130->agent-framework->-r requirements.txt (line 4)) (0.77.1)\n",
            "Requirement already satisfied: docstring-parser<1,>=0.15 in ./.venv/lib/python3.12/site-packages (from anthropic<1,>=0.70.0->agent-framework-anthropic->agent-framework-core[all]==1.0.0b260130->agent-framework->-r requirements.txt (line 4)) (0.17.0)\n",
            "Requirement already satisfied: azure-ai-projects>=2.0.0b3 in ./.venv/lib/python3.12/site-packages (from agent-framework-azure-ai->agent-framework-core[all]==1.0.0b260130->agent-framework->-r requirements.txt (line 4)) (2.0.0b3)\n",
            "Requirement already satisfied: azure-ai-agents==1.2.0b5 in ./.venv/lib/python3.12/site-packages (from agent-framework-azure-ai->agent-framework-core[all]==1.0.0b260130->agent-framework->-r requirements.txt (line 4)) (1.2.0b5)\n",
            "Requirement already satisfied: aiohttp in ./.venv/lib/python3.12/site-packages (from agent-framework-azure-ai->agent-framework-core[all]==1.0.0b260130->agent-framework->-r requirements.txt (line 4)) (3.13.3)\n",
            "Requirement already satisfied: isodate>=0.6.1 in ./.venv/lib/python3.12/site-packages (from azure-ai-agents==1.2.0b5->agent-framework-azure-ai->agent-framework-core[all]==1.0.0b260130->agent-framework->-r requirements.txt (line 4)) (0.7.2)\n",
            "Requirement already satisfied: azure-storage-blob>=12.15.0 in ./.venv/lib/python3.12/site-packages (from azure-ai-projects>=2.0.0b3->agent-framework-azure-ai->agent-framework-core[all]==1.0.0b260130->agent-framework->-r requirements.txt (line 4)) (12.29.0b1)\n",
            "Requirement already satisfied: azure-search-documents==11.7.0b2 in ./.venv/lib/python3.12/site-packages (from agent-framework-azure-ai-search->agent-framework-core[all]==1.0.0b260130->agent-framework->-r requirements.txt (line 4)) (11.7.0b2)\n",
            "Requirement already satisfied: azure-common>=1.1 in ./.venv/lib/python3.12/site-packages (from azure-search-documents==11.7.0b2->agent-framework-azure-ai-search->agent-framework-core[all]==1.0.0b260130->agent-framework->-r requirements.txt (line 4)) (1.1.28)\n",
            "Requirement already satisfied: azure-functions in ./.venv/lib/python3.12/site-packages (from agent-framework-azurefunctions->agent-framework-core[all]==1.0.0b260130->agent-framework->-r requirements.txt (line 4)) (1.25.0b3.dev3)\n",
            "Requirement already satisfied: azure-functions-durable in ./.venv/lib/python3.12/site-packages (from agent-framework-azurefunctions->agent-framework-core[all]==1.0.0b260130->agent-framework->-r requirements.txt (line 4)) (1.4.0)\n",
            "Requirement already satisfied: openai-chatkit<2.0.0,>=1.4.0 in ./.venv/lib/python3.12/site-packages (from agent-framework-chatkit->agent-framework-core[all]==1.0.0b260130->agent-framework->-r requirements.txt (line 4)) (1.6.0)\n",
            "Requirement already satisfied: openai-agents>=0.3.2 in ./.venv/lib/python3.12/site-packages (from openai-chatkit<2.0.0,>=1.4.0->agent-framework-chatkit->agent-framework-core[all]==1.0.0b260130->agent-framework->-r requirements.txt (line 4)) (0.7.0)\n",
            "Requirement already satisfied: jinja2<4,>=3.1 in ./.venv/lib/python3.12/site-packages (from openai-chatkit<2.0.0,>=1.4.0->agent-framework-chatkit->agent-framework-core[all]==1.0.0b260130->agent-framework->-r requirements.txt (line 4)) (3.1.6)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in ./.venv/lib/python3.12/site-packages (from jinja2<4,>=3.1->openai-chatkit<2.0.0,>=1.4.0->agent-framework-chatkit->agent-framework-core[all]==1.0.0b260130->agent-framework->-r requirements.txt (line 4)) (3.0.3)\n",
            "Requirement already satisfied: griffe<2,>=1.5.6 in ./.venv/lib/python3.12/site-packages (from openai-agents>=0.3.2->openai-chatkit<2.0.0,>=1.4.0->agent-framework-chatkit->agent-framework-core[all]==1.0.0b260130->agent-framework->-r requirements.txt (line 4)) (1.15.0)\n",
            "Requirement already satisfied: types-requests<3,>=2.0 in ./.venv/lib/python3.12/site-packages (from openai-agents>=0.3.2->openai-chatkit<2.0.0,>=1.4.0->agent-framework-chatkit->agent-framework-core[all]==1.0.0b260130->agent-framework->-r requirements.txt (line 4)) (2.32.4.20260107)\n",
            "Requirement already satisfied: colorama>=0.4 in ./.venv/lib/python3.12/site-packages (from griffe<2,>=1.5.6->openai-agents>=0.3.2->openai-chatkit<2.0.0,>=1.4.0->agent-framework-chatkit->agent-framework-core[all]==1.0.0b260130->agent-framework->-r requirements.txt (line 4)) (0.4.6)\n",
            "Requirement already satisfied: microsoft-agents-copilotstudio-client>=0.3.1 in ./.venv/lib/python3.12/site-packages (from agent-framework-copilotstudio->agent-framework-core[all]==1.0.0b260130->agent-framework->-r requirements.txt (line 4)) (0.7.0)\n",
            "Requirement already satisfied: microsoft-agents-hosting-core==0.7.0 in ./.venv/lib/python3.12/site-packages (from microsoft-agents-copilotstudio-client>=0.3.1->agent-framework-copilotstudio->agent-framework-core[all]==1.0.0b260130->agent-framework->-r requirements.txt (line 4)) (0.7.0)\n",
            "Requirement already satisfied: microsoft-agents-activity==0.7.0 in ./.venv/lib/python3.12/site-packages (from microsoft-agents-hosting-core==0.7.0->microsoft-agents-copilotstudio-client>=0.3.1->agent-framework-copilotstudio->agent-framework-core[all]==1.0.0b260130->agent-framework->-r requirements.txt (line 4)) (0.7.0)\n",
            "Requirement already satisfied: powerfx>=0.0.31 in ./.venv/lib/python3.12/site-packages (from agent-framework-declarative->agent-framework-core[all]==1.0.0b260130->agent-framework->-r requirements.txt (line 4)) (0.0.34)\n",
            "Requirement already satisfied: pyyaml<7.0,>=6.0 in ./.venv/lib/python3.12/site-packages (from agent-framework-declarative->agent-framework-core[all]==1.0.0b260130->agent-framework->-r requirements.txt (line 4)) (6.0.3)\n",
            "Requirement already satisfied: pythonnet==3.0.5 in ./.venv/lib/python3.12/site-packages (from powerfx>=0.0.31->agent-framework-declarative->agent-framework-core[all]==1.0.0b260130->agent-framework->-r requirements.txt (line 4)) (3.0.5)\n",
            "Requirement already satisfied: clr_loader<0.3.0,>=0.2.7 in ./.venv/lib/python3.12/site-packages (from pythonnet==3.0.5->powerfx>=0.0.31->agent-framework-declarative->agent-framework-core[all]==1.0.0b260130->agent-framework->-r requirements.txt (line 4)) (0.2.10)\n",
            "Requirement already satisfied: httptools>=0.6.3 in ./.venv/lib/python3.12/site-packages (from uvicorn[standard]>=0.24.0->agent-framework-devui->agent-framework-core[all]==1.0.0b260130->agent-framework->-r requirements.txt (line 4)) (0.7.1)\n",
            "Requirement already satisfied: uvloop>=0.15.1 in ./.venv/lib/python3.12/site-packages (from uvicorn[standard]>=0.24.0->agent-framework-devui->agent-framework-core[all]==1.0.0b260130->agent-framework->-r requirements.txt (line 4)) (0.22.1)\n",
            "Requirement already satisfied: watchfiles>=0.13 in ./.venv/lib/python3.12/site-packages (from uvicorn[standard]>=0.24.0->agent-framework-devui->agent-framework-core[all]==1.0.0b260130->agent-framework->-r requirements.txt (line 4)) (1.1.1)\n",
            "Requirement already satisfied: durabletask>=1.3.0 in ./.venv/lib/python3.12/site-packages (from agent-framework-durabletask->agent-framework-core[all]==1.0.0b260130->agent-framework->-r requirements.txt (line 4)) (1.3.0)\n",
            "Requirement already satisfied: durabletask-azuremanaged>=1.3.0 in ./.venv/lib/python3.12/site-packages (from agent-framework-durabletask->agent-framework-core[all]==1.0.0b260130->agent-framework->-r requirements.txt (line 4)) (1.3.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.0 in ./.venv/lib/python3.12/site-packages (from agent-framework-durabletask->agent-framework-core[all]==1.0.0b260130->agent-framework->-r requirements.txt (line 4)) (2.9.0.post0)\n",
            "Requirement already satisfied: grpcio in ./.venv/lib/python3.12/site-packages (from durabletask>=1.3.0->agent-framework-durabletask->agent-framework-core[all]==1.0.0b260130->agent-framework->-r requirements.txt (line 4)) (1.78.0rc2)\n",
            "Requirement already satisfied: asyncio in ./.venv/lib/python3.12/site-packages (from durabletask>=1.3.0->agent-framework-durabletask->agent-framework-core[all]==1.0.0b260130->agent-framework->-r requirements.txt (line 4)) (4.0.0)\n",
            "Requirement already satisfied: six>=1.5 in ./.venv/lib/python3.12/site-packages (from python-dateutil>=2.8.0->agent-framework-durabletask->agent-framework-core[all]==1.0.0b260130->agent-framework->-r requirements.txt (line 4)) (1.17.0)\n",
            "Requirement already satisfied: github-copilot-sdk>=0.1.0 in ./.venv/lib/python3.12/site-packages (from agent-framework-github-copilot->agent-framework-core[all]==1.0.0b260130->agent-framework->-r requirements.txt (line 4)) (0.1.21)\n",
            "Requirement already satisfied: mem0ai>=1.0.0 in ./.venv/lib/python3.12/site-packages (from agent-framework-mem0->agent-framework-core[all]==1.0.0b260130->agent-framework->-r requirements.txt (line 4)) (1.0.3)\n",
            "Requirement already satisfied: posthog>=3.5.0 in ./.venv/lib/python3.12/site-packages (from mem0ai>=1.0.0->agent-framework-mem0->agent-framework-core[all]==1.0.0b260130->agent-framework->-r requirements.txt (line 4)) (7.8.0)\n",
            "Requirement already satisfied: pytz>=2024.1 in ./.venv/lib/python3.12/site-packages (from mem0ai>=1.0.0->agent-framework-mem0->agent-framework-core[all]==1.0.0b260130->agent-framework->-r requirements.txt (line 4)) (2025.2)\n",
            "Requirement already satisfied: qdrant-client>=1.9.1 in ./.venv/lib/python3.12/site-packages (from mem0ai>=1.0.0->agent-framework-mem0->agent-framework-core[all]==1.0.0b260130->agent-framework->-r requirements.txt (line 4)) (1.16.2)\n",
            "Requirement already satisfied: sqlalchemy>=2.0.31 in ./.venv/lib/python3.12/site-packages (from mem0ai>=1.0.0->agent-framework-mem0->agent-framework-core[all]==1.0.0b260130->agent-framework->-r requirements.txt (line 4)) (2.1.0b1)\n",
            "Requirement already satisfied: backoff>=1.10.0 in ./.venv/lib/python3.12/site-packages (from posthog>=3.5.0->mem0ai>=1.0.0->agent-framework-mem0->agent-framework-core[all]==1.0.0b260130->agent-framework->-r requirements.txt (line 4)) (2.2.1)\n",
            "Requirement already satisfied: numpy>=1.26 in ./.venv/lib/python3.12/site-packages (from qdrant-client>=1.9.1->mem0ai>=1.0.0->agent-framework-mem0->agent-framework-core[all]==1.0.0b260130->agent-framework->-r requirements.txt (line 4)) (2.4.2)\n",
            "Requirement already satisfied: portalocker<4.0,>=2.7.0 in ./.venv/lib/python3.12/site-packages (from qdrant-client>=1.9.1->mem0ai>=1.0.0->agent-framework-mem0->agent-framework-core[all]==1.0.0b260130->agent-framework->-r requirements.txt (line 4)) (3.2.0)\n",
            "Requirement already satisfied: h2<5,>=3 in ./.venv/lib/python3.12/site-packages (from httpx[http2]>=0.20.0->qdrant-client>=1.9.1->mem0ai>=1.0.0->agent-framework-mem0->agent-framework-core[all]==1.0.0b260130->agent-framework->-r requirements.txt (line 4)) (4.3.0)\n",
            "Requirement already satisfied: hyperframe<7,>=6.1 in ./.venv/lib/python3.12/site-packages (from h2<5,>=3->httpx[http2]>=0.20.0->qdrant-client>=1.9.1->mem0ai>=1.0.0->agent-framework-mem0->agent-framework-core[all]==1.0.0b260130->agent-framework->-r requirements.txt (line 4)) (6.1.0)\n",
            "Requirement already satisfied: hpack<5,>=4.1 in ./.venv/lib/python3.12/site-packages (from h2<5,>=3->httpx[http2]>=0.20.0->qdrant-client>=1.9.1->mem0ai>=1.0.0->agent-framework-mem0->agent-framework-core[all]==1.0.0b260130->agent-framework->-r requirements.txt (line 4)) (4.1.0)\n",
            "Requirement already satisfied: ollama>=0.5.3 in ./.venv/lib/python3.12/site-packages (from agent-framework-ollama->agent-framework-core[all]==1.0.0b260130->agent-framework->-r requirements.txt (line 4)) (0.6.1)\n",
            "Requirement already satisfied: redis>=6.4.0 in ./.venv/lib/python3.12/site-packages (from agent-framework-redis->agent-framework-core[all]==1.0.0b260130->agent-framework->-r requirements.txt (line 4)) (7.1.0)\n",
            "Requirement already satisfied: redisvl>=0.8.2 in ./.venv/lib/python3.12/site-packages (from agent-framework-redis->agent-framework-core[all]==1.0.0b260130->agent-framework->-r requirements.txt (line 4)) (0.13.2)\n",
            "Requirement already satisfied: jsonpath-ng>=1.5.0 in ./.venv/lib/python3.12/site-packages (from redisvl>=0.8.2->agent-framework-redis->agent-framework-core[all]==1.0.0b260130->agent-framework->-r requirements.txt (line 4)) (1.7.0)\n",
            "Requirement already satisfied: ml-dtypes<1.0.0,>=0.4.0 in ./.venv/lib/python3.12/site-packages (from redisvl>=0.8.2->agent-framework-redis->agent-framework-core[all]==1.0.0b260130->agent-framework->-r requirements.txt (line 4)) (0.5.4)\n",
            "Requirement already satisfied: python-ulid>=3.0.0 in ./.venv/lib/python3.12/site-packages (from redisvl>=0.8.2->agent-framework-redis->agent-framework-core[all]==1.0.0b260130->agent-framework->-r requirements.txt (line 4)) (3.1.0)\n",
            "Requirement already satisfied: tenacity>=8.2.2 in ./.venv/lib/python3.12/site-packages (from redisvl>=0.8.2->agent-framework-redis->agent-framework-core[all]==1.0.0b260130->agent-framework->-r requirements.txt (line 4)) (9.1.2)\n",
            "Requirement already satisfied: ply in ./.venv/lib/python3.12/site-packages (from jsonpath-ng>=1.5.0->redisvl>=0.8.2->agent-framework-redis->agent-framework-core[all]==1.0.0b260130->agent-framework->-r requirements.txt (line 4)) (3.11)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in ./.venv/lib/python3.12/site-packages (from aiohttp->agent-framework-azure-ai->agent-framework-core[all]==1.0.0b260130->agent-framework->-r requirements.txt (line 4)) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in ./.venv/lib/python3.12/site-packages (from aiohttp->agent-framework-azure-ai->agent-framework-core[all]==1.0.0b260130->agent-framework->-r requirements.txt (line 4)) (1.4.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in ./.venv/lib/python3.12/site-packages (from aiohttp->agent-framework-azure-ai->agent-framework-core[all]==1.0.0b260130->agent-framework->-r requirements.txt (line 4)) (1.8.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in ./.venv/lib/python3.12/site-packages (from aiohttp->agent-framework-azure-ai->agent-framework-core[all]==1.0.0b260130->agent-framework->-r requirements.txt (line 4)) (6.7.1)\n",
            "Requirement already satisfied: propcache>=0.2.0 in ./.venv/lib/python3.12/site-packages (from aiohttp->agent-framework-azure-ai->agent-framework-core[all]==1.0.0b260130->agent-framework->-r requirements.txt (line 4)) (0.4.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in ./.venv/lib/python3.12/site-packages (from aiohttp->agent-framework-azure-ai->agent-framework-core[all]==1.0.0b260130->agent-framework->-r requirements.txt (line 4)) (1.22.0)\n",
            "Requirement already satisfied: werkzeug~=3.1.3 in ./.venv/lib/python3.12/site-packages (from azure-functions->agent-framework-azurefunctions->agent-framework-core[all]==1.0.0b260130->agent-framework->-r requirements.txt (line 4)) (3.1.5)\n",
            "Requirement already satisfied: furl>=2.1.0 in ./.venv/lib/python3.12/site-packages (from azure-functions-durable->agent-framework-azurefunctions->agent-framework-core[all]==1.0.0b260130->agent-framework->-r requirements.txt (line 4)) (2.1.4)\n",
            "Requirement already satisfied: orderedmultidict>=1.0.1 in ./.venv/lib/python3.12/site-packages (from furl>=2.1.0->azure-functions-durable->agent-framework-azurefunctions->agent-framework-core[all]==1.0.0b260130->agent-framework->-r requirements.txt (line 4)) (1.0.2)\n",
            "\n",
            "\u2705 Virtual environment created at .venv\n",
            "   Activate with: source .venv/bin/activate\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.1.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m26.0\u001b[0m\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "# Create and configure the virtual environment (run once)\n",
        "import subprocess\n",
        "import shutil\n",
        "\n",
        "def find_python():\n",
        "    \"\"\"Find a Python 3.10+ interpreter on the system.\"\"\"\n",
        "    # Check common Python commands in order of preference\n",
        "    candidates = [\n",
        "        \"python3.13\", \"python3.12\", \"python3.11\", \"python3.10\",\n",
        "        \"python3\", \"python\"\n",
        "    ]\n",
        "    \n",
        "    for cmd in candidates:\n",
        "        path = shutil.which(cmd)\n",
        "        if path:\n",
        "            # Verify version is 3.10+\n",
        "            try:\n",
        "                result = subprocess.run(\n",
        "                    [path, \"-c\", \"import sys; print(f'{sys.version_info.major}.{sys.version_info.minor}')\"],\n",
        "                    capture_output=True, text=True\n",
        "                )\n",
        "                version = result.stdout.strip()\n",
        "                major, minor = map(int, version.split('.'))\n",
        "                if major >= 3 and minor >= 10:\n",
        "                    return path, version\n",
        "            except:\n",
        "                continue\n",
        "    \n",
        "    raise RuntimeError(\"No Python 3.10+ found. Please install Python 3.10 or higher.\")\n",
        "\n",
        "# Find suitable Python\n",
        "python_path, python_version = find_python()\n",
        "print(f\"\u2705 Found Python {python_version}: {python_path}\")\n",
        "\n",
        "# Create .venv\n",
        "subprocess.run([python_path, \"-m\", \"venv\", \".venv\"])\n",
        "\n",
        "# Install requirements with pre-release flag\n",
        "subprocess.run([\".venv/bin/pip\", \"install\", \"-r\", \"requirements.txt\", \"--pre\"])\n",
        "\n",
        "print(\"\\n\u2705 Virtual environment created at .venv\")\n",
        "print(\"   Activate with: source .venv/bin/activate\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3a0e423b",
      "metadata": {},
      "source": [
        "## Initialize the InboxOps Chat Client\n",
        "\n",
        "We create **one shared Azure OpenAI client** and reuse it across the entire notebook.\n",
        "\n",
        "This mirrors how InboxOps would run a long-lived backend service:\n",
        "- The service initializes once\n",
        "- Agents are created from the same client\n",
        "- Tool calls, workflows, memory, and orchestration all share the same foundation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 81,
      "id": "7d946629",
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Unclosed client session\n",
            "client_session: <aiohttp.client.ClientSession object at 0x117e7d9a0>\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u2705 Environment loaded and chat_client created\n"
          ]
        }
      ],
      "source": [
        "from agent_framework_azure_ai import AzureAIAgentClient\n",
        "import nest_asyncio\n",
        "nest_asyncio.apply()\n",
        "\n",
        "import asyncio\n",
        "from dotenv import load_dotenv\n",
        "from azure.identity import AzureCliCredential\n",
        "from agent_framework.azure import AzureOpenAIChatClient\n",
        "\n",
        "# Load environment variables\n",
        "load_dotenv()\n",
        "\n",
        "# Create ONE chat client - reused throughout the notebook\n",
        "chat_client = AzureOpenAIChatClient(credential=AzureCliCredential())\n",
        "chat_client_mcp = AzureAIAgentClient(credential=AzureCliCredential())\n",
        "\n",
        "print(\"\u2705 Environment loaded and chat_client created\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "10492593",
      "metadata": {},
      "source": [
        "## Data Models (InboxOps Message Contracts)\n",
        "\n",
        "InboxOps wants predictable, structured outputs\u2014not messy free-text.\n",
        "\n",
        "We define Pydantic schemas used across the system:\n",
        "- Incoming email structure (`EmailInput`)\n",
        "- Classification outputs (`ClassificationResult`)\n",
        "- Draft response formats (`DraftResponse`)\n",
        "- Final approval structure (`FinalResponse`)\n",
        "\n",
        "> These schemas represent the \"API contracts\" between our agents, tools, and workflows."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "e398ef4e",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u2705 Shared models defined: EmailInput, ClassificationResult, DraftResponse, FinalResponse\n"
          ]
        }
      ],
      "source": [
        "from typing import Literal, Annotated\n",
        "from pydantic import BaseModel, Field\n",
        "\n",
        "# === Input Model ===\n",
        "class EmailInput(BaseModel):\n",
        "    \"\"\"Incoming support email.\"\"\"\n",
        "    sender: str = Field(description=\"Email sender address\")\n",
        "    subject: str = Field(description=\"Email subject line\")\n",
        "    body: str = Field(description=\"Email body content\")\n",
        "    customer_id: str | None = Field(default=None, description=\"Customer ID if known\")\n",
        "    ticket_id: str | None = Field(default=None, description=\"Related ticket ID if any\")\n",
        "\n",
        "# === Classification Model ===\n",
        "class ClassificationResult(BaseModel):\n",
        "    \"\"\"Result of email classification.\"\"\"\n",
        "    category: Literal[\"spam\", \"not_spam\", \"uncertain\"] = Field(description=\"Email category\")\n",
        "    confidence: float = Field(ge=0.0, le=1.0, description=\"Confidence score 0-1\")\n",
        "    reason: str = Field(description=\"Brief explanation of classification\")\n",
        "\n",
        "# === Draft Response Model ===\n",
        "class DraftResponse(BaseModel):\n",
        "    \"\"\"Draft reply to customer email.\"\"\"\n",
        "    subject: str = Field(description=\"Reply subject line\")\n",
        "    body: str = Field(description=\"Reply body\")\n",
        "    tone: Literal[\"formal\", \"friendly\", \"apologetic\"] = Field(description=\"Tone used\")\n",
        "    needs_review: bool = Field(default=False, description=\"Flag if needs human review\")\n",
        "\n",
        "# === Final Response Model ===\n",
        "class FinalResponse(BaseModel):\n",
        "    \"\"\"Final approved response.\"\"\"\n",
        "    classification: ClassificationResult\n",
        "    draft: DraftResponse | None = Field(default=None, description=\"Draft if not spam\")\n",
        "    review_notes: str | None = Field(default=None, description=\"Reviewer comments\")\n",
        "    approved: bool = Field(default=False, description=\"Whether approved to send\")\n",
        "\n",
        "print(\"\u2705 Shared models defined: EmailInput, ClassificationResult, DraftResponse, FinalResponse\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "13ca66c9",
      "metadata": {},
      "source": [
        "## Sample InboxOps Emails\n",
        "\n",
        "We'll use three realistic email types to simulate real inbox traffic:\n",
        "\n",
        "\u2705 Legitimate Customer Issue \u2014 should generate a helpful response  \n",
        "\ud83d\udeab Spam Message \u2014 should be blocked  \n",
        "\u26a0\ufe0f Ambiguous Request \u2014 should be routed for human review  \n",
        "\n",
        "> This is exactly what InboxOps sees daily at scale."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "e7d68e08",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u2705 Sample emails defined: LEGIT_EMAIL, SPAM_EMAIL, AMBIGUOUS_EMAIL\n"
          ]
        }
      ],
      "source": [
        "# === LEGITIMATE EMAIL ===\n",
        "LEGIT_EMAIL = EmailInput(\n",
        "    sender=\"sarah.chen@acmecorp.com\",\n",
        "    subject=\"Order #12345 - Delivery Issue\",\n",
        "    body=\"\"\"Hi Support Team,\n",
        "\n",
        "I placed order #12345 last week and the tracking shows it was delivered, \n",
        "but I never received the package. I've checked with my neighbors and the building \n",
        "concierge, but no one has seen it.\n",
        "\n",
        "This is urgent as the items were needed for a client presentation on Friday.\n",
        "Can you please help me locate the package or arrange a replacement?\n",
        "\n",
        "Thank you,\n",
        "Sarah Chen\n",
        "Account: ACME-7891\n",
        "\"\"\",\n",
        "    customer_id=\"CUST-7891\",\n",
        "    ticket_id=\"TKT-2024-001\"\n",
        ")\n",
        "\n",
        "# === SPAM EMAIL ===\n",
        "SPAM_EMAIL = EmailInput(\n",
        "    sender=\"winner@prize-notifications.biz\",\n",
        "    subject=\"\ud83c\udf89 CONGRATULATIONS! You've WON $1,000,000!!!\",\n",
        "    body=\"\"\"URGENT NOTIFICATION!!!\n",
        "\n",
        "You have been selected as the WINNER of our international lottery!\n",
        "To claim your $1,000,000 prize, simply send your bank details and \n",
        "a processing fee of $500 to unlock your winnings.\n",
        "\n",
        "ACT NOW - This offer expires in 24 HOURS!!!\n",
        "\n",
        "Click here to claim: http://totally-legit-prize.com/claim\n",
        "\"\"\",\n",
        "    customer_id=None,\n",
        "    ticket_id=None\n",
        ")\n",
        "\n",
        "# === AMBIGUOUS EMAIL ===\n",
        "AMBIGUOUS_EMAIL = EmailInput(\n",
        "    sender=\"j.smith@unknown-domain.net\",\n",
        "    subject=\"Partnership Opportunity\",\n",
        "    body=\"\"\"Hello,\n",
        "\n",
        "I found your company online and I'm interested in discussing a potential \n",
        "business partnership. We have a new product line that might complement your services.\n",
        "\n",
        "Can we schedule a call this week?\n",
        "\n",
        "Best,\n",
        "J. Smith\n",
        "\"\"\",\n",
        "    customer_id=None,\n",
        "    ticket_id=None\n",
        ")\n",
        "\n",
        "print(\"\u2705 Sample emails defined: LEGIT_EMAIL, SPAM_EMAIL, AMBIGUOUS_EMAIL\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "26154c1d",
      "metadata": {},
      "source": [
        "# 1. V0 \u2014 A Single Support Agent\n",
        "\n",
        "![Agent Components](images/agent-components.png)\n",
        "\n",
        "InboxOps started with the simplest solution:\n",
        "\n",
        "**One agent that reads an email and drafts a reply.**\n",
        "\n",
        "This already provides huge value:\n",
        "- Faster draft creation\n",
        "- More consistent tone\n",
        "- Reduced repetitive typing for support reps\n",
        "\n",
        "But this is still \"V0\":\n",
        "- No streaming UX\n",
        "- No tools\n",
        "- No multi-turn context\n",
        "- No approvals or governance"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "3f96ea02",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u2705 support_agent created\n"
          ]
        }
      ],
      "source": [
        "# Create the core Support Agent - we'll enhance this throughout the notebook\n",
        "support_agent = chat_client.as_agent(\n",
        "    name=\"SupportAgent\",\n",
        "    instructions=\"\"\"You are a helpful customer support agent for an e-commerce company.\n",
        "Your job is to:\n",
        "1. Understand customer issues from their emails\n",
        "2. Draft professional, empathetic responses\n",
        "3. Provide clear next steps when possible\n",
        "\n",
        "Always be polite, acknowledge the customer's frustration, and offer concrete solutions.\"\"\"\n",
        ")\n",
        "\n",
        "print(\"\u2705 support_agent created\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cd8f5e7f",
      "metadata": {},
      "source": [
        "## Run the SupportAgent\n",
        "\n",
        "This is the InboxOps baseline:\n",
        "\n",
        "**Input:** customer email  \n",
        "**Output:** draft reply\n",
        "\n",
        "At this stage, we're validating:\n",
        "- Can the agent understand the issue?\n",
        "- Does it respond empathetically?\n",
        "- Are next steps clear and actionable?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "a0324c3e",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\ud83d\udce7 Draft Response:\n",
            "\n",
            "Subject: Re: Order #12345 - Delivery Issue\n",
            "\n",
            "Dear Sarah,\n",
            "\n",
            "Thank you for reaching out, and I sincerely apologize for the inconvenience you are experiencing with your order. I understand how important it is to have your items for your client presentation, and I appreciate your patience as we work to resolve this issue.\n",
            "\n",
            "To assist you further, I will need to initiate a trace with our shipping carrier to locate your package. This process typically takes 1-2 business days. In the meantime, I recommend checking with the shipping carrier to see if there are any additional details about the delivery that might help us.\n",
            "\n",
            "If we are unable to locate the package within that time frame, I will be happy to arrange a replacement for you to ensure you have what you need for your presentation on Friday.\n",
            "\n",
            "Please let me know if you have any further questions or if there\u2019s anything else I can help you with in the meantime.\n",
            "\n",
            "Thank you for your understanding.\n",
            "\n",
            "Best regards,\n",
            "\n",
            "[Your Name]  \n",
            "Customer Support Team  \n",
            "[Your Company]  \n",
            "[Your Contact Information]  \n"
          ]
        }
      ],
      "source": [
        "# Run the support agent on our legitimate email\n",
        "async def run_basic_agent():\n",
        "    prompt = f\"\"\"Please draft a response to this customer email:\n",
        "\n",
        "From: {LEGIT_EMAIL.sender}\n",
        "Subject: {LEGIT_EMAIL.subject}\n",
        "\n",
        "{LEGIT_EMAIL.body}\n",
        "\"\"\"\n",
        "    result = await support_agent.run(prompt)\n",
        "    print(\"\ud83d\udce7 Draft Response:\\n\")\n",
        "    print(result.text)\n",
        "\n",
        "asyncio.run(run_basic_agent())"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c6f9e31c",
      "metadata": {},
      "source": [
        "# 2. V0.1 \u2014 Streaming Responses (Real-Time UX)\n",
        "\n",
        "InboxOps support reps don't want to wait for a full answer.\n",
        "\n",
        "They want a **live drafting experience**:\n",
        "- The response appears token-by-token\n",
        "- It feels interactive, like a \"Copilot\"\n",
        "- Faster perceived performance\n",
        "\n",
        "Streaming is not just cosmetic\u2014it's a product requirement when humans are in the loop."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "9b03aef0",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\ud83d\udce7 Streaming Draft Response:\n",
            "\n",
            "Subject: Re: Order #12345 - Delivery Issue\n",
            "\n",
            "Dear Sarah,\n",
            "\n",
            "Thank you for reaching out to us regarding your order #12345. I sincerely apologize for the inconvenience and frustration this situation has caused, especially with your client presentation coming up this Friday.\n",
            "\n",
            "I understand how urgent it is to locate your package. Here are the steps we can take to resolve this issue:\n",
            "\n",
            "1. **Investigate the Delivery**: I will start by contacting our shipping carrier to gather more details about the delivery status of your order. This typically takes 1-2 business days.\n",
            "\n",
            "2. **Replacement Order**: In the meantime, if the investigation does not lead to finding your package, I can initiate a replacement order for you. Please confirm if you would like us to proceed with this option.\n",
            "\n",
            "3. **Tracking Updates**: I will provide you with updates as soon as I have more information regarding the package.\n",
            "\n",
            "Thank you for your patience and understanding. Rest assured, we are here to help you resolve this as quickly as possible.\n",
            "\n",
            "Best regards,\n",
            "\n",
            "[Your Name]  \n",
            "Customer Support Team  \n",
            "[Your Company]  \n",
            "[Your Contact Information]  \n"
          ]
        }
      ],
      "source": [
        "### Stream the response token by token using the SAME support_agent\n",
        "async def stream_support_response():\n",
        "    prompt = f\"\"\"Please draft a response to this customer email:\n",
        "\n",
        "From: {LEGIT_EMAIL.sender}\n",
        "Subject: {LEGIT_EMAIL.subject}\n",
        "\n",
        "{LEGIT_EMAIL.body}\n",
        "\"\"\"\n",
        "    print(\"\ud83d\udce7 Streaming Draft Response:\\n\")\n",
        "    async for update in support_agent.run_stream(prompt):\n",
        "        if update.text:\n",
        "            print(update.text, end=\"\", flush=True)\n",
        "    print()  # New line after streaming\n",
        "\n",
        "asyncio.run(stream_support_response())"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "54494e5c",
      "metadata": {},
      "source": [
        "# 3. V1 \u2014 Multi-Turn Conversations with Threads\n",
        "\n",
        "![Threads and Memory](images/threads-and-memory.png)\n",
        "\n",
        "InboxOps quickly discovered a real-world problem:\n",
        "\n",
        "Customers don't send only one email.\n",
        "\n",
        "They follow up:\n",
        "- \"Any updates?\"\n",
        "- \"This is urgent\"\n",
        "- \"I already tried that\"\n",
        "\n",
        "By default, agents are stateless.\n",
        "So InboxOps introduced **Threads** to preserve context across multiple turns.\n",
        "\n",
        "\u2705 The agent can summarize first  \n",
        "\u2705 Then draft a response using the summary  \n",
        "\u2705 And continue the conversation coherently"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "42f4aa94",
      "metadata": {},
      "source": [
        "## Using Threads\n",
        "\n",
        "Create a thread with `agent.get_new_thread()` and pass it to each call."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "92bc87f8",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Turn 1: Summarize the issue\n",
            "--------------------------------------------------\n",
            "- Sarah's order (#12345) shows as delivered, but she has not received the package.\n",
            "- She has checked with her neighbors and the building concierge, and no one has seen the package.\n",
            "- The situation is urgent as the items are needed for a client presentation on Friday, and she is requesting assistance in locating the package or arranging a replacement.\n",
            "\n",
            "Turn 2: Draft response with professional tone\n",
            "--------------------------------------------------\n",
            "Subject: Urgent Assistance with Your Order #12345\n",
            "\n",
            "Dear Sarah,\n",
            "\n",
            "Thank you for reaching out to us regarding your order #12345. I understand how distressing it must be not to receive an item that is crucial for your upcoming client presentation, and I sincerely apologize for any inconvenience this may have caused.\n",
            "\n",
            "To address your concerns:\n",
            "\n",
            "1. **Package Tracking and Delivery**: We will initiate an investigation with our shipping carrier to locate your package. This process may take a short while, but we will keep you updated on any progress.\n",
            "\n",
            "2. **Next Steps**: In the meantime, I will also explore the option of arranging a replacement for the items, given the urgency of your situation. Once we complete our investigation, I will provide you with further details.\n",
            "\n",
            "Please rest assured that we are committed to resolving this issue as quickly as possible. If you have any more information that could assist us, please feel free to share.\n",
            "\n",
            "Thank you for your patience and understanding.\n",
            "\n",
            "Sincerely,  \n",
            "[Your Name]  \n",
            "Customer Support Team  \n",
            "[Your Company]  \n",
            "[Contact Information]  \n"
          ]
        }
      ],
      "source": [
        "# Create a thread for multi-turn conversation\n",
        "thread = support_agent.get_new_thread()\n",
        "\n",
        "# Turn 1: Summarize the customer issue\n",
        "print(\"Turn 1: Summarize the issue\")\n",
        "print(\"-\" * 50)\n",
        "result1 = await support_agent.run(\n",
        "    f\"Summarize the key issues in this email in 2-3 bullet points:\\n\\n{LEGIT_EMAIL.body}\", \n",
        "    thread=thread\n",
        ")\n",
        "print(result1.text)\n",
        "print()\n",
        "\n",
        "# Turn 2: Draft a response (agent remembers the summary from Turn 1)\n",
        "print(\"Turn 2: Draft response with professional tone\")\n",
        "print(\"-\" * 50)\n",
        "result2 = await support_agent.run(\n",
        "    \"Now draft a professional response addressing each of those issues. Use a formal but empathetic tone.\",\n",
        "    thread=thread\n",
        ")\n",
        "print(result2.text)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b01d5c10",
      "metadata": {},
      "source": [
        "# 4. V1.1 \u2014 Tools: Connecting InboxOps Internal Systems\n",
        "\n",
        "A drafting agent is helpful\u2026\n",
        "but a production support assistant must also be **correct**.\n",
        "\n",
        "InboxOps needs the agent to reference real internal data, not guess.\n",
        "\n",
        "Examples:\n",
        "- SLA tier (Premium vs Standard)\n",
        "- Current ticket status (Open/Resolved)\n",
        "- Prior actions already taken\n",
        "\n",
        "So we expose internal functions as tools using `@tool`.\n",
        "\n",
        "The agent will autonomously decide when tool calls are needed."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bb6d70fa",
      "metadata": {},
      "source": [
        "## Define InboxOps Tools\n",
        "\n",
        "In a real InboxOps environment these tools would call:\n",
        "- CRM systems\n",
        "- ticketing platforms\n",
        "- order management databases\n",
        "\n",
        "For this demo, we simulate internal systems using in-memory dictionaries.\n",
        "\n",
        "> The key point: the Agent Framework turns Python functions into callable tools."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "963debc8",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u2705 Support tools defined: lookup_customer_sla, get_incident_status\n"
          ]
        }
      ],
      "source": [
        "from agent_framework import tool\n",
        "# Simulated database of customer SLAs\n",
        "CUSTOMER_SLAS = {\n",
        "    \"CUST-7891\": {\"tier\": \"Premium\", \"response_time\": \"4 hours\", \"replacement_policy\": \"Free expedited replacement\"},\n",
        "    \"CUST-1234\": {\"tier\": \"Standard\", \"response_time\": \"24 hours\", \"replacement_policy\": \"Standard replacement\"},\n",
        "}\n",
        "\n",
        "# Simulated ticket database\n",
        "TICKET_STATUSES = {\n",
        "    \"TKT-2024-001\": {\"status\": \"Open\", \"priority\": \"High\", \"assigned_to\": \"Support Team\", \"last_update\": \"2024-01-15\"},\n",
        "    \"TKT-2024-002\": {\"status\": \"Resolved\", \"priority\": \"Low\", \"assigned_to\": \"Bot\", \"last_update\": \"2024-01-10\"},\n",
        "}\n",
        "\n",
        "@tool(name=\"lookup_customer_sla\", description=\"Look up a customer's SLA tier and policies\")\n",
        "def lookup_customer_sla(\n",
        "    customer_id: Annotated[str, Field(description=\"The customer ID to look up (e.g., CUST-7891)\")]\n",
        ") -> str:\n",
        "    \"\"\"Look up customer SLA information.\"\"\"\n",
        "    if customer_id in CUSTOMER_SLAS:\n",
        "        sla = CUSTOMER_SLAS[customer_id]\n",
        "        return f\"Customer {customer_id}: {sla['tier']} tier, {sla['response_time']} response time, {sla['replacement_policy']}\"\n",
        "    return f\"Customer {customer_id} not found in system.\"\n",
        "\n",
        "@tool(name=\"get_incident_status\", description=\"Get the current status of a support ticket\")\n",
        "def get_incident_status(\n",
        "    ticket_id: Annotated[str, Field(description=\"The ticket ID to check (e.g., TKT-2024-001)\")]\n",
        ") -> str:\n",
        "    \"\"\"Get ticket status information.\"\"\"\n",
        "    if ticket_id in TICKET_STATUSES:\n",
        "        ticket = TICKET_STATUSES[ticket_id]\n",
        "        return f\"Ticket {ticket_id}: Status={ticket['status']}, Priority={ticket['priority']}, Assigned to={ticket['assigned_to']}, Last update={ticket['last_update']}\"\n",
        "    return f\"Ticket {ticket_id} not found in system.\"\n",
        "\n",
        "print(\"\u2705 Support tools defined: lookup_customer_sla, get_incident_status\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0b7ee9eb",
      "metadata": {},
      "source": [
        "## Attach Tools to Agent\n",
        "\n",
        "Pass tools when creating the agent."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "id": "363e4277",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u2705 support_agent_with_tools created\n"
          ]
        }
      ],
      "source": [
        "# Create support agent with tools\n",
        "support_agent_with_tools = chat_client.as_agent(\n",
        "    name=\"SupportAgentWithTools\",\n",
        "    instructions=\"\"\"You are a customer support agent with access to internal systems.\n",
        "When handling emails:\n",
        "1. Look up the customer's SLA tier to understand their service level\n",
        "2. Check ticket status if a ticket ID is mentioned\n",
        "3. Use this information to provide appropriate responses and set expectations\n",
        "\n",
        "Always be empathetic and use the customer's SLA tier to guide your response (e.g., Premium customers get expedited service).\"\"\",\n",
        "    tools=[lookup_customer_sla, get_incident_status]\n",
        ")\n",
        "\n",
        "print(\"\u2705 support_agent_with_tools created\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f461f75e",
      "metadata": {},
      "source": [
        "## Execute with Tools\n",
        "\n",
        "The agent autonomously decides when to invoke tools."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "63cff641",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\ud83d\udce7 Response (with tool lookups):\n",
            "\n",
            "Subject: Re: Order #12345 - Delivery Issue\n",
            "\n",
            "Hi Sarah,\n",
            "\n",
            "Thank you for reaching out and I\u2019m sorry to hear about the delivery issue with your order. I understand how urgent this is, especially with your client presentation coming up on Friday.\n",
            "\n",
            "I see that you are a Premium tier customer, which means we can expedite your request. Currently, your ticket (TKT-2024-001) is open and marked as high priority, and it has been assigned to our support team.\n",
            "\n",
            "I will escalate this matter right away to ensure we locate your package or arrange a replacement as soon as possible. You can expect an update from us within the next 4 hours.\n",
            "\n",
            "Thank you for your patience, and please let me know if there\u2019s anything else I can assist you with in the meantime.\n",
            "\n",
            "Best regards,\n",
            "\n",
            "[Your Name]  \n",
            "Customer Support Team\n"
          ]
        }
      ],
      "source": [
        "# Test with the legitimate email that has customer_id and ticket_id\n",
        "prompt = f\"\"\"Handle this customer support email. Look up their SLA and ticket status first:\n",
        "\n",
        "From: {LEGIT_EMAIL.sender}\n",
        "Subject: {LEGIT_EMAIL.subject}\n",
        "Customer ID: {LEGIT_EMAIL.customer_id}\n",
        "Ticket ID: {LEGIT_EMAIL.ticket_id}\n",
        "\n",
        "{LEGIT_EMAIL.body}\n",
        "\"\"\"\n",
        "\n",
        "result = await support_agent_with_tools.run(prompt)\n",
        "print(\"\ud83d\udce7 Response (with tool lookups):\\n\")\n",
        "print(result.text)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "90598d46",
      "metadata": {},
      "source": [
        "# 4.1. V1.2 \u2014 Multimodal Input (InboxOps Visual Support)\n",
        "\n",
        "## The Problem: Customers Send Screenshots\n",
        "\n",
        "InboxOps customers often attach **error screenshots** instead of describing problems in text:\n",
        "\n",
        "> \"My checkout isn't working\" + \ud83d\uddbc\ufe0f `error_screenshot.png`\n",
        "\n",
        "Our agents need to understand images, PDFs, and attachments to provide accurate support.\n",
        "\n",
        "## Solution: Multimodal Content\n",
        "\n",
        "The Agent Framework supports multimodal input using `Content` objects:\n",
        "\n",
        "Let's enable our Support Agent to handle customer screenshots.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "id": "9f6c3f9a",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u2705 multimodal_support_agent created\n",
            "\n",
            "\ud83d\udce7 Email with screenshot received...\n",
            "\ud83d\udcce Attachment: images/customer_image.png\n",
            "\n",
            "================================================================================\n",
            "\n",
            "\ud83e\udd16 Multimodal Support Agent analyzing email and screenshot...\n",
            "\n",
            "I can see the screenshot you provided. Here's a breakdown of the issue observed:\n",
            "\n",
            "### Description of the Issue\n",
            "- The checkout process has encountered an error that states: **\"There was an error processing your customer info. Please try again, or contact us if you continue to have problems.\"**\n",
            "\n",
            "### Troubleshooting Steps\n",
            "\n",
            "1. **Check Input Information**:\n",
            "   - Review all fields in the customer information section (name, address, email, phone number, etc.) to ensure they are filled out correctly.\n",
            "   - Look for any required fields that might be blank or incorrectly formatted (like postal codes or phone numbers).\n",
            "\n",
            "2. **Refresh the Page**:\n",
            "   - Sometimes simply refreshing the webpage can resolve temporary glitches. After refreshing, try to fill out the form again.\n",
            "\n",
            "3. **Clear Browser Cache**:\n",
            "   - Clear your browser cache or try accessing the checkout page in an incognito/private browsing window.\n",
            "\n",
            "4. **Browser Compatibility**:\n",
            "   - Ensure you are using an updated web browser. Sometimes, switching to a different browser can help (e.g., from Chrome to Firefox).\n",
            "\n",
            "5. **Check for Special Characters**:\n",
            "   - If you\u2019re entering text, avoid using special characters that may not be allowed in the fields (like &, #, etc.).\n",
            "\n",
            "6. **Disable Browser Extensions**:\n",
            "   - Try disabling any ad-blockers or other extensions that might interfere with web forms.\n",
            "\n",
            "7. **Try Another Device**:\n",
            "   - If the issue persists, try accessing the checkout process from a different device to see if the problem is device-specific.\n",
            "\n",
            "8. **Contact Support**:\n",
            "   - If none of these steps resolve the issue, reach out to customer support for assistance, providing them with details of the error message.\n",
            "\n",
            "By following these steps, you should be able to address the issue effectively. If problems continue, contacting support may be necessary.\n"
          ]
        }
      ],
      "source": [
        "# Create a specialized Multimodal Support Agent for handling visual issues\n",
        "multimodal_support_agent = chat_client.as_agent(\n",
        "    name=\"MultimodalSupportAgent\",\n",
        "    instructions=\"\"\"You are a specialized customer support agent with expertise in visual issue diagnosis.\n",
        "\n",
        "IMPORTANT: When you receive an image, you MUST:\n",
        "1. Acknowledge that you can see the image\n",
        "2. Describe what you observe in the screenshot\n",
        "3. Identify any error messages visible\n",
        "4. Provide specific troubleshooting steps based on what you see\n",
        "\n",
        "Your responsibilities:\n",
        "- Analyze both textual descriptions and visual evidence (screenshots, images)\n",
        "- Identify the exact error or problem from the visual content\n",
        "- Provide step-by-step resolution instructions\n",
        "- Consider visual context when recommending solutions\n",
        "- Prioritize urgent issues and offer temporary workarounds\n",
        "\n",
        "Be empathetic, solution-focused, and clear in your guidance.\"\"\"\n",
        ")\n",
        "\n",
        "print(\"\u2705 multimodal_support_agent created\")\n",
        "\n",
        "# Load the customer's screenshot from local images folder\n",
        "image_path = \"images/customer_image.png\"\n",
        "\n",
        "print(\"\\n\ud83d\udce7 Email with screenshot received...\")\n",
        "print(f\"\ud83d\udcce Attachment: {image_path}\")\n",
        "\n",
        "# Load the image from file\n",
        "with open(image_path, \"rb\") as f:\n",
        "    image_bytes = f.read()\n",
        "print(\"\\n\" + \"=\"*80 + \"\\n\")\n",
        "\n",
        "# Create a multimodal message with the local image\n",
        "from agent_framework import ChatMessage, Content, Role\n",
        "\n",
        "multimodal_message = ChatMessage(\n",
        "    role=Role.USER,\n",
        "    contents=[\n",
        "        Content.from_text(text=\"What error do you see in this checkout screenshot? Describe the issue and provide troubleshooting steps.\"),\n",
        "        Content.from_data(data=image_bytes, media_type=\"image/png\")\n",
        "    ]\n",
        ")\n",
        "\n",
        "# Run the specialized multimodal support agent - pass as messages list\n",
        "print(\"\ud83e\udd16 Multimodal Support Agent analyzing email and screenshot...\\n\")\n",
        "result = await multimodal_support_agent.run(messages=[multimodal_message])\n",
        "print(result.text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4f181ab4",
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "69c6311d",
      "metadata": {},
      "source": [
        "# 4.2. V1.3 \u2014 Structured Output (InboxOps Ticket Metadata)\n",
        "\n",
        "## The Problem: Downstream Systems Need JSON\n",
        "\n",
        "After the agent drafts a response, InboxOps needs to:\n",
        "- Create a ticket in the CRM with structured metadata\n",
        "- Log priority, category, sentiment\n",
        "- Route to the correct team\n",
        "\n",
        "**Free-text agent output is hard to parse reliably.**\n",
        "\n",
        "## Solution: Structured Output with Pydantic\n",
        "\n",
        "Use `response_format` to enforce a JSON schema:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "id": "9d1a08a9",
      "metadata": {},
      "outputs": [],
      "source": [
        "from pydantic import BaseModel\n",
        "\n",
        "class TicketMetadata(BaseModel):\n",
        "    priority: str  # \"low\", \"medium\", \"high\", \"urgent\"\n",
        "    category: str  # \"order\", \"refund\", \"technical\", etc.\n",
        "    sentiment: str  # \"positive\", \"neutral\", \"negative\"\n",
        "    estimated_resolution_time: str\n",
        "\n",
        "agent = chat_client.as_agent(\n",
        "    name=\"TicketMetadataExtractor\",\n",
        "    response_format=TicketMetadata  # Force structured output\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8ed588fa",
      "metadata": {},
      "source": [
        "Let's extract ticket metadata automatically."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "id": "507e0567",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\ud83d\udce7 Extracting metadata from email...\n",
            "\n",
            "\ud83d\udd0d Raw agent output:\n",
            "{\n",
            "    \"priority\": \"urgent\",\n",
            "    \"category\": \"shipping\",\n",
            "    \"sentiment\": \"negative\",\n",
            "    \"estimated_resolution_time\": \"1-2 hours\",\n",
            "    \"requires_human_review\": true\n",
            "}\n",
            "\n",
            "\ud83d\udcca TICKET METADATA\n",
            "==================================================\n",
            "Priority:              urgent\n",
            "Category:              shipping\n",
            "Sentiment:             negative\n",
            "Est. Resolution Time:  1-2 hours\n",
            "Needs Human Review:    True\n",
            "\n",
            "\u2705 Structured output ready for CRM ingestion!\n"
          ]
        }
      ],
      "source": [
        "from pydantic import BaseModel, Field\n",
        "\n",
        "# Define ticket metadata schema\n",
        "class TicketMetadata(BaseModel):\n",
        "    \"\"\"Structured metadata for InboxOps support tickets\"\"\"\n",
        "    priority: str = Field(description=\"Priority level: low, medium, high, or urgent\")\n",
        "    category: str = Field(description=\"Ticket category: order, refund, technical, shipping, account, other\")\n",
        "    sentiment: str = Field(description=\"Customer sentiment: positive, neutral, or negative\")\n",
        "    estimated_resolution_time: str = Field(description=\"Estimated time to resolve (e.g., '1 hour', '24 hours', '3-5 days')\")\n",
        "    requires_human_review: bool = Field(description=\"Whether this ticket needs escalation to a human agent\")\n",
        "\n",
        "# Create a metadata extraction agent\n",
        "metadata_agent = chat_client.as_agent(\n",
        "    name=\"TicketMetadataExtractor\",\n",
        "    instructions=\"\"\"You are an InboxOps ticket classification system.\n",
        "    Extract structured metadata from customer support emails.\n",
        "    Be accurate and consistent with your classifications.\n",
        "    \n",
        "    You must return JSON with these exact fields:\n",
        "    - priority: low, medium, high, or urgent\n",
        "    - category: order, refund, technical, shipping, account, or other\n",
        "    - sentiment: positive, neutral, or negative\n",
        "    - estimated_resolution_time: estimated time like \"1 hour\", \"24 hours\", \"3-5 days\"\n",
        "    - requires_human_review: true or false\"\"\",\n",
        "    response_format=TicketMetadata  # Enforce structured output\n",
        ")\n",
        "\n",
        "# Test with the legitimate email\n",
        "test_email = LEGIT_EMAIL.body\n",
        "\n",
        "print(\"\ud83d\udce7 Extracting metadata from email...\\n\")\n",
        "result = await metadata_agent.run(test_email)\n",
        "\n",
        "# Debug: Show what the agent returned\n",
        "print(\"\ud83d\udd0d Raw agent output:\")\n",
        "print(result.text)\n",
        "print()\n",
        "\n",
        "# Parse the structured output\n",
        "metadata = TicketMetadata.model_validate_json(result.text)\n",
        "\n",
        "print(\"\ud83d\udcca TICKET METADATA\")\n",
        "print(\"=\"*50)\n",
        "print(f\"Priority:              {metadata.priority}\")\n",
        "print(f\"Category:              {metadata.category}\")\n",
        "print(f\"Sentiment:             {metadata.sentiment}\")\n",
        "print(f\"Est. Resolution Time:  {metadata.estimated_resolution_time}\")\n",
        "print(f\"Needs Human Review:    {metadata.requires_human_review}\")\n",
        "print(\"\\n\u2705 Structured output ready for CRM ingestion!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fcbd7b8a",
      "metadata": {},
      "source": [
        "# 4.3. V1.4 \u2014 MCP Integration (InboxOps External Tool Connections)\n",
        "\n",
        "## The Problem: Need to Connect External Systems\n",
        "\n",
        "InboxOps uses **Zendesk** for ticketing, **Shopify** for orders, and **Stripe** for payments.\n",
        "\n",
        "Instead of building custom API wrappers for each system, we can use **Model Context Protocol (MCP)** to connect agents to external tools.\n",
        "\n",
        "## Solution: MCP Tools\n",
        "\n",
        "MCP provides a standardized way to expose tools from external systems:\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ad459d0f",
      "metadata": {},
      "source": [
        "Let's simulate connecting to a Zendesk-like ticket system via MCP."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 98,
      "id": "19be1595",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\ud83d\udd0c MCP Agent with Microsoft Learn tool connection...\n",
            "Request: \n",
            "A customer is asking: \"What are the latest Azure AI Foundry features announced in January 2026?\"\n",
            "\n",
            "You MUST use the MCP tool to search for this information.\n",
            "\n",
            "\n",
            "\ud83d\udd10 Auto-approving MCP tool call: microsoft_docs_search\n",
            "\n",
            "\ud83d\udd0d Total approvals granted: 1\n",
            "   Result text length: 1101\n",
            "\n",
            "\ud83d\udcdd Agent Response:\n",
            "============================================================\n",
            "In January 2026, several notable features were announced for Azure AI Foundry:\n",
            "\n",
            "1. **Orchestration Workflow**:\n",
            "   - Now available in Microsoft Foundry (classic).\n",
            "   - The new interface streamlines integration between **Conversational Language Understanding (CLU)** and **Custom Question Answering (CQA)** projects, allowing for better orchestration of user utterances across multiple conversational applications.\n",
            "\n",
            "2. **Intent-Based Routing**:\n",
            "   - This feature directs user queries to the appropriate CLU or CQA project, enhancing response accuracy and reducing development complexity.\n",
            "\n",
            "3. **Full Azure AI Language Capabilities**:\n",
            "   - All Azure AI Language capabilities are now accessible in Microsoft Foundry (classic), offering a complete development experience.\n",
            "   - Language Studio's authoring, testing capabilities, model training, and deployment workflows are fully integrated into the Foundry platform.\n",
            "\n",
            "For more details, you can visit the official release notes: [What's new in Azure Language in Foundry Tools?](https://learn.microsoft.com/en-us/azure/ai-services/language-service/whats-new).\n",
            "\n",
            "============================================================\n"
          ]
        }
      ],
      "source": [
        "from agent_framework import ChatAgent, HostedMCPTool, ChatMessage\n",
        "\n",
        "# Recreate the MCP tool with auto-approval\n",
        "learn_mcp_tool = HostedMCPTool(\n",
        "    name=\"MicrosoftLearn\",\n",
        "    url=\"https://learn.microsoft.com/api/mcp\",\n",
        "    approval_mode=\"never_require\"  # Auto-approve MCP tool calls\n",
        ")\n",
        "\n",
        "# Create the agent with the new tool\n",
        "mcp_support_agent = ChatAgent(\n",
        "    chat_client=chat_client_mcp,\n",
        "    name=\"MCPSupportAgent\",\n",
        "    instructions=\"\"\"You are a documentation assistant agent with access to Microsoft Learn documentation via MCP. \n",
        "When asked about Azure features, you MUST use the MCP tool to search for information.\"\"\",\n",
        "    tools=[learn_mcp_tool],\n",
        ")\n",
        "\n",
        "# Test: Ask a very specific recent question that requires the MCP tool\n",
        "test_request = \"\"\"\n",
        "A customer is asking: \"What are the latest Azure AI Foundry features announced in January 2026?\"\n",
        "\n",
        "You MUST use the MCP tool to search for this information.\n",
        "\"\"\"\n",
        "\n",
        "print(\"\ud83d\udd0c MCP Agent with Microsoft Learn tool connection...\")\n",
        "print(f\"Request: {test_request}\\n\")\n",
        "\n",
        "# Run with auto-approval loop\n",
        "from agent_framework import AgentThread\n",
        "\n",
        "thread = AgentThread()\n",
        "max_approvals = 5  # Safety limit\n",
        "approval_count = 0\n",
        "\n",
        "result = await mcp_support_agent.run(test_request, thread=thread)\n",
        "\n",
        "# Handle approval requests automatically\n",
        "while approval_count < max_approvals:\n",
        "    # Check for approval requests\n",
        "    has_approval_request = False\n",
        "    approval_responses = []\n",
        "    \n",
        "    if hasattr(result, 'messages') and result.messages:\n",
        "        for msg in result.messages:\n",
        "            if hasattr(msg, 'contents'):\n",
        "                for content in msg.contents:\n",
        "                    if content.type == \"function_approval_request\":\n",
        "                        has_approval_request = True\n",
        "                        # Auto-approve by converting to approval response\n",
        "                        approval_response = content.to_function_approval_response(approved=True)\n",
        "                        tool_name = content.function_call.name if hasattr(content, 'function_call') and content.function_call else 'unknown'\n",
        "                        print(f\"\ud83d\udd10 Auto-approving MCP tool call: {tool_name}\")\n",
        "                        approval_responses.append(approval_response)\n",
        "    \n",
        "    if not has_approval_request:\n",
        "        break\n",
        "    \n",
        "    # Continue the conversation with approval responses wrapped in a message\n",
        "    approval_message = ChatMessage(role=\"tool\", contents=approval_responses)\n",
        "    result = await mcp_support_agent.run(\n",
        "        [approval_message],\n",
        "        thread=thread\n",
        "    )\n",
        "    approval_count += 1\n",
        "\n",
        "# Debug output\n",
        "print(f\"\\n\ud83d\udd0d Total approvals granted: {approval_count}\")\n",
        "print(f\"   Result text length: {len(result.text) if result.text else 0}\")\n",
        "\n",
        "print(\"\\n\ud83d\udcdd Agent Response:\")\n",
        "print(\"=\"*60)\n",
        "print(result.text if result.text else \"(empty response)\")\n",
        "print(\"\\n\" + \"=\"*60)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e530d0d1",
      "metadata": {},
      "source": [
        "# 5. V2 \u2014 Human-in-the-Loop Approval (InboxOps Safety Gate)\n",
        "\n",
        "Drafting is safe.\n",
        "\n",
        "**Sending an email is not.**\n",
        "\n",
        "InboxOps policy:\n",
        "\u2705 AI may draft responses  \n",
        "\ud83d\udd12 A human must approve before sending  \n",
        "\n",
        "So we mark the sending tool as approval-required.\n",
        "\n",
        "This creates a safety mechanism:\n",
        "- The agent can propose the action\n",
        "- The platform pauses execution\n",
        "- A human confirms or rejects\n",
        "- Only then can the workflow continue"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "479786af",
      "metadata": {},
      "source": [
        "## Approval-Required Action Tool\n",
        "\n",
        "We treat sending a reply as a sensitive business action.\n",
        "\n",
        "We set:\n",
        "\n",
        "`approval_mode=\"always_require\"`\n",
        "\n",
        "This ensures:\n",
        "- No accidental customer emails\n",
        "- No legal/compliance surprises\n",
        "- Brand safety for InboxOps"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 105,
      "id": "c9cbdcca",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u2705 approval_agent created with send_email_reply tool\n"
          ]
        }
      ],
      "source": [
        "from agent_framework import ChatMessage, Content, Role\n",
        "\n",
        "# Tool that requires human approval before sending\n",
        "@tool(approval_mode=\"always_require\", name=\"send_email_reply\", description=\"Send an email reply to the customer. Requires human approval.\")\n",
        "def send_email_reply(\n",
        "    to: Annotated[str, Field(description=\"Recipient email address\")],\n",
        "    subject: Annotated[str, Field(description=\"Email subject\")],\n",
        "    body: Annotated[str, Field(description=\"Email body content\")]\n",
        ") -> str:\n",
        "    \"\"\"Send an email reply to the customer. Requires human approval.\"\"\"\n",
        "    # In production, this would actually send the email\n",
        "    return f\"\u2705 Email sent to {to} with subject '{subject}'\"\n",
        "\n",
        "# Create agent with the approval-required tool\n",
        "approval_agent = chat_client.as_agent(\n",
        "    name=\"ApprovalSupportAgent\",\n",
        "    instructions=\"\"\"You are a customer support agent. When you finish drafting a response, \n",
        "you MUST call the send_email_reply tool to send it. Do not ask for permission - just call the tool.\n",
        "The system will automatically handle approval. Always use the tool to send your response.\"\"\",\n",
        "    tools=[lookup_customer_sla, get_incident_status, send_email_reply]\n",
        ")\n",
        "\n",
        "print(\"\u2705 approval_agent created with send_email_reply tool\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1de90248",
      "metadata": {},
      "source": [
        "## Check for Pending Approvals\n",
        "\n",
        "Approval-required calls return `user_input_requests` instead of executing."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 106,
      "id": "3e6063ae",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\ud83d\udd12 APPROVAL REQUIRED!\n",
            "  Function: send_email_reply\n",
            "  Arguments: {\"to\":\"sarah.chen@acmecorp.com\",\"subject\":\"Re: Order #12345 - Delivery Issue\",\"body\":\"Dear Sarah,\\n\\nThank you for reaching out regarding your order #12345. I apologize for the inconvenience you are experiencing with the delivery. We understand the urgency, especially with your upcoming client presentation.\\n\\nSince you are a Premium tier customer, we will prioritize this issue and will provide updates within our SLA of 4 hours. We will also check the tracking details and explore the possibility of arranging a replacement for you. \\n\\nPlease give us a moment to investigate, and we will get back to you as soon as possible with a resolution.\\n\\nThank you for your patience.\\n\\nBest regards,\\n\\n[Your Name]\\nCustomer Support Team\"}\n"
          ]
        }
      ],
      "source": [
        "# Ask the agent to handle and send a response\n",
        "prompt = f\"\"\"Handle this email and propose sending the response using the send_email_reply tool.\n",
        "The platform will automatically require human approval before execution.\n",
        "\n",
        "From: {LEGIT_EMAIL.sender}\n",
        "Subject: {LEGIT_EMAIL.subject}\n",
        "Customer ID: {LEGIT_EMAIL.customer_id}\n",
        "\n",
        "{LEGIT_EMAIL.body}\n",
        "\"\"\"\n",
        "\n",
        "result = await approval_agent.run(prompt)\n",
        "\n",
        "# Check if approval is needed\n",
        "if result.user_input_requests:\n",
        "    print(\"\ud83d\udd12 APPROVAL REQUIRED!\")\n",
        "    for user_input_needed in result.user_input_requests:\n",
        "        print(f\"  Function: {user_input_needed.function_call.name}\")\n",
        "        print(f\"  Arguments: {user_input_needed.function_call.arguments}\")\n",
        "else:\n",
        "    print(\"\u26a0\ufe0f No approval requested - agent didn't call the tool\")\n",
        "    print(result.text)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f8e80ab2",
      "metadata": {},
      "source": [
        "## Grant Approval\n",
        "\n",
        "Respond with `to_function_approval_response(True/False)`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 107,
      "id": "efa70478",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "--- Handling Approval ---\n",
            "\n",
            "\u2705 Human approved: True\n",
            "\n",
            "\ud83d\udcca Final Result:\n",
            "I have sent a response to Sarah Chen regarding her order #12345 and the delivery issue she is experiencing. If you need further assistance, feel free to let me know!\n"
          ]
        }
      ],
      "source": [
        "print(\"\\n--- Handling Approval ---\\n\")\n",
        "\n",
        "# Provide approval and continue the conversation\n",
        "if result.user_input_requests:\n",
        "    user_input_needed = result.user_input_requests[0]\n",
        "    \n",
        "    # Simulate human approval (in production, this would be interactive)\n",
        "    user_approval = True\n",
        "    print(f\"\u2705 Human approved: {user_approval}\\n\")\n",
        "    \n",
        "    # Create approval response message\n",
        "    approval_message = ChatMessage(\n",
        "        role=Role.USER,\n",
        "        contents=[user_input_needed.to_function_approval_response(user_approval)]\n",
        "    )\n",
        "    \n",
        "    # Continue with approval\n",
        "    final_result = await approval_agent.run([\n",
        "        prompt,\n",
        "        ChatMessage(role=Role.ASSISTANT, contents=[user_input_needed]),\n",
        "        approval_message\n",
        "    ])\n",
        "    print(f\"\ud83d\udcca Final Result:\\n{final_result.text}\")\n",
        "else:\n",
        "    print(\"\u274c No approval was requested in the previous cell.\")\n",
        "    print(\"   The agent needs to call the send_email_reply tool to trigger approval.\")\n",
        "    print(\"   Re-run the previous cell to try again.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3bbefd9d",
      "metadata": {},
      "source": [
        "# 6. V2.1 \u2014 Middleware (Observability for Production)\n",
        "\n",
        "InboxOps engineering asked the next obvious question:\n",
        "\n",
        "\"How do we monitor this system in production?\"\n",
        "\n",
        "They need:\n",
        "- execution timing\n",
        "- tool call logging\n",
        "- tracing / visibility for debugging\n",
        "- metrics for performance\n",
        "\n",
        "Middleware gives InboxOps **observability hooks** without rewriting agent code."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c8829240",
      "metadata": {},
      "source": [
        "## Define Middleware\n",
        "\n",
        "Middleware wraps execution with `context` and `next` function."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 108,
      "id": "eae080f2",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u2705 Middleware defined: logging_agent_middleware, logging_function_middleware\n"
          ]
        }
      ],
      "source": [
        "from typing import Callable, Awaitable\n",
        "from agent_framework import AgentRunContext, FunctionInvocationContext\n",
        "import time\n",
        "\n",
        "async def logging_agent_middleware(\n",
        "    context: AgentRunContext,\n",
        "    next: Callable[[AgentRunContext], Awaitable[None]],\n",
        ") -> None:\n",
        "    \"\"\"Log agent execution with timing.\"\"\"\n",
        "    print(f\"\ud83d\ude80 Agent starting... ({len(context.messages)} message(s))\")\n",
        "    start_time = time.time()\n",
        "    \n",
        "    await next(context)  # Continue to agent execution\n",
        "    \n",
        "    elapsed = time.time() - start_time\n",
        "    print(f\"\u2705 Agent finished in {elapsed:.2f}s\")\n",
        "\n",
        "async def logging_function_middleware(\n",
        "    context: FunctionInvocationContext,\n",
        "    next: Callable[[FunctionInvocationContext], Awaitable[None]],\n",
        ") -> None:\n",
        "    \"\"\"Log function tool calls.\"\"\"\n",
        "    print(f\"  \ud83d\udcde Calling: {context.function.name}({context.arguments})\")\n",
        "    \n",
        "    await next(context)\n",
        "    \n",
        "    print(f\"  \ud83d\udce4 Result: {context.result[:100]}...\" if len(str(context.result)) > 100 else f\"  \ud83d\udce4 Result: {context.result}\")\n",
        "\n",
        "print(\"\u2705 Middleware defined: logging_agent_middleware, logging_function_middleware\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e47e9a62",
      "metadata": {},
      "source": [
        "## Attach Middleware\n",
        "\n",
        "Pass middleware list when creating the agent."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 109,
      "id": "f92c1554",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\ud83d\ude80 Agent starting... (1 message(s))\n",
            "  \ud83d\udcde Calling: lookup_customer_sla(customer_id='CUST-7891')\n",
            "  \ud83d\udce4 Result: Customer CUST-7891: Premium tier, 4 hours response time, Free expedited replacement\n",
            "  \ud83d\udcde Calling: get_incident_status(ticket_id='TKT-2024-001')\n",
            "  \ud83d\udce4 Result: Ticket TKT-2024-001: Status=Open, Priority=High, Assigned to=Support Team, Last update=2024-01-15\n",
            "\u2705 Agent finished in 4.14s\n",
            "\n",
            "\ud83d\udcac Response: Here's the information you requested:\n",
            "\n",
            "**Customer SLA for CUST-7891:**\n",
            "- Tier: Premium\n",
            "- Response Time: 4 hours\n",
            "- Policies: Free expedited replacement\n",
            "\n",
            "**Ticket Status for TKT-2024-001:**\n",
            "- Status: Open\n",
            "- Priority: High\n",
            "- Assigned to: Support Team\n",
            "- Last Update: January 15, 2024\n",
            "\n",
            "If you have any further questions or need assistance, feel free to ask!\n"
          ]
        }
      ],
      "source": [
        "# Create agent with middleware for logging\n",
        "middleware_agent = chat_client.as_agent(\n",
        "    name=\"LoggingSupportAgent\",\n",
        "    instructions=\"You are a support agent. Look up customer information when handling requests.\",\n",
        "    tools=[lookup_customer_sla, get_incident_status],\n",
        "    middleware=[logging_agent_middleware, logging_function_middleware]\n",
        ")\n",
        "\n",
        "# Test - you'll see logs for agent and function calls\n",
        "prompt = f\"Check the SLA for customer {LEGIT_EMAIL.customer_id} and ticket status for {LEGIT_EMAIL.ticket_id}\"\n",
        "result = await middleware_agent.run(prompt)\n",
        "print(f\"\\n\ud83d\udcac Response: {result.text}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 6.2. V2.2 \u2014 Error Handling & Retry (InboxOps API Resilience)\n",
        "\n",
        "During Black Friday 2025, the InboxOps external shipping tracker API went down. Support agents started failing catastrophically, leaving 10,000 customers without order status updates.\n",
        "\n",
        "The team learned a hard lesson: **production systems need resilience**.\n",
        "\n",
        "Let's build in proper error handling:\n",
        "1. **Retry Policies** \u2014 Exponential backoff for transient failures\n",
        "2. **Timeouts** \u2014 Prevent hanging on slow APIs\n",
        "3. **Circuit Breakers** \u2014 Stop hammering a failing service\n",
        "4. **Graceful Degradation** \u2014 Provide fallback responses when tools fail\n",
        "\n",
        "## The Problem: Fragile API Calls"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import random\n",
        "from agent_framework import tool\n",
        "\n",
        "# Simulated flaky external API\n",
        "@tool\n",
        "async def check_order_status_fragile(order_id: str) -> str:\n",
        "    \"\"\"Check shipping status - but this API is unreliable!\"\"\"\n",
        "    if random.random() < 0.7:  # 70% failure rate during outage!\n",
        "        raise ConnectionError(\"Shipping API timeout - service degraded\")\n",
        "    return f\"Order {order_id}: Shipped, arriving Tuesday\"\n",
        "\n",
        "# Without retry, this will fail 70% of the time\n",
        "try:\n",
        "    result = await check_order_status_fragile(\"ORD-12345\")\n",
        "    print(f\"\u2705 Success: {result}\")\n",
        "except ConnectionError as e:\n",
        "    print(f\"\u274c Failed: {e}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Solution 1: Retry with Exponential Backoff\n",
        "\n",
        "When an API call fails, don't give up immediately. Retry a few times with increasing delays:\n",
        "- **Attempt 1**: Wait 1 second\n",
        "- **Attempt 2**: Wait 2 seconds\n",
        "- **Attempt 3**: Wait 4 seconds\n",
        "\n",
        "This gives transient issues time to resolve."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import asyncio\n",
        "from functools import wraps\n",
        "from typing import Callable, Type\n",
        "\n",
        "def retry_with_backoff(\n",
        "    max_retries: int = 3,\n",
        "    base_delay: float = 1.0,\n",
        "    backoff_factor: float = 2.0,\n",
        "    exceptions: tuple[Type[Exception], ...] = (ConnectionError, TimeoutError)\n",
        "):\n",
        "    \"\"\"Retry decorator with exponential backoff.\"\"\"\n",
        "    def decorator(func: Callable):\n",
        "        @wraps(func)\n",
        "        async def wrapper(*args, **kwargs):\n",
        "            last_exception = None\n",
        "            \n",
        "            for attempt in range(max_retries):\n",
        "                try:\n",
        "                    return await func(*args, **kwargs)\n",
        "                except exceptions as e:\n",
        "                    last_exception = e\n",
        "                    if attempt < max_retries - 1:  # Don't sleep on last attempt\n",
        "                        delay = base_delay * (backoff_factor ** attempt)\n",
        "                        print(f\"\u26a0\ufe0f  Attempt {attempt + 1} failed: {e}. Retrying in {delay}s...\")\n",
        "                        await asyncio.sleep(delay)\n",
        "                    else:\n",
        "                        print(f\"\u274c All {max_retries} attempts failed\")\n",
        "            \n",
        "            raise last_exception\n",
        "        return wrapper\n",
        "    return decorator\n",
        "\n",
        "# Apply retry logic to our fragile tool\n",
        "@tool\n",
        "@retry_with_backoff(max_retries=3, base_delay=0.5)  # Faster for demo\n",
        "async def check_order_status_resilient(order_id: str) -> str:\n",
        "    \"\"\"Check shipping status with automatic retry.\"\"\"\n",
        "    if random.random() < 0.7:  # Still 70% failure per attempt\n",
        "        raise ConnectionError(\"Shipping API timeout\")\n",
        "    return f\"Order {order_id}: Shipped, arriving Tuesday\"\n",
        "\n",
        "# Test it - should succeed after retries\n",
        "result = await check_order_status_resilient(\"ORD-12345\")\n",
        "print(f\"\\n\u2705 Final result: {result}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Solution 2: Timeouts (Don't Wait Forever)\n",
        "\n",
        "Some APIs hang indefinitely. Set timeouts to fail fast and retry."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "@tool\n",
        "async def check_inventory_slow(product_id: str) -> str:\n",
        "    \"\"\"Check inventory - sometimes this API hangs for 30+ seconds!\"\"\"\n",
        "    await asyncio.sleep(10)  # Simulated slow API\n",
        "    return f\"Product {product_id}: 42 units in stock\"\n",
        "\n",
        "# Add timeout wrapper\n",
        "async def with_timeout(coro, timeout_seconds: float):\n",
        "    \"\"\"Run coroutine with timeout.\"\"\"\n",
        "    try:\n",
        "        return await asyncio.wait_for(coro, timeout=timeout_seconds)\n",
        "    except asyncio.TimeoutError:\n",
        "        raise TimeoutError(f\"Operation exceeded {timeout_seconds}s timeout\")\n",
        "\n",
        "# Test timeout\n",
        "try:\n",
        "    result = await with_timeout(\n",
        "        check_inventory_slow(\"PROD-789\"),\n",
        "        timeout_seconds=2.0  # Only wait 2 seconds\n",
        "    )\n",
        "    print(f\"\u2705 {result}\")\n",
        "except TimeoutError as e:\n",
        "    print(f\"\u23f1\ufe0f Timeout: {e}\")\n",
        "    print(\"\ud83d\udca1 Fallback: Using cached inventory data instead\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Solution 3: Circuit Breaker (Stop Hammering Failed Services)\n",
        "\n",
        "If an API fails repeatedly, stop trying for a while. This prevents:\n",
        "- Overwhelming a struggling service\n",
        "- Wasting time on guaranteed failures\n",
        "- Cascading failures in your system\n",
        "\n",
        "**Circuit States:**\n",
        "1. **CLOSED** (normal): Requests go through\n",
        "2. **OPEN** (failed): Requests fail fast without calling API\n",
        "3. **HALF-OPEN** (testing): Try one request to see if service recovered"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from enum import Enum\n",
        "from datetime import datetime, timedelta\n",
        "\n",
        "class CircuitState(Enum):\n",
        "    CLOSED = \"closed\"  # Normal operation\n",
        "    OPEN = \"open\"      # Failing - reject requests\n",
        "    HALF_OPEN = \"half_open\"  # Testing if recovered\n",
        "\n",
        "class CircuitBreaker:\n",
        "    def __init__(self, failure_threshold: int = 5, timeout_seconds: float = 60):\n",
        "        self.failure_threshold = failure_threshold\n",
        "        self.timeout_seconds = timeout_seconds\n",
        "        self.failure_count = 0\n",
        "        self.state = CircuitState.CLOSED\n",
        "        self.opened_at: datetime | None = None\n",
        "    \n",
        "    def call(self, func: Callable):\n",
        "        \"\"\"Wrap a function with circuit breaker logic.\"\"\"\n",
        "        @wraps(func)\n",
        "        async def wrapper(*args, **kwargs):\n",
        "            # Check if circuit should transition from OPEN to HALF_OPEN\n",
        "            if self.state == CircuitState.OPEN:\n",
        "                if datetime.now() - self.opened_at > timedelta(seconds=self.timeout_seconds):\n",
        "                    print(\"\ud83d\udd04 Circuit HALF-OPEN: Testing if service recovered...\")\n",
        "                    self.state = CircuitState.HALF_OPEN\n",
        "                else:\n",
        "                    raise Exception(\"\u274c Circuit OPEN: Service is down, failing fast\")\n",
        "            \n",
        "            # Try the call\n",
        "            try:\n",
        "                result = await func(*args, **kwargs)\n",
        "                # Success - reset failure count\n",
        "                if self.state == CircuitState.HALF_OPEN:\n",
        "                    print(\"\u2705 Circuit CLOSED: Service recovered!\")\n",
        "                self.failure_count = 0\n",
        "                self.state = CircuitState.CLOSED\n",
        "                return result\n",
        "            except Exception as e:\n",
        "                self.failure_count += 1\n",
        "                print(f\"\u26a0\ufe0f  Failure {self.failure_count}/{self.failure_threshold}: {e}\")\n",
        "                \n",
        "                if self.failure_count >= self.failure_threshold:\n",
        "                    self.state = CircuitState.OPEN\n",
        "                    self.opened_at = datetime.now()\n",
        "                    print(f\"\ud83d\udd34 Circuit OPEN: Too many failures. Pausing for {self.timeout_seconds}s\")\n",
        "                raise\n",
        "        return wrapper\n",
        "    \n",
        "# Create circuit breaker for payment API\n",
        "payment_circuit = CircuitBreaker(failure_threshold=3, timeout_seconds=5)\n",
        "\n",
        "@payment_circuit.call\n",
        "async def process_refund(order_id: str) -> str:\n",
        "    \"\"\"Process refund - payment gateway is down!\"\"\"\n",
        "    raise ConnectionError(\"Payment gateway unavailable\")\n",
        "\n",
        "# Test circuit breaker behavior\n",
        "for i in range(5):\n",
        "    try:\n",
        "        await process_refund(f\"ORD-{i}\")\n",
        "    except Exception as e:\n",
        "        print(f\"Request {i+1}: {str(e)[:50]}\")\n",
        "    await asyncio.sleep(0.5)\n",
        "\n",
        "print(\"\\n\ud83d\udca1 After 3 failures, circuit opened. Requests 4-5 failed immediately.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Solution 4: Graceful Degradation (Fallback Responses)\n",
        "\n",
        "When tools fail, don't let the agent fail. Provide fallback responses."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "@tool\n",
        "@retry_with_backoff(max_retries=2, base_delay=0.5)\n",
        "async def get_order_tracking(order_id: str) -> str:\n",
        "    \"\"\"Get detailed tracking with fallback to basic info.\"\"\"\n",
        "    try:\n",
        "        # Try external tracking API\n",
        "        if random.random() < 0.9:  # 90% failure rate\n",
        "            raise ConnectionError(\"Tracking API down\")\n",
        "        return f\"Order {order_id}: Last scan at Denver hub, 2 hours ago\"\n",
        "    except ConnectionError:\n",
        "        # Fallback to basic cached data\n",
        "        print(\"\u26a0\ufe0f  Tracking API failed. Using cached basic status.\")\n",
        "        return f\"Order {order_id}: Shipped. Detailed tracking temporarily unavailable.\"\n",
        "\n",
        "# Create resilient agent with error-handling tools\n",
        "resilient_agent = chat_client.as_agent(\n",
        "    name=\"ResilientSupportAgent\",\n",
        "    instructions=\"\"\"You are InboxOps support. You have access to order tracking.\n",
        "    If tools fail or return limited data, acknowledge the limitation but still help the customer.\n",
        "    Never say 'I cannot help' - always provide what info you can.\"\"\",\n",
        "    tools=[get_order_tracking]\n",
        ")\n",
        "\n",
        "# Test with API failures\n",
        "result = await resilient_agent.run(\n",
        "    \"Where is my order ORD-99999? I'm worried it's lost.\"\n",
        ")\n",
        "print(\"\\n\ud83d\udce7 Agent Response:\")\n",
        "print(result.text)\n",
        "print(\"\\n\u2705 Agent provided helpful response despite API failure!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## \ud83c\udfaf Error Handling Summary\n",
        "\n",
        "InboxOps learned to handle failures gracefully:\n",
        "\n",
        "| Pattern | Use Case | Benefit |\n",
        "|---------|----------|----------|\n",
        "| **Retry + Backoff** | Transient network issues | Succeeds on temporary glitches |\n",
        "| **Timeouts** | Slow/hanging APIs | Fails fast, moves on |\n",
        "| **Circuit Breaker** | Sustained outages | Stops wasting time on dead services |\n",
        "| **Graceful Degradation** | Tool failures | Agent still provides value |\n",
        "\n",
        "**Production Impact:**\n",
        "- \u2705 95% fewer customer-facing errors during API issues\n",
        "- \u2705 Response times stayed under 5s even during outages\n",
        "- \u2705 Circuit breakers prevented cascading failures\n",
        "\n",
        "**Next:** Rate limiting protects InboxOps from request floods \u2192"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7568cf38",
      "metadata": {},
      "source": [
        "# 6.2. V2.3 \u2014 Rate Limiting (InboxOps Black Friday Protection)\n",
        "\n",
        "## The Problem: Email Surges Overwhelm the System\n",
        "\n",
        "**Black Friday scenario:**\n",
        "- Normal load: 1,000 emails/hour\n",
        "- Black Friday: **100,000 emails/hour** \ud83d\udd25\n",
        "\n",
        "Without rate limiting:\n",
        "- OpenAI API quota exhausted\n",
        "- $10,000+ in unexpected costs\n",
        "- System crashes\n",
        "\n",
        "## Solution: Token Bucket Rate Limiting\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9013361e",
      "metadata": {},
      "source": [
        "Let's protect InboxOps from traffic surges."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 141,
      "id": "70d19348",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\ud83d\udecd\ufe0f BLACK FRIDAY EMAIL SURGE SIMULATION\n",
            "============================================================\n",
            "Rate Limit: 3 requests per 5 seconds\n",
            "Simulating rapid-fire emails to trigger rate limiting...\n",
            "\n",
            "\ud83d\udce7 Email 1/8: Where is my order #12345?...\n",
            "   \u2705 Response: ...\n",
            "   \u23f1\ufe0f  Processed in 1.55s\n",
            "\n",
            "\ud83d\udce7 Email 2/8: I need a refund for order #67890...\n",
            "   \u2705 Response: ...\n",
            "   \u23f1\ufe0f  Processed in 1.31s\n",
            "\n",
            "\ud83d\udce7 Email 3/8: Is the sale still active?...\n",
            "   \u2705 Response: ...\n",
            "   \u23f1\ufe0f  Processed in 1.26s\n",
            "\n",
            "\ud83d\udce7 Email 4/8: My promo code isn't working...\n",
            "\u26a0\ufe0f RATE LIMIT EXCEEDED. Wait 0.9s before next request.\n",
            "   \u23f3 Waiting 0.9s...\n",
            "   \u2705 Response: ...\n",
            "   \u23f1\ufe0f  Processed in 2.28s\n",
            "\n",
            "\ud83d\udce7 Email 5/8: When will item XYZ be back in stock?...\n",
            "\u26a0\ufe0f RATE LIMIT EXCEEDED. Wait 0.2s before next request.\n",
            "   \u23f3 Waiting 0.2s...\n",
            "   \u2705 Response: ...\n",
            "   \u23f1\ufe0f  Processed in 1.66s\n",
            "\n",
            "\ud83d\udce7 Email 6/8: I can't log into my account...\n",
            "   \u2705 Response: ...\n",
            "   \u23f1\ufe0f  Processed in 2.16s\n",
            "\n",
            "\ud83d\udce7 Email 7/8: Need help with shipping address...\n",
            "   \u2705 Response: ...\n",
            "   \u23f1\ufe0f  Processed in 1.73s\n",
            "\n",
            "\ud83d\udce7 Email 8/8: Is free shipping available?...\n",
            "   \u2705 Response: ...\n",
            "   \u23f1\ufe0f  Processed in 1.35s\n",
            "\n",
            "\n",
            "============================================================\n",
            "\u2705 Rate limiting protected the system from being overwhelmed!\n",
            "\ud83d\udca1 In production, rate-limited requests would be queued or delayed.\n",
            "\ud83d\udcca Total requests in rate limiter: 3\n"
          ]
        }
      ],
      "source": [
        "import time\n",
        "import asyncio\n",
        "from typing import Callable, Awaitable\n",
        "from agent_framework import ChatAgent, AgentRunContext\n",
        "\n",
        "# Simple rate limiter using token bucket algorithm\n",
        "class RateLimiter:\n",
        "    def __init__(self, max_requests: int, time_window: float):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            max_requests: Maximum requests allowed in time window\n",
        "            time_window: Time window in seconds\n",
        "        \"\"\"\n",
        "        self.max_requests = max_requests\n",
        "        self.time_window = time_window\n",
        "        self.requests = []\n",
        "    \n",
        "    def allow_request(self) -> bool:\n",
        "        \"\"\"Check if request is allowed under rate limit\"\"\"\n",
        "        now = time.time()\n",
        "        \n",
        "        # Remove old requests outside time window\n",
        "        self.requests = [req_time for req_time in self.requests \n",
        "                        if now - req_time < self.time_window]\n",
        "        \n",
        "        # Check if under limit\n",
        "        if len(self.requests) < self.max_requests:\n",
        "            self.requests.append(now)\n",
        "            return True\n",
        "        \n",
        "        return False\n",
        "    \n",
        "    def get_wait_time(self) -> float:\n",
        "        \"\"\"Get time to wait before next request is allowed\"\"\"\n",
        "        if not self.requests:\n",
        "            return 0.0\n",
        "        \n",
        "        oldest_request = min(self.requests)\n",
        "        time_passed = time.time() - oldest_request\n",
        "        return max(0.0, self.time_window - time_passed)\n",
        "\n",
        "# Create rate limiter: 3 requests per 5 seconds (stricter for demo)\n",
        "rate_limiter = RateLimiter(max_requests=3, time_window=5.0)\n",
        "\n",
        "# Middleware function for rate limiting with proper signature\n",
        "async def rate_limit_middleware(\n",
        "    context: AgentRunContext,\n",
        "    next: Callable[[AgentRunContext], Awaitable[None]]\n",
        ") -> None:\n",
        "    \"\"\"Middleware that enforces rate limits\"\"\"\n",
        "    if not rate_limiter.allow_request():\n",
        "        wait_time = rate_limiter.get_wait_time()\n",
        "        error_msg = f\"\u26a0\ufe0f RATE LIMIT EXCEEDED. Wait {wait_time:.1f}s before next request.\"\n",
        "        print(error_msg)\n",
        "        # In production, you might queue the request or return an error\n",
        "        # For demo, we'll wait the required time\n",
        "        print(f\"   \u23f3 Waiting {wait_time:.1f}s...\")\n",
        "        await asyncio.sleep(wait_time)\n",
        "        # After waiting, allow the request\n",
        "        rate_limiter.allow_request()\n",
        "    \n",
        "    await next(context)\n",
        "\n",
        "# Create rate-limited agent\n",
        "rate_limited_agent = chat_client.as_agent(\n",
        "    name=\"RateLimitedSupportAgent\",\n",
        "    instructions=\"You are an InboxOps support agent. Answer briefly in 1-2 sentences.\",\n",
        "    middleware=[rate_limit_middleware]\n",
        ")\n",
        "\n",
        "# Simulate Black Friday email surge\n",
        "print(\"\ud83d\udecd\ufe0f BLACK FRIDAY EMAIL SURGE SIMULATION\")\n",
        "print(\"=\"*60)\n",
        "print(\"Rate Limit: 3 requests per 5 seconds\")\n",
        "print(\"Simulating rapid-fire emails to trigger rate limiting...\\n\")\n",
        "\n",
        "async def simulate_email_surge():\n",
        "    emails = [\n",
        "        \"Where is my order #12345?\",\n",
        "        \"I need a refund for order #67890\",\n",
        "        \"Is the sale still active?\",\n",
        "        \"My promo code isn't working\",\n",
        "        \"When will item XYZ be back in stock?\",\n",
        "        \"I can't log into my account\",\n",
        "        \"Need help with shipping address\",\n",
        "        \"Is free shipping available?\",\n",
        "    ]\n",
        "    \n",
        "    for i, email in enumerate(emails, 1):\n",
        "        print(f\"\ud83d\udce7 Email {i}/{len(emails)}: {email[:40]}...\")\n",
        "        start_time = time.time()\n",
        "        \n",
        "        # Don't await run_stream - it returns an async generator\n",
        "        result = rate_limited_agent.run_stream(email)\n",
        "        \n",
        "        # Consume stream\n",
        "        response = \"\"\n",
        "        async for chunk in result:\n",
        "            if hasattr(chunk, 'delta') and chunk.delta:\n",
        "                response += chunk.delta\n",
        "        \n",
        "        elapsed = time.time() - start_time\n",
        "        print(f\"   \u2705 Response: {response[:60]}...\")\n",
        "        print(f\"   \u23f1\ufe0f  Processed in {elapsed:.2f}s\\n\")\n",
        "        \n",
        "        # NO delay between requests - fire them as fast as possible to trigger rate limit!\n",
        "        # await asyncio.sleep(0.5)\n",
        "\n",
        "# Run the simulation\n",
        "await simulate_email_surge()\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"\u2705 Rate limiting protected the system from being overwhelmed!\")\n",
        "print(\"\ud83d\udca1 In production, rate-limited requests would be queued or delayed.\")\n",
        "print(f\"\ud83d\udcca Total requests in rate limiter: {len(rate_limiter.requests)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8ced2740",
      "metadata": {},
      "source": [
        "# 6.3. V2.4 \u2014 Caching (InboxOps FAQ Optimization)\n",
        "\n",
        "## The Problem: Repetitive Questions Waste API Calls\n",
        "\n",
        "InboxOps receives the same questions repeatedly:\n",
        "- \"What's your return policy?\" (asked 500 times/day)\n",
        "- \"Do you ship internationally?\" (asked 300 times/day)\n",
        "- \"How do I reset my password?\" (asked 200 times/day)\n",
        "\n",
        "**Each question costs $0.002 in API calls = $2,000/day wasted!**\n",
        "\n",
        "## Solution: Response Caching\n",
        "\n",
        "Cache responses for common questions:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2106b6d7",
      "metadata": {},
      "outputs": [],
      "source": [
        "import hashlib\n",
        "\n",
        "cache = {}\n",
        "\n",
        "def get_cached_response(message: str) -> str | None:\n",
        "    cache_key = hashlib.sha256(message.encode()).hexdigest()\n",
        "    \n",
        "    if cache_key in cache:\n",
        "        cached_item = cache[cache_key]\n",
        "        if time.time() - cached_item['timestamp'] < TTL:\n",
        "            return cached_item['response']  # Cache hit!\n",
        "    \n",
        "    return None  # Cache miss"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "40b80dad",
      "metadata": {},
      "source": [
        "Let's reduce InboxOps API costs with smart caching."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2eb74af0",
      "metadata": {},
      "outputs": [],
      "source": [
        "import hashlib\n",
        "import time\n",
        "from typing import Optional\n",
        "from agent_framework import ChatAgent, Context\n",
        "\n",
        "# Simple in-memory cache with TTL (Time To Live)\n",
        "class ResponseCache:\n",
        "    def __init__(self, ttl_seconds: int = 3600):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            ttl_seconds: Cache TTL in seconds (default: 1 hour)\n",
        "        \"\"\"\n",
        "        self.cache = {}\n",
        "        self.ttl = ttl_seconds\n",
        "        self.hits = 0\n",
        "        self.misses = 0\n",
        "    \n",
        "    def _get_cache_key(self, message: str) -> str:\n",
        "        \"\"\"Generate cache key from message\"\"\"\n",
        "        # Normalize message (lowercase, strip whitespace)\n",
        "        normalized = message.lower().strip()\n",
        "        return hashlib.sha256(normalized.encode()).hexdigest()\n",
        "    \n",
        "    def get(self, message: str) -> Optional[str]:\n",
        "        \"\"\"Get cached response if available and not expired\"\"\"\n",
        "        cache_key = self._get_cache_key(message)\n",
        "        \n",
        "        if cache_key in self.cache:\n",
        "            cached_item = self.cache[cache_key]\n",
        "            age = time.time() - cached_item['timestamp']\n",
        "            \n",
        "            if age < self.ttl:\n",
        "                self.hits += 1\n",
        "                print(f\"   \ud83d\udcb0 CACHE HIT! (age: {age:.1f}s, saved $0.002)\")\n",
        "                return cached_item['response']\n",
        "            else:\n",
        "                # Expired, remove from cache\n",
        "                del self.cache[cache_key]\n",
        "        \n",
        "        self.misses += 1\n",
        "        return None\n",
        "    \n",
        "    def set(self, message: str, response: str):\n",
        "        \"\"\"Cache a response\"\"\"\n",
        "        cache_key = self._get_cache_key(message)\n",
        "        self.cache[cache_key] = {\n",
        "            'response': response,\n",
        "            'timestamp': time.time()\n",
        "        }\n",
        "    \n",
        "    def get_stats(self) -> dict:\n",
        "        \"\"\"Get cache statistics\"\"\"\n",
        "        total = self.hits + self.misses\n",
        "        hit_rate = (self.hits / total * 100) if total > 0 else 0\n",
        "        \n",
        "        return {\n",
        "            'hits': self.hits,\n",
        "            'misses': self.misses,\n",
        "            'hit_rate': f\"{hit_rate:.1f}%\",\n",
        "            'size': len(self.cache),\n",
        "            'estimated_savings': f\"${self.hits * 0.002:.2f}\"\n",
        "        }\n",
        "\n",
        "# Create cache\n",
        "response_cache = ResponseCache(ttl_seconds=300)  # 5 minute TTL\n",
        "\n",
        "# Middleware for caching\n",
        "async def cache_middleware(messages: list, context: Context, next_fn):\n",
        "    \"\"\"Middleware that caches agent responses\"\"\"\n",
        "    if not messages:\n",
        "        return await next_fn(messages, context)\n",
        "    \n",
        "    last_message = messages[-1]\n",
        "    user_message = last_message.get('content', '') if isinstance(last_message, dict) else str(last_message)\n",
        "    \n",
        "    # Try to get cached response\n",
        "    cached_response = response_cache.get(user_message)\n",
        "    if cached_response:\n",
        "        # Return cached response without calling LLM\n",
        "        from agent_framework import ChatMessage, Role\n",
        "        return type('CachedResult', (), {\n",
        "            'output': cached_response,\n",
        "            'messages': [ChatMessage(role=Role.ASSISTANT, content=cached_response)]\n",
        "        })()\n",
        "    \n",
        "    # Cache miss - call the agent\n",
        "    result = await next_fn(messages, context)\n",
        "    \n",
        "    # Cache the response\n",
        "    if hasattr(result, 'output'):\n",
        "        response_cache.set(user_message, result.output)\n",
        "    \n",
        "    return result\n",
        "\n",
        "# Create cached agent\n",
        "cached_agent = ChatAgent(\n",
        "    name=\"CachedSupportAgent\",\n",
        "    model_client=model,\n",
        "    instructions=\"\"\"You are an InboxOps support agent. Provide concise, helpful answers to customer questions.\"\"\",\n",
        "    middleware=[cache_middleware]\n",
        ")\n",
        "\n",
        "# Test with frequently asked questions\n",
        "faq_questions = [\n",
        "    \"What is your return policy?\",\n",
        "    \"Do you ship internationally?\",\n",
        "    \"What is your return policy?\",  # Duplicate - should hit cache\n",
        "    \"How do I reset my password?\",\n",
        "    \"Do you ship internationally?\",  # Duplicate - should hit cache\n",
        "    \"What is your return policy?\",  # Duplicate - should hit cache\n",
        "]\n",
        "\n",
        "print(\"\ud83e\uddea TESTING FAQ CACHING\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "async def test_caching():\n",
        "    for i, question in enumerate(faq_questions, 1):\n",
        "        print(f\"\\n\ud83d\udce7 Question {i}: {question}\")\n",
        "        \n",
        "        result = await cached_agent.run_stream(\n",
        "            messages=[{\"role\": \"user\", \"content\": question}]\n",
        "        )\n",
        "        \n",
        "        # Consume stream\n",
        "        response = \"\"\n",
        "        async for chunk in result.stream:\n",
        "            if hasattr(chunk, 'delta') and chunk.delta:\n",
        "                response += chunk.delta\n",
        "        \n",
        "        if not response_cache.get(question):  # If wasn't cached before\n",
        "            print(f\"   \ud83d\udd04 Generated new response\")\n",
        "\n",
        "await test_caching()\n",
        "\n",
        "# Show cache statistics\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"\ud83d\udcca CACHE STATISTICS\")\n",
        "stats = response_cache.get_stats()\n",
        "for key, value in stats.items():\n",
        "    print(f\"   {key}: {value}\")\n",
        "\n",
        "print(\"\\n\u2705 Caching dramatically reduces API costs for repetitive questions!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f4ffbde4",
      "metadata": {},
      "source": [
        "# 7. V3 \u2014 Memory That Survives Beyond a Single Thread\n",
        "\n",
        "Threads remember a conversation.\n",
        "\n",
        "But InboxOps also needs persistent preferences across conversations, such as:\n",
        "- preferred language\n",
        "- preferred tone\n",
        "- customer name\n",
        "\n",
        "Example:\n",
        "A customer always wants **brief responses**.\n",
        "Or requests replies in **Hebrew**.\n",
        "Or is a VIP account.\n",
        "\n",
        "This is where a ContextProvider-based memory layer becomes powerful:\n",
        "\u2705 Extract preferences automatically  \n",
        "\u2705 Inject them as context into future calls  \n",
        "\u2705 Maintain consistent customer experience"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d89ced48",
      "metadata": {},
      "source": [
        "## Preferences Model\n",
        "\n",
        "Define what to remember."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b3468ebe",
      "metadata": {},
      "outputs": [],
      "source": [
        "class SupportPreferences(BaseModel):\n",
        "    \"\"\"User preferences for support interactions.\"\"\"\n",
        "    name: str | None = None\n",
        "    preferred_language: Literal[\"English\", \"Hebrew\", \"Spanish\"] = \"English\"\n",
        "    preferred_tone: Literal[\"formal\", \"friendly\", \"brief\"] = \"formal\"\n",
        "\n",
        "print(\"\u2705 SupportPreferences model defined\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b2fdd4af",
      "metadata": {},
      "source": [
        "## Implement ContextProvider\n",
        "\n",
        "Two methods: `invoking` (inject context before calls) and `invoked` (extract state after calls)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "082eefb0",
      "metadata": {},
      "outputs": [],
      "source": [
        "from collections.abc import MutableSequence, Sequence\n",
        "from typing import Any\n",
        "\n",
        "from agent_framework import ContextProvider, Context, ChatAgent, ChatOptions\n",
        "\n",
        "\n",
        "class SupportMemory(ContextProvider):\n",
        "    \"\"\"Memory that tracks user preferences for support interactions.\"\"\"\n",
        "    \n",
        "    def __init__(self, chat_client, preferences: SupportPreferences | None = None, **kwargs: Any):\n",
        "        \"\"\"Create the memory.\n",
        "        \n",
        "        Args:\n",
        "            chat_client: The chat client to use for extracting structured data\n",
        "            preferences: Optional initial preferences\n",
        "            **kwargs: Additional keyword arguments for deserialization\n",
        "        \"\"\"\n",
        "        self._chat_client = chat_client\n",
        "        if preferences:\n",
        "            self.preferences = preferences\n",
        "        elif kwargs:\n",
        "            self.preferences = SupportPreferences.model_validate(kwargs)\n",
        "        else:\n",
        "            self.preferences = SupportPreferences()\n",
        "    \n",
        "    async def invoked(\n",
        "        self,\n",
        "        request_messages: ChatMessage | Sequence[ChatMessage],\n",
        "        response_messages: ChatMessage | Sequence[ChatMessage] | None = None,\n",
        "        invoke_exception: Exception | None = None,\n",
        "        **kwargs: Any,\n",
        "    ) -> None:\n",
        "        \"\"\"Extract preferences from user messages after each call.\"\"\"\n",
        "        # Ensure request_messages is a list\n",
        "        messages_list = [request_messages] if isinstance(request_messages, ChatMessage) else list(request_messages)\n",
        "        \n",
        "        # Check if we have user messages\n",
        "        user_messages = [msg for msg in messages_list if msg.role.value == \"user\"]\n",
        "        \n",
        "        if user_messages:\n",
        "            try:\n",
        "                # Use the chat client to extract structured information\n",
        "                # NOTE: Use `options=` not `chat_options=`\n",
        "                result = await self._chat_client.get_response(\n",
        "                    messages=messages_list,\n",
        "                    options=ChatOptions(\n",
        "                        instructions=(\n",
        "                            \"Extract the user's name, preferred tone (formal/friendly/brief), \"\n",
        "                            \"and preferred language (English/Hebrew/Spanish) from the messages if present. \"\n",
        "                            \"If not present, return None for that field.\"\n",
        "                        ),\n",
        "                        response_format=SupportPreferences,\n",
        "                    ),\n",
        "                )\n",
        "                \n",
        "                # result.value should now be a SupportPreferences instance\n",
        "                extracted = result.value\n",
        "                \n",
        "                # Update preferences with extracted data\n",
        "                if extracted and isinstance(extracted, SupportPreferences):\n",
        "                    if self.preferences.name is None and extracted.name:\n",
        "                        self.preferences.name = extracted.name\n",
        "                        print(f\"   \ud83e\udde0 Memory updated: name = {extracted.name}\")\n",
        "                    \n",
        "                    if extracted.preferred_tone != \"formal\":  # formal is default\n",
        "                        self.preferences.preferred_tone = extracted.preferred_tone\n",
        "                        print(f\"   \ud83e\udde0 Memory updated: tone = {extracted.preferred_tone}\")\n",
        "                    \n",
        "                    if extracted.preferred_language != \"English\":  # English is default\n",
        "                        self.preferences.preferred_language = extracted.preferred_language\n",
        "                        print(f\"   \ud83e\udde0 Memory updated: language = {extracted.preferred_language}\")\n",
        "                        \n",
        "            except Exception as e:\n",
        "                print(f\"   \u26a0\ufe0f Failed to extract preferences: {e}\")\n",
        "    \n",
        "    async def invoking(self, messages: ChatMessage | MutableSequence[ChatMessage], **kwargs: Any) -> Context:\n",
        "        \"\"\"Provide preference context before each agent call.\"\"\"\n",
        "        instructions: list[str] = []\n",
        "        \n",
        "        if self.preferences.name:\n",
        "            instructions.append(f\"The user's name is {self.preferences.name}. Address them by name.\")\n",
        "        \n",
        "        instructions.append(f\"Respond in {self.preferences.preferred_language}.\")\n",
        "        instructions.append(f\"Use a {self.preferences.preferred_tone} tone.\")\n",
        "        \n",
        "        return Context(instructions=\" \".join(instructions))\n",
        "    \n",
        "    def serialize(self) -> str:\n",
        "        \"\"\"Serialize for persistence.\"\"\"\n",
        "        return self.preferences.model_dump_json()\n",
        "\n",
        "print(\"\u2705 SupportMemory ContextProvider defined\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9e2d6fd8",
      "metadata": {},
      "source": [
        "## Test Memory\n",
        "\n",
        "The agent automatically extracts and applies preferences across turns."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "417d9431",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create the memory provider using the existing chat_client\n",
        "support_memory = SupportMemory(chat_client)\n",
        "\n",
        "# Create the agent with memory\n",
        "memory_agent = ChatAgent(\n",
        "    name=\"MemorySupportAgent\",\n",
        "    instructions=\"You are a friendly support agent. Adapt your responses based on user preferences.\",\n",
        "    chat_client=chat_client,\n",
        "    context_provider=support_memory,\n",
        ")\n",
        "\n",
        "# Turn 1: User introduces themselves\n",
        "print(\"Turn 1: User introduction\")\n",
        "print(\"-\" * 50)\n",
        "result1 = await memory_agent.run(\"Hi, my name is David\")\n",
        "print(f\"Agent: {result1.text}\\n\")\n",
        "\n",
        "# Turn 2: User sets preference\n",
        "print(\"Turn 2: Setting preference\")\n",
        "print(\"-\" * 50)\n",
        "result2 = await memory_agent.run(\"Please keep responses brief and casual\")\n",
        "print(f\"Agent: {result2.text}\\n\")\n",
        "\n",
        "# Turn 3: Ask a question - memory should apply name and brief tone\n",
        "print(\"Turn 3: Question with preferences applied\")\n",
        "print(\"-\" * 50)\n",
        "result3 = await memory_agent.run(\"What's your return policy?\")\n",
        "print(f\"Agent: {result3.text}\\n\")\n",
        "\n",
        "# Check memory state - access the original support_memory object directly\n",
        "print(\"\ud83e\udde0 Memory State (tracked by ContextProvider):\")\n",
        "print(f\"   Name: {support_memory.preferences.name}\")\n",
        "print(f\"   Language: {support_memory.preferences.preferred_language}\")\n",
        "print(f\"   Tone: {support_memory.preferences.preferred_tone}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a3b8a13c",
      "metadata": {},
      "source": [
        "# Workflows: InboxOps Pipeline Automation\n",
        "\n",
        "At scale, InboxOps realized something important:\n",
        "\n",
        "**A single agent loop is not enough.**\n",
        "\n",
        "They need repeatable, testable execution paths:\n",
        "- classify \u2192 draft \u2192 review\n",
        "- routing rules (spam vs legit)\n",
        "- parallel tasks (respond + summarize)\n",
        "- human escalation loops\n",
        "\n",
        "Workflows turn agent interactions into a real operational pipeline.\n",
        "\n",
        "---\n",
        "\n",
        "### Agent vs. Workflow\n",
        "\n",
        "| AI Agent | Workflow |\n",
        "|----------|----------|\n",
        "| Single reasoning loop | Orchestrates multiple components |\n",
        "| Dynamic tool selection | Predefined execution paths |\n",
        "| Best for: focused tasks | Best for: multi-step processes |\n",
        "\n",
        "### When to Use Workflows\n",
        "\n",
        "| Pattern | Use Case |\n",
        "|---------|----------|\n",
        "| **Sequential** | Steps must run in order (classify \u2192 draft \u2192 review) |\n",
        "| **Branching** | Different paths based on conditions (spam vs. legitimate) |\n",
        "| **Parallel (Fan-out/Fan-in)** | Independent tasks that can run concurrently |\n",
        "| **Group Chat** | Iterative refinement with multiple reviewers |\n",
        "\n",
        "### Core Concepts\n",
        "\n",
        "| Concept | Description |\n",
        "|---------|-------------|\n",
        "| **Executor** | Unit of work \u2014 agent or custom logic |\n",
        "| **Edge** | Connection between executors with optional conditions |\n",
        "| **WorkflowBuilder** | Constructs the execution graph |"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9429fcad",
      "metadata": {},
      "source": [
        "# 8. Workflow Pattern #1 \u2014 Sequential Pipeline (InboxOps Assembly Line)\n",
        "\n",
        "![Sequential Workflow](images/sequential-workflow.png)\n",
        "\n",
        "InboxOps introduced a standard pipeline for every inbound email:\n",
        "\n",
        "1) Classify the email  \n",
        "2) Draft a response  \n",
        "3) Review it  \n",
        "\n",
        "This pattern is perfect when order matters.\n",
        "\n",
        "\u2705 Predictable  \n",
        "\u2705 Easy to debug  \n",
        "\u2705 Easy to measure  \n",
        "\u2705 Easy to extend"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b6274db5",
      "metadata": {},
      "source": [
        "## Core Concepts\n",
        "\n",
        "| Concept | Description |\n",
        "|---------|-------------|\n",
        "| **Executor** | Unit of work (`@executor` or class with `@handler`) |\n",
        "| **WorkflowBuilder** | Connects executors with `add_edge()` |\n",
        "| `ctx.send_message()` | Pass data to next executor |\n",
        "| `ctx.yield_output()` | Return final result |"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bc80541f",
      "metadata": {},
      "source": [
        "## Define Executors\n",
        "\n",
        "Create agent executors for classification, writing, and review."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "276a9eab",
      "metadata": {},
      "outputs": [],
      "source": [
        "from typing_extensions import Never\n",
        "from agent_framework import (\n",
        "    WorkflowBuilder, WorkflowContext, WorkflowOutputEvent,\n",
        "    Executor, executor, handler, AgentExecutor, AgentExecutorRequest, AgentExecutorResponse\n",
        ")\n",
        "\n",
        "# === CLASSIFIER AGENT ===\n",
        "classifier_agent = AgentExecutor(\n",
        "    chat_client.as_agent(\n",
        "        name=\"Classifier\",\n",
        "        instructions=\"\"\"Classify incoming emails. Return JSON with:\n",
        "- category: \"spam\", \"not_spam\", or \"uncertain\"\n",
        "- confidence: float 0-1\n",
        "- reason: brief explanation\"\"\",\n",
        "        response_format=ClassificationResult,\n",
        "    ),\n",
        "    id=\"classifier\",\n",
        ")\n",
        "\n",
        "# === DRAFT WRITER AGENT ===\n",
        "writer_agent = AgentExecutor(\n",
        "    chat_client.as_agent(\n",
        "        name=\"DraftWriter\",\n",
        "        instructions=\"\"\"Draft professional support responses. Return JSON with:\n",
        "- subject: reply subject line\n",
        "- body: reply body\n",
        "- tone: \"formal\", \"friendly\", or \"apologetic\"\n",
        "- needs_review: true if sensitive or complex\"\"\",\n",
        "        response_format=DraftResponse,\n",
        "    ),\n",
        "    id=\"writer\",\n",
        ")\n",
        "\n",
        "# === REVIEWER AGENT ===\n",
        "reviewer_agent = AgentExecutor(\n",
        "    chat_client.as_agent(\n",
        "        name=\"Reviewer\",\n",
        "        instructions=\"\"\"Review draft responses for quality. Check:\n",
        "- Professionalism and tone\n",
        "- Accuracy of information\n",
        "- Completeness\n",
        "Return approval decision with notes.\"\"\",\n",
        "    ),\n",
        "    id=\"reviewer\",\n",
        ")\n",
        "\n",
        "print(\"\u2705 Workflow agents defined: classifier, writer, reviewer\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3e3f78d8",
      "metadata": {},
      "source": [
        "## Build & Run\n",
        "\n",
        "Connect executors with `add_edge()` and execute."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "94b511c5",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Build sequential workflow\n",
        "sequential_support_workflow = (\n",
        "    WorkflowBuilder()\n",
        "    .set_start_executor(classifier_agent)\n",
        "    .add_edge(classifier_agent, writer_agent)\n",
        "    .add_edge(writer_agent, reviewer_agent)\n",
        "    .build()\n",
        ")\n",
        "\n",
        "# Run with legitimate email\n",
        "async def run_sequential_workflow():\n",
        "    email_prompt = f\"\"\"Process this support email:\n",
        "\n",
        "From: {LEGIT_EMAIL.sender}\n",
        "Subject: {LEGIT_EMAIL.subject}\n",
        "Customer ID: {LEGIT_EMAIL.customer_id}\n",
        "\n",
        "{LEGIT_EMAIL.body}\n",
        "\"\"\"\n",
        "    \n",
        "    print(\"\ud83d\udce7 Processing email through workflow: Classify \u2192 Draft \u2192 Review\\n\")\n",
        "    print(\"-\" * 60)\n",
        "    \n",
        "    request = AgentExecutorRequest(\n",
        "        messages=[ChatMessage(Role.USER, text=email_prompt)],\n",
        "        should_respond=True\n",
        "    )\n",
        "    \n",
        "    from agent_framework._workflows._events import ExecutorCompletedEvent\n",
        "    \n",
        "    async for event in sequential_support_workflow.run_stream(request):\n",
        "        if isinstance(event, ExecutorCompletedEvent) and event.data:\n",
        "            data = event.data[0] if isinstance(event.data, list) else event.data\n",
        "            if hasattr(data, 'agent_response'):\n",
        "                print(f\"\\n\u2705 [{event.executor_id}]:\")\n",
        "                print(f\"   {data.agent_response.text[:300]}...\")\n",
        "        elif isinstance(event, WorkflowOutputEvent):\n",
        "            print(f\"\\n\ud83c\udfaf FINAL OUTPUT:\")\n",
        "            if isinstance(event.data, list) and event.data:\n",
        "                final = event.data[0]\n",
        "                if hasattr(final, 'agent_response'):\n",
        "                    print(final.agent_response.text)\n",
        "\n",
        "await run_sequential_workflow()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0f37a59d",
      "metadata": {},
      "source": [
        "# 9. Workflow Pattern #2 \u2014 Branching (InboxOps Triage System)\n",
        "\n",
        "InboxOps doesn't want to treat every message the same.\n",
        "\n",
        "So they built a triage workflow:\n",
        "\n",
        "\ud83d\udeab Spam \u2192 Block and log  \n",
        "\u2705 Legitimate \u2192 Draft a response  \n",
        "\u26a0\ufe0f Uncertain \u2192 Escalate to human review  \n",
        "\n",
        "This prevents wasted effort, reduces risk, and keeps human attention focused where needed."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4cec9cf6",
      "metadata": {},
      "source": [
        "## Routing Patterns\n",
        "\n",
        "| Pattern | Use Case |\n",
        "|---------|----------|\n",
        "| **Conditional Edge** | Binary if/else |\n",
        "| **Switch-Case** | Multi-way routing |\n",
        "| **Multi-Selection** | Dynamic fan-out |"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1e60db70",
      "metadata": {},
      "source": [
        "## Define Branch Handlers\n",
        "\n",
        "Create handlers for each classification outcome."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "38082206",
      "metadata": {},
      "outputs": [],
      "source": [
        "from dataclasses import dataclass\n",
        "from uuid import uuid4\n",
        "from agent_framework import Case, Default\n",
        "\n",
        "# Internal payload for routing\n",
        "@dataclass\n",
        "class ClassifiedEmail:\n",
        "    email_id: str\n",
        "    category: str  # spam, not_spam, uncertain\n",
        "    confidence: float\n",
        "    reason: str\n",
        "    original_content: str\n",
        "\n",
        "# Shared state keys\n",
        "EMAIL_KEY = \"current_email\"\n",
        "\n",
        "# Helper to extract JSON from markdown code blocks\n",
        "def extract_json(text: str) -> str:\n",
        "    \"\"\"Extract JSON from text, stripping markdown code blocks if present.\"\"\"\n",
        "    import re\n",
        "    match = re.search(r'```(?:json)?\\s*([\\s\\S]*?)```', text)\n",
        "    if match:\n",
        "        return match.group(1).strip()\n",
        "    return text.strip()\n",
        "\n",
        "# Transform classification result to routable payload\n",
        "@executor(id=\"extract_classification\")\n",
        "async def extract_classification(response: Any, ctx: WorkflowContext[ClassifiedEmail]) -> None:\n",
        "    \"\"\"Extract classification from agent response for routing.\"\"\"\n",
        "    if isinstance(response, list):\n",
        "        response = response[0]\n",
        "    \n",
        "    # Extract JSON (handles markdown code blocks)\n",
        "    json_text = extract_json(response.agent_response.text)\n",
        "    classification = ClassificationResult.model_validate_json(json_text)\n",
        "    \n",
        "    # Get original email from shared state\n",
        "    original_content = await ctx.get_shared_state(EMAIL_KEY) or \"Unknown\"\n",
        "    \n",
        "    payload = ClassifiedEmail(\n",
        "        email_id=str(uuid4()),\n",
        "        category=classification.category,\n",
        "        confidence=classification.confidence,\n",
        "        reason=classification.reason,\n",
        "        original_content=original_content\n",
        "    )\n",
        "    await ctx.send_message(payload)\n",
        "\n",
        "# Route conditions\n",
        "def is_spam(message: Any) -> bool:\n",
        "    return isinstance(message, ClassifiedEmail) and message.category == \"spam\"\n",
        "\n",
        "def is_not_spam(message: Any) -> bool:\n",
        "    return isinstance(message, ClassifiedEmail) and message.category == \"not_spam\"\n",
        "\n",
        "def is_uncertain(message: Any) -> bool:\n",
        "    return isinstance(message, ClassifiedEmail) and message.category == \"uncertain\"\n",
        "\n",
        "# Terminal handlers\n",
        "@executor(id=\"handle_spam\")\n",
        "async def handle_spam_terminal(email: ClassifiedEmail, ctx: WorkflowContext[Never, str]) -> None:\n",
        "    \"\"\"Handle spam: block and log.\"\"\"\n",
        "    await ctx.yield_output(f\"\ud83d\udeab SPAM BLOCKED: {email.reason} (confidence: {email.confidence:.0%})\")\n",
        "\n",
        "@executor(id=\"handle_not_spam\")\n",
        "async def handle_not_spam_continue(email: ClassifiedEmail, ctx: WorkflowContext[AgentExecutorRequest]) -> None:\n",
        "    \"\"\"Handle not_spam: forward to writer.\"\"\"\n",
        "    await ctx.send_message(AgentExecutorRequest(\n",
        "        messages=[ChatMessage(Role.USER, text=f\"Draft a response to: {email.original_content}\")],\n",
        "        should_respond=True\n",
        "    ))\n",
        "\n",
        "@executor(id=\"finalize_draft\")\n",
        "async def finalize_draft(response: Any, ctx: WorkflowContext[Never, str]) -> None:\n",
        "    \"\"\"Output the final draft.\"\"\"\n",
        "    if isinstance(response, list):\n",
        "        response = response[0]\n",
        "    # Extract JSON (handles markdown code blocks)\n",
        "    json_text = extract_json(response.agent_response.text)\n",
        "    draft = DraftResponse.model_validate_json(json_text)\n",
        "    await ctx.yield_output(f\"\u2709\ufe0f DRAFT READY:\\nSubject: {draft.subject}\\n\\n{draft.body}\")\n",
        "\n",
        "@executor(id=\"handle_uncertain\")\n",
        "async def handle_uncertain_terminal(email: ClassifiedEmail, ctx: WorkflowContext[Never, str]) -> None:\n",
        "    \"\"\"Handle uncertain: flag for human review.\"\"\"\n",
        "    await ctx.yield_output(f\"\u26a0\ufe0f NEEDS HUMAN REVIEW: {email.reason} (confidence: {email.confidence:.0%})\\n\\nOriginal: {email.original_content[:200]}...\")\n",
        "\n",
        "print(\"\u2705 Branching executors defined\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "70f06000",
      "metadata": {},
      "source": [
        "## Build Switch-Case Workflow\n",
        "\n",
        "Route based on classification result."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "840d3b84",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Store email and start classification\n",
        "@executor(id=\"start_classification\")\n",
        "async def start_classification(email_text: str, ctx: WorkflowContext[AgentExecutorRequest]) -> None:\n",
        "    \"\"\"Store email and send for classification.\"\"\"\n",
        "    await ctx.set_shared_state(EMAIL_KEY, email_text)\n",
        "    await ctx.send_message(AgentExecutorRequest(\n",
        "        messages=[ChatMessage(Role.USER, text=f\"Classify this email:\\n\\n{email_text}\")],\n",
        "        should_respond=True\n",
        "    ))\n",
        "\n",
        "# Build branching workflow\n",
        "branching_workflow = (\n",
        "    WorkflowBuilder()\n",
        "    .set_start_executor(start_classification)\n",
        "    .add_edge(start_classification, classifier_agent)\n",
        "    .add_edge(classifier_agent, extract_classification)\n",
        "    # Switch-case routing\n",
        "    .add_switch_case_edge_group(\n",
        "        extract_classification,\n",
        "        [\n",
        "            Case(condition=is_spam, target=handle_spam_terminal),\n",
        "            Case(condition=is_not_spam, target=handle_not_spam_continue),\n",
        "            Default(target=handle_uncertain_terminal),  # Catches uncertain + unexpected\n",
        "        ],\n",
        "    )\n",
        "    # Continue not_spam path to draft\n",
        "    .add_edge(handle_not_spam_continue, writer_agent)\n",
        "    .add_edge(writer_agent, finalize_draft)\n",
        "    .build()\n",
        ")\n",
        "\n",
        "print(\"\u2705 Branching workflow built\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a7e6f304",
      "metadata": {},
      "source": [
        "## Test Branching\n",
        "\n",
        "Run all three email types through the workflow."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "59110839",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Test all three paths\n",
        "async def test_branching():\n",
        "    test_cases = [\n",
        "        (\"LEGITIMATE\", LEGIT_EMAIL),\n",
        "        (\"SPAM\", SPAM_EMAIL),\n",
        "        (\"AMBIGUOUS\", AMBIGUOUS_EMAIL),\n",
        "    ]\n",
        "    \n",
        "    for label, email in test_cases:\n",
        "        print(f\"\\n\ud83d\udce7 Testing {label} email...\")\n",
        "        print(\"-\" * 50)\n",
        "        \n",
        "        email_text = f\"From: {email.sender}\\nSubject: {email.subject}\\n\\n{email.body}\"\n",
        "        \n",
        "        async for event in branching_workflow.run_stream(email_text):\n",
        "            if isinstance(event, WorkflowOutputEvent):\n",
        "                print(event.data)\n",
        "\n",
        "await test_branching()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5322b48f",
      "metadata": {},
      "source": [
        "# 9.1. Workflow Pattern #2.5 \u2014 Checkpointing (InboxOps Batch Recovery)\n",
        "\n",
        "## The Problem: Processing 10,000 Emails Overnight\n",
        "\n",
        "InboxOps runs nightly batch jobs to process accumulated emails:\n",
        "- **10,000 emails** need classification and routing\n",
        "- Job takes **3 hours** to complete\n",
        "- **What if it crashes at email 7,500?**\n",
        "\n",
        "Without checkpointing:\n",
        "- \u274c Restart from beginning\n",
        "- \u274c Reprocess 7,500 emails (duplicate work, duplicate costs)\n",
        "- \u274c Delays customer responses\n",
        "\n",
        "## Solution: Workflow Checkpointing\n",
        "\n",
        "Save progress at each step so you can resume from failure point:\n",
        "\n",
        "```python\n",
        "from agent_framework.workflows import FileCheckpointStorage\n",
        "\n",
        "# Enable checkpointing\n",
        "workflow = SequentialWorkflow()\\\n",
        "    .with_checkpointing(\n",
        "        storage=FileCheckpointStorage(checkpoint_dir=\"./checkpoints\")\n",
        "    )\n",
        "\n",
        "# If workflow fails at step 3 of 5:\n",
        "# Resume from step 3 (skip steps 1-2)\n",
        "workflow.resume(checkpoint_id=\"batch_job_001\")\n",
        "```\n",
        "\n",
        "Let's add fault tolerance to InboxOps batch processing.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6ed2b992",
      "metadata": {},
      "outputs": [],
      "source": [
        "from agent_framework.workflows import SequentialWorkflow, WorkflowAgent\n",
        "from agent_framework import ChatAgent\n",
        "import json\n",
        "import os\n",
        "import time\n",
        "\n",
        "# Simulated batch email processing\n",
        "emails_batch = [\n",
        "    {\"id\": f\"EMAIL-{i:04d}\", \"subject\": f\"Customer inquiry #{i}\", \"priority\": \"normal\"}\n",
        "    for i in range(1, 21)  # 20 emails for demo (imagine 10,000 in production)\n",
        "]\n",
        "\n",
        "# Create processing agents\n",
        "classifier_agent = ChatAgent(\n",
        "    name=\"EmailClassifier\",\n",
        "    model_client=model,\n",
        "    instructions=\"Classify emails into: urgent, normal, or low priority. Return only the priority level.\"\n",
        ")\n",
        "\n",
        "router_agent = ChatAgent(\n",
        "    name=\"EmailRouter\",\n",
        "    model_client=model,\n",
        "    instructions=\"Based on email priority, route to: urgent_queue, normal_queue, or low_queue. Return only the queue name.\"\n",
        ")\n",
        "\n",
        "# Simple file-based checkpoint storage (similar to FileCheckpointStorage)\n",
        "class SimpleCheckpointStorage:\n",
        "    def __init__(self, checkpoint_dir: str = \"./checkpoints\"):\n",
        "        self.checkpoint_dir = checkpoint_dir\n",
        "        os.makedirs(checkpoint_dir, exist_ok=True)\n",
        "    \n",
        "    def save_checkpoint(self, workflow_id: str, step: int, data: dict):\n",
        "        \"\"\"Save checkpoint to file\"\"\"\n",
        "        checkpoint_file = os.path.join(self.checkpoint_dir, f\"{workflow_id}.json\")\n",
        "        checkpoint = {\n",
        "            \"workflow_id\": workflow_id,\n",
        "            \"step\": step,\n",
        "            \"timestamp\": time.time(),\n",
        "            \"data\": data\n",
        "        }\n",
        "        with open(checkpoint_file, 'w') as f:\n",
        "            json.dump(checkpoint, f, indent=2)\n",
        "        print(f\"   \ud83d\udcbe Checkpoint saved: step {step}\")\n",
        "    \n",
        "    def load_checkpoint(self, workflow_id: str) -> dict | None:\n",
        "        \"\"\"Load checkpoint from file\"\"\"\n",
        "        checkpoint_file = os.path.join(self.checkpoint_dir, f\"{workflow_id}.json\")\n",
        "        if os.path.exists(checkpoint_file):\n",
        "            with open(checkpoint_file, 'r') as f:\n",
        "                return json.load(f)\n",
        "        return None\n",
        "    \n",
        "    def clear_checkpoint(self, workflow_id: str):\n",
        "        \"\"\"Clear checkpoint after successful completion\"\"\"\n",
        "        checkpoint_file = os.path.join(self.checkpoint_dir, f\"{workflow_id}.json\")\n",
        "        if os.path.exists(checkpoint_file):\n",
        "            os.remove(checkpoint_file)\n",
        "\n",
        "# Create checkpoint storage\n",
        "checkpoint_storage = SimpleCheckpointStorage()\n",
        "workflow_id = \"email_batch_2024\"\n",
        "\n",
        "# Check for existing checkpoint\n",
        "checkpoint = checkpoint_storage.load_checkpoint(workflow_id)\n",
        "if checkpoint:\n",
        "    print(f\"\ud83d\udd04 RESUMING FROM CHECKPOINT\")\n",
        "    print(f\"   Workflow: {checkpoint['workflow_id']}\")\n",
        "    print(f\"   Last completed step: {checkpoint['step']}\")\n",
        "    print(f\"   Processed emails: {checkpoint['data']['processed_count']}\\n\")\n",
        "    start_index = checkpoint['data']['processed_count']\n",
        "else:\n",
        "    print(\"\ud83d\ude80 STARTING NEW BATCH PROCESSING\\n\")\n",
        "    start_index = 0\n",
        "\n",
        "# Process emails with checkpointing\n",
        "processed_emails = []\n",
        "\n",
        "print(f\"\ud83d\udce7 Processing {len(emails_batch)} emails (starting from email {start_index + 1})...\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "for i in range(start_index, len(emails_batch)):\n",
        "    email = emails_batch[i]\n",
        "    print(f\"\\n\ud83d\udcec Processing: {email['id']} - {email['subject']}\")\n",
        "    \n",
        "    # Classify email\n",
        "    classification = f\"priority_{email['priority']}\"  # Simplified for demo\n",
        "    print(f\"   \ud83c\udff7\ufe0f  Classified as: {classification}\")\n",
        "    \n",
        "    # Route email\n",
        "    queue = f\"{email['priority']}_queue\"\n",
        "    print(f\"   \ud83d\udcee Routed to: {queue}\")\n",
        "    \n",
        "    processed_emails.append({\n",
        "        **email,\n",
        "        \"classification\": classification,\n",
        "        \"queue\": queue,\n",
        "        \"processed_at\": time.time()\n",
        "    })\n",
        "    \n",
        "    # Save checkpoint every 5 emails\n",
        "    if (i + 1) % 5 == 0:\n",
        "        checkpoint_storage.save_checkpoint(\n",
        "            workflow_id=workflow_id,\n",
        "            step=i + 1,\n",
        "            data={\n",
        "                \"processed_count\": i + 1,\n",
        "                \"last_email_id\": email['id'],\n",
        "                \"processed_emails\": processed_emails\n",
        "            }\n",
        "        )\n",
        "    \n",
        "    # Simulate processing time\n",
        "    time.sleep(0.1)\n",
        "    \n",
        "    # Simulate failure at email 12 (only on first run)\n",
        "    if i == 11 and start_index == 0:\n",
        "        print(\"\\n\" + \"=\"*60)\n",
        "        print(\"\u274c SIMULATED SYSTEM CRASH AT EMAIL 12!\")\n",
        "        print(\"\ud83d\udcbe Checkpoint saved at email 10\")\n",
        "        print(\"\\n\ud83d\udd04 To resume, run this cell again...\")\n",
        "        print(\"=\"*60)\n",
        "        break\n",
        "else:\n",
        "    # Successfully completed\n",
        "    print(\"\\n\" + \"=\"*60)\n",
        "    print(f\"\u2705 BATCH PROCESSING COMPLETE!\")\n",
        "    print(f\"   Total processed: {len(processed_emails)} emails\")\n",
        "    print(f\"   Success rate: 100%\")\n",
        "    \n",
        "    # Clear checkpoint\n",
        "    checkpoint_storage.clear_checkpoint(workflow_id)\n",
        "    print(\"   \ud83e\uddf9 Checkpoint cleared\")\n",
        "\n",
        "# Show sample results\n",
        "if processed_emails:\n",
        "    print(\"\\n\ud83d\udcca Sample Results:\")\n",
        "    for email in processed_emails[:3]:\n",
        "        print(f\"   {email['id']}: {email['classification']} \u2192 {email['queue']}\")\n",
        "    if len(processed_emails) > 3:\n",
        "        print(f\"   ... and {len(processed_emails) - 3} more\")\n",
        "\n",
        "print(\"\\n\u2705 Checkpointing enables fault-tolerant batch processing!\")\n",
        "print(\"\ud83d\udca1 In production, use FileCheckpointStorage from agent_framework.workflows\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "09ecb767",
      "metadata": {},
      "source": [
        "# 10. Workflow Pattern #3 \u2014 Fan-Out / Fan-In (Parallelization)\n",
        "\n",
        "![Concurrent Workflow](images/concurrent-workflow.png)\n",
        "\n",
        "InboxOps had a performance and productivity challenge:\n",
        "\n",
        "For long emails, support reps want:\n",
        "\u2705 a customer-facing reply  \n",
        "\u2705 an internal summary (for ticket notes)  \n",
        "\n",
        "These tasks are independent.\n",
        "So InboxOps runs them in parallel and merges the results.\n",
        "\n",
        "This reduces total processing time and improves rep productivity."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c863e4e6",
      "metadata": {},
      "source": [
        "## Define Parallel Paths\n",
        "\n",
        "For long emails: respond AND summarize concurrently."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3d8e251d",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Summary model\n",
        "class EmailSummary(BaseModel):\n",
        "    \"\"\"Concise email summary.\"\"\"\n",
        "    key_points: list[str] = Field(description=\"Main points from the email\")\n",
        "    urgency: Literal[\"low\", \"medium\", \"high\"] = Field(description=\"Urgency level\")\n",
        "    action_required: str = Field(description=\"Primary action needed\")\n",
        "\n",
        "# Summarizer agent\n",
        "summarizer_agent = AgentExecutor(\n",
        "    chat_client.as_agent(\n",
        "        name=\"Summarizer\",\n",
        "        instructions=\"\"\"Summarize emails concisely. Return JSON with:\n",
        "- key_points: list of main points\n",
        "- urgency: low/medium/high\n",
        "- action_required: primary action needed\"\"\",\n",
        "        response_format=EmailSummary,\n",
        "    ),\n",
        "    id=\"summarizer\",\n",
        ")\n",
        "\n",
        "# Threshold for \"long\" emails\n",
        "LONG_EMAIL_THRESHOLD = 200  # characters\n",
        "\n",
        "@dataclass\n",
        "class EnrichedEmail:\n",
        "    \"\"\"Email with metadata for routing.\"\"\"\n",
        "    email_id: str\n",
        "    content: str\n",
        "    is_long: bool\n",
        "    category: str\n",
        "\n",
        "# Selection function for multi-selection routing\n",
        "def select_parallel_paths(email: EnrichedEmail, target_ids: list[str]) -> list[str]:\n",
        "    \"\"\"Select paths based on email length.\"\"\"\n",
        "    # target_ids order: [respond_path, summarize_path]\n",
        "    respond_id, summarize_id = target_ids\n",
        "    \n",
        "    if email.is_long:\n",
        "        return [respond_id, summarize_id]  # Both paths in parallel\n",
        "    else:\n",
        "        return [respond_id]  # Only respond for short emails\n",
        "\n",
        "# Executors for parallel paths\n",
        "@executor(id=\"prepare_parallel\")\n",
        "async def prepare_parallel(classified: ClassifiedEmail, ctx: WorkflowContext[EnrichedEmail]) -> None:\n",
        "    \"\"\"Prepare email for parallel processing.\"\"\"\n",
        "    enriched = EnrichedEmail(\n",
        "        email_id=classified.email_id,\n",
        "        content=classified.original_content,\n",
        "        is_long=len(classified.original_content) > LONG_EMAIL_THRESHOLD,\n",
        "        category=classified.category\n",
        "    )\n",
        "    await ctx.send_message(enriched)\n",
        "\n",
        "@executor(id=\"respond_path\")\n",
        "async def respond_path(email: EnrichedEmail, ctx: WorkflowContext[AgentExecutorRequest]) -> None:\n",
        "    \"\"\"Send to writer for response.\"\"\"\n",
        "    await ctx.send_message(AgentExecutorRequest(\n",
        "        messages=[ChatMessage(Role.USER, text=f\"Draft a response to:\\n{email.content}\")],\n",
        "        should_respond=True\n",
        "    ))\n",
        "\n",
        "@executor(id=\"summarize_path\")\n",
        "async def summarize_path(email: EnrichedEmail, ctx: WorkflowContext[AgentExecutorRequest]) -> None:\n",
        "    \"\"\"Send to summarizer.\"\"\"\n",
        "    await ctx.send_message(AgentExecutorRequest(\n",
        "        messages=[ChatMessage(Role.USER, text=f\"Summarize this email:\\n{email.content}\")],\n",
        "        should_respond=True\n",
        "    ))\n",
        "\n",
        "# Aggregator to combine parallel results\n",
        "class ParallelAggregator(Executor):\n",
        "    def __init__(self):\n",
        "        super().__init__(id=\"parallel_aggregator\")\n",
        "    \n",
        "    @handler\n",
        "    async def aggregate(self, results: list[Any], ctx: WorkflowContext[Never, str]) -> None:\n",
        "        \"\"\"Combine response and summary.\"\"\"\n",
        "        output_parts = []\n",
        "        \n",
        "        for result in results:\n",
        "            if isinstance(result, AgentExecutorResponse):\n",
        "                try:\n",
        "                    draft = DraftResponse.model_validate_json(result.agent_response.text)\n",
        "                    output_parts.append(f\"\ud83d\udce7 DRAFT RESPONSE:\\nSubject: {draft.subject}\\n{draft.body}\")\n",
        "                except:\n",
        "                    try:\n",
        "                        summary = EmailSummary.model_validate_json(result.agent_response.text)\n",
        "                        points = \"\\n\".join(f\"  \u2022 {p}\" for p in summary.key_points)\n",
        "                        output_parts.append(f\"\ud83d\udccb SUMMARY:\\n{points}\\nUrgency: {summary.urgency}\\nAction: {summary.action_required}\")\n",
        "                    except:\n",
        "                        output_parts.append(f\"Result: {result.agent_response.text[:200]}...\")\n",
        "        \n",
        "        await ctx.yield_output(\"\\n\\n\" + \"=\"*40 + \"\\n\\n\".join(output_parts))\n",
        "\n",
        "aggregator = ParallelAggregator()\n",
        "\n",
        "print(\"\u2705 Parallel processing executors defined\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f19ef984",
      "metadata": {},
      "source": [
        "## Build Fan-Out/Fan-In Workflow\n",
        "\n",
        "Short emails \u2192 respond only. Long emails \u2192 respond + summarize in parallel."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1e887adc",
      "metadata": {},
      "outputs": [],
      "source": [
        "from agent_framework import WorkflowBuilder\n",
        "from agent_framework._workflows._events import ExecutorCompletedEvent\n",
        "from datetime import datetime\n",
        "\n",
        "# Constants\n",
        "LONG_EMAIL_THRESHOLD = 200  # Characters\n",
        "\n",
        "# Start executor - entry point stores email and passes it forward\n",
        "@executor(id=\"fanout_start\")\n",
        "async def fanout_start(email_text: str, ctx: WorkflowContext[str]) -> None:\n",
        "    \"\"\"Entry point: store email length, forward email text.\"\"\"\n",
        "    # Store email length in shared state for selection\n",
        "    await ctx.set_shared_state(\"email_length\", len(email_text))\n",
        "    # Store workflow start time\n",
        "    await ctx.set_shared_state(\"workflow_start_time\", time.time())\n",
        "    await ctx.send_message(email_text)\n",
        "\n",
        "# Selection function that uses shared state\n",
        "def fanout_select_paths(email_text: str, target_ids: list[str]) -> list[str]:\n",
        "    \"\"\"Select paths based on email length (stored in text).\"\"\"\n",
        "    # The email_text is still the raw string at this point\n",
        "    if len(email_text) > LONG_EMAIL_THRESHOLD:\n",
        "        return target_ids  # Both paths for long emails\n",
        "    return [target_ids[0]]  # Only response path for short emails\n",
        "\n",
        "# Response path preparer with timing\n",
        "@executor(id=\"fanout_respond_prep\")\n",
        "async def fanout_respond_prep(email_text: str, ctx: WorkflowContext[AgentExecutorRequest]) -> None:\n",
        "    \"\"\"Prepare email for writer agent.\"\"\"\n",
        "    workflow_start = await ctx.get_shared_state(\"workflow_start_time\")\n",
        "    start_time = time.time()\n",
        "    elapsed = start_time - workflow_start\n",
        "    print(f\"   \u23f1\ufe0f  [+{elapsed:.2f}s] \ud83d\udcdd RESPONSE PATH started\")\n",
        "    \n",
        "    await ctx.set_shared_state(\"response_start_time\", start_time)\n",
        "    await ctx.send_message(AgentExecutorRequest(\n",
        "        messages=[ChatMessage(Role.USER, text=f\"Draft a response to:\\n{email_text}\")],\n",
        "        should_respond=True\n",
        "    ))\n",
        "\n",
        "# Summary path preparer with timing\n",
        "@executor(id=\"fanout_summarize_prep\")\n",
        "async def fanout_summarize_prep(email_text: str, ctx: WorkflowContext[AgentExecutorRequest]) -> None:\n",
        "    \"\"\"Prepare email for summarizer agent.\"\"\"\n",
        "    workflow_start = await ctx.get_shared_state(\"workflow_start_time\")\n",
        "    start_time = time.time()\n",
        "    elapsed = start_time - workflow_start\n",
        "    print(f\"   \u23f1\ufe0f  [+{elapsed:.2f}s] \ud83d\udccb SUMMARY PATH started\")\n",
        "    \n",
        "    await ctx.set_shared_state(\"summary_start_time\", start_time)\n",
        "    await ctx.send_message(AgentExecutorRequest(\n",
        "        messages=[ChatMessage(Role.USER, text=f\"Summarize this email:\\n{email_text}\")],\n",
        "        should_respond=True\n",
        "    ))\n",
        "\n",
        "# Capture completion time immediately after writer finishes\n",
        "@executor(id=\"capture_writer_completion\")\n",
        "async def capture_writer_completion(result: Any, ctx: WorkflowContext[Any]) -> None:\n",
        "    \"\"\"Capture writer completion time.\"\"\"\n",
        "    workflow_start = await ctx.get_shared_state(\"workflow_start_time\")\n",
        "    response_start = await ctx.get_shared_state(\"response_start_time\")\n",
        "    end_time = time.time()\n",
        "    \n",
        "    elapsed_from_start = end_time - workflow_start\n",
        "    duration = end_time - response_start\n",
        "    print(f\"   \u23f1\ufe0f  [+{elapsed_from_start:.2f}s] \u2705 RESPONSE PATH completed ({duration:.2f}s)\")\n",
        "    \n",
        "    await ctx.set_shared_state(\"response_end_time\", end_time)\n",
        "    await ctx.send_message(result)\n",
        "\n",
        "# Capture completion time immediately after summarizer finishes\n",
        "@executor(id=\"capture_summarizer_completion\")\n",
        "async def capture_summarizer_completion(result: Any, ctx: WorkflowContext[Any]) -> None:\n",
        "    \"\"\"Capture summarizer completion time.\"\"\"\n",
        "    workflow_start = await ctx.get_shared_state(\"workflow_start_time\")\n",
        "    summary_start = await ctx.get_shared_state(\"summary_start_time\")\n",
        "    end_time = time.time()\n",
        "    \n",
        "    elapsed_from_start = end_time - workflow_start\n",
        "    duration = end_time - summary_start\n",
        "    print(f\"   \u23f1\ufe0f  [+{elapsed_from_start:.2f}s] \u2705 SUMMARY PATH completed ({duration:.2f}s)\")\n",
        "    \n",
        "    await ctx.set_shared_state(\"summary_end_time\", end_time)\n",
        "    await ctx.send_message(result)\n",
        "\n",
        "# Aggregator - combines results from parallel paths with timing\n",
        "@executor(id=\"fanout_aggregator\")\n",
        "async def fanout_aggregator(results: list[Any], ctx: WorkflowContext[Never, str]) -> None:\n",
        "    \"\"\"Combine response and summary results with timing information.\"\"\"\n",
        "    response_start = await ctx.get_shared_state(\"response_start_time\")\n",
        "    summary_start = await ctx.get_shared_state(\"summary_start_time\")\n",
        "    response_end = await ctx.get_shared_state(\"response_end_time\")\n",
        "    summary_end = await ctx.get_shared_state(\"summary_end_time\")\n",
        "    \n",
        "    output_parts = []\n",
        "    response_time = None\n",
        "    summary_time = None\n",
        "    \n",
        "    # Calculate durations from stored times\n",
        "    if response_start and response_end:\n",
        "        response_time = response_end - response_start\n",
        "    if summary_start and summary_end:\n",
        "        summary_time = summary_end - summary_start\n",
        "    \n",
        "    for result in results:\n",
        "        if isinstance(result, AgentExecutorResponse):\n",
        "            try:\n",
        "                draft = DraftResponse.model_validate_json(extract_json(result.agent_response.text))\n",
        "                output_parts.append(\n",
        "                    f\"\ud83d\udcec RESPONSE (completed in {response_time:.2f}s):\\n\"\n",
        "                    f\"Subject: {draft.subject}\\n{draft.body}\"\n",
        "                )\n",
        "            except:\n",
        "                try:\n",
        "                    summary = EmailSummary.model_validate_json(extract_json(result.agent_response.text))\n",
        "                    points = \"\\n\".join(f\"  \u2022 {p}\" for p in summary.key_points)\n",
        "                    output_parts.append(\n",
        "                        f\"\ud83d\udccb SUMMARY (completed in {summary_time:.2f}s):\\n\"\n",
        "                        f\"{points}\\n\"\n",
        "                        f\"Urgency: {summary.urgency}\\n\"\n",
        "                        f\"Action: {summary.action_required}\"\n",
        "                    )\n",
        "                except:\n",
        "                    output_parts.append(f\"Result: {result.agent_response.text[:200]}...\")\n",
        "    \n",
        "    # Calculate overlap to show parallelization\n",
        "    if response_time and summary_time:\n",
        "        total_sequential = response_time + summary_time\n",
        "        total_parallel = max(response_time, summary_time)\n",
        "        time_saved = total_sequential - total_parallel\n",
        "        output_parts.append(\n",
        "            f\"\\n\u26a1 PARALLEL EXECUTION BENEFIT:\\n\"\n",
        "            f\"   Sequential time: {total_sequential:.2f}s\\n\"\n",
        "            f\"   Parallel time: {total_parallel:.2f}s\\n\"\n",
        "            f\"   Time saved: {time_saved:.2f}s ({time_saved/total_sequential*100:.1f}%)\"\n",
        "        )\n",
        "    \n",
        "    await ctx.yield_output(\"\\n\\n\" + \"=\"*50 + \"\\n\\n\".join(output_parts))\n",
        "\n",
        "# Build the fan-out workflow\n",
        "# Pattern: start -> [fanout to preparers] -> [agents] -> [capture timing] -> aggregator\n",
        "fanout_workflow = (\n",
        "    WorkflowBuilder()\n",
        "    .set_start_executor(fanout_start)\n",
        "    # Fan-out from start directly to path preparers based on email length\n",
        "    .add_multi_selection_edge_group(\n",
        "        fanout_start,\n",
        "        targets=[fanout_respond_prep, fanout_summarize_prep],\n",
        "        selection_func=fanout_select_paths,\n",
        "    )\n",
        "    # Each preparer sends to its agent\n",
        "    .add_edge(fanout_respond_prep, writer_agent)\n",
        "    .add_edge(fanout_summarize_prep, summarizer_agent)\n",
        "    # Capture completion times immediately after each agent\n",
        "    .add_edge(writer_agent, capture_writer_completion)\n",
        "    .add_edge(summarizer_agent, capture_summarizer_completion)\n",
        "    # Fan-in: collect all results\n",
        "    .add_fan_in_edges([capture_writer_completion, capture_summarizer_completion], fanout_aggregator)\n",
        "    .build()\n",
        ")\n",
        "\n",
        "print(\"\u2705 Fan-out/fan-in workflow built\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3b962d58",
      "metadata": {},
      "source": [
        "## Test Parallel Execution\n",
        "\n",
        "Long emails trigger both response and summary paths concurrently."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d7492286",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Test with long legitimate email\n",
        "async def test_fanout():\n",
        "    email_text = f\"From: {LEGIT_EMAIL.sender}\\nSubject: {LEGIT_EMAIL.subject}\\n\\n{LEGIT_EMAIL.body}\"\n",
        "    \n",
        "    print(f\"\ud83d\udce7 Testing LONG email ({len(email_text)} chars > {LONG_EMAIL_THRESHOLD} threshold)\")\n",
        "    print(\"Expected: Response AND Summary in parallel\\n\")\n",
        "    print(\"-\" * 60)\n",
        "    \n",
        "    async for event in fanout_workflow.run_stream(email_text):\n",
        "        if isinstance(event, WorkflowOutputEvent):\n",
        "            print(event.data)\n",
        "\n",
        "await test_fanout()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d85a7439",
      "metadata": {},
      "source": [
        "# 11. Workflow Pattern #4 \u2014 Group Chat (InboxOps Review Committee)\n",
        "\n",
        "![Group Chat Pattern](images/group-chat.png)\n",
        "\n",
        "InboxOps Enterprise customers have strict requirements.\n",
        "\n",
        "Before sending a response, the draft must pass:\n",
        "1) Security review (PII / compliance)\n",
        "2) Accuracy review (promises and timelines)\n",
        "3) Tone review (final editor)\n",
        "\n",
        "A Group Chat pattern allows:\n",
        "- shared context across reviewers\n",
        "- structured collaboration\n",
        "- a \"final editor\" agent that ships the final result"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "38398cec",
      "metadata": {},
      "source": [
        "## Key Differences\n",
        "\n",
        "| Pattern | Coordination | Use Case |\n",
        "|---------|--------------|----------|\n",
        "| **Concurrent** | No coordination | Independent parallel tasks |\n",
        "| **Group Chat** | Orchestrator selects speakers | Iterative refinement, shared context |\n",
        "| **Magentic** | Manager with dynamic planning | Complex open-ended tasks |"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1105e4d2",
      "metadata": {},
      "source": [
        "## Define Specialists\n",
        "\n",
        "Create agents with distinct review roles. All agents will see the shared conversation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "74b41c3e",
      "metadata": {},
      "outputs": [],
      "source": [
        "from agent_framework import GroupChatBuilder, GroupChatState, ConcurrentBuilder, MagenticBuilder\n",
        "\n",
        "# Three specialized reviewers - order matters! Last one produces final output.\n",
        "\n",
        "# 1st: Security reviewer - identifies security/compliance issues\n",
        "security_reviewer = ChatAgent(\n",
        "    name=\"SecurityReviewer\",\n",
        "    description=\"Security and compliance specialist - reviews first\",\n",
        "    instructions=\"\"\"You are the FIRST reviewer. Analyze the support response for:\n",
        "- Data exposure risks (customer IDs, case numbers that shouldn't be in emails)\n",
        "- PII handling concerns (names, order details)\n",
        "- Policy compliance issues\n",
        "\n",
        "Be concise. List only the security issues you find. Do NOT rewrite the email - just identify problems for later reviewers to address.\"\"\",\n",
        "    chat_client=chat_client,\n",
        ")\n",
        "\n",
        "# 2nd: Accuracy reviewer - checks facts and promises\n",
        "accuracy_reviewer = ChatAgent(\n",
        "    name=\"AccuracyReviewer\", \n",
        "    description=\"Factual accuracy specialist - reviews second\",\n",
        "    instructions=\"\"\"You are the SECOND reviewer. Analyze the support response for:\n",
        "- Unrealistic promises or timelines\n",
        "- Unverifiable claims\n",
        "- Compensation appropriateness\n",
        "\n",
        "Consider the security feedback from the previous reviewer. Be concise. List only the accuracy issues. Do NOT rewrite the email - just identify problems for the final reviewer to address.\"\"\",\n",
        "    chat_client=chat_client,\n",
        ")\n",
        "\n",
        "# 3rd: Tone reviewer - applies all feedback and produces final email\n",
        "tone_reviewer = ChatAgent(\n",
        "    name=\"ToneReviewer\",\n",
        "    description=\"Tone specialist and final editor - produces revised email\",\n",
        "    instructions=\"\"\"You are the FINAL reviewer. Your job is to:\n",
        "1. Consider ALL feedback from SecurityReviewer and AccuracyReviewer\n",
        "2. Review the tone and empathy of the original email\n",
        "3. **PRODUCE A FINAL REVISED EMAIL** that:\n",
        "   - Addresses security concerns (remove/mask sensitive identifiers if needed)\n",
        "   - Fixes accuracy issues (realistic timelines, appropriate promises)\n",
        "   - Maintains professional, empathetic tone\n",
        "   - Is ready to send to the customer\n",
        "\n",
        "End your response with the complete revised email in a clear format.\"\"\",\n",
        "    chat_client=chat_client,\n",
        ")\n",
        "\n",
        "print(\"\u2705 Three specialist reviewers defined:\")\n",
        "print(\"   1. SecurityReviewer - identifies security issues\")\n",
        "print(\"   2. AccuracyReviewer - checks facts and promises\")  \n",
        "print(\"   3. ToneReviewer - applies all feedback and produces FINAL email\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "27452e67",
      "metadata": {},
      "source": [
        "## Build Group Chat with Round-Robin\n",
        "\n",
        "Simple selection: each reviewer speaks in turn."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c4ab3019",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Sample draft response to review\n",
        "draft_to_review = \"\"\"\n",
        "Subject: Re: Order #12345 - Delivery Issue\n",
        "\n",
        "Dear Sarah,\n",
        "\n",
        "I'm so sorry to hear about the missing package! This must be incredibly frustrating.\n",
        "\n",
        "I've located your order and can confirm it was marked as delivered on Monday. Here's what I'll do:\n",
        "\n",
        "1. I've opened an investigation with our shipping partner (Case #INV-789)\n",
        "2. As a Premium customer, I'm expediting a replacement shipment TODAY\n",
        "3. The replacement will arrive by Thursday, well before your Friday presentation\n",
        "\n",
        "Your account has also been credited $50 for the inconvenience.\n",
        "\n",
        "If you need anything else, reply directly to this email - I'm here to help!\n",
        "\n",
        "Best regards,\n",
        "Support Team\n",
        "\"\"\"\n",
        "\n",
        "# Round-robin selector: each reviewer speaks in order\n",
        "def round_robin_selector(state: GroupChatState) -> str:\n",
        "    \"\"\"Pick the next speaker based on round index.\"\"\"\n",
        "    participants = list(state.participants.keys())\n",
        "    return participants[state.current_round % len(participants)]\n",
        "\n",
        "# Build group chat with round-robin selection\n",
        "# ORDER MATTERS: Security \u2192 Accuracy \u2192 Tone (final editor)\n",
        "review_group_chat = (\n",
        "    GroupChatBuilder()\n",
        "    .with_orchestrator(selection_func=round_robin_selector, orchestrator_name=\"RoundRobinOrchestrator\")\n",
        "    .participants([security_reviewer, accuracy_reviewer, tone_reviewer])  # Order: Security \u2192 Accuracy \u2192 Tone\n",
        "    .with_termination_condition(lambda msgs: len([m for m in msgs if m.role.value == \"assistant\"]) >= 3)\n",
        "    .build()\n",
        ")\n",
        "\n",
        "print(\"\u2705 Group chat built with round-robin selection\")\n",
        "print(\"   Order: SecurityReviewer \u2192 AccuracyReviewer \u2192 ToneReviewer (final)\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2d7588de",
      "metadata": {},
      "source": [
        "## Test Round-Robin Group Chat\n",
        "\n",
        "Each reviewer analyzes the draft in turn, building on previous insights."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4794a908",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Run the group chat with round-robin selection\n",
        "from agent_framework._workflows._events import AgentRunUpdateEvent\n",
        "\n",
        "async def test_round_robin_group_chat():\n",
        "    print(\"\ud83d\udcdd DRAFT TO REVIEW:\")\n",
        "    print(draft_to_review)\n",
        "    print(\"-\" * 60)\n",
        "    print(\"\\n\ud83d\udd04 ROUND-ROBIN GROUP CHAT (each reviewer speaks in turn):\\n\")\n",
        "    \n",
        "    last_executor_id: str | None = None\n",
        "    agent_order = []\n",
        "    \n",
        "    async for event in review_group_chat.run_stream(f\"Review this support response:\\n{draft_to_review}\"):\n",
        "        if isinstance(event, AgentRunUpdateEvent):\n",
        "            eid = event.executor_id\n",
        "            if eid != last_executor_id:\n",
        "                if last_executor_id is not None:\n",
        "                    print(\"\\n\")\n",
        "                agent_order.append(eid)\n",
        "                print(f\"\\n\ud83e\udd16 [{eid}] (Turn #{len(agent_order)}):\", end=\" \", flush=True)\n",
        "                last_executor_id = eid\n",
        "            print(event.data, end=\"\", flush=True)\n",
        "        \n",
        "        elif isinstance(event, WorkflowOutputEvent):\n",
        "            print(\"\\n\\n\" + \"=\" * 60)\n",
        "            print(f\"\ud83d\udcca EXECUTION ORDER: {' \u2192 '.join(agent_order)}\")\n",
        "            print(\"=\" * 60)\n",
        "\n",
        "await test_round_robin_group_chat()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5350b545",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Agent-based orchestrator for intelligent speaker selection\n",
        "from typing import cast\n",
        "from agent_framework._workflows._events import AgentRunUpdateEvent, WorkflowOutputEvent\n",
        "from agent_framework._types import ChatMessage\n",
        "\n",
        "orchestrator_agent = ChatAgent(\n",
        "    name=\"ReviewOrchestrator\",\n",
        "    description=\"Coordinates multi-agent review process\",\n",
        "    instructions=f\"\"\"You coordinate a team reviewing this support response:\n",
        "\n",
        "{draft_to_review}\n",
        "\n",
        "YOUR TEAM:\n",
        "- SecurityReviewer: Identifies security/PII issues (reviews first)\n",
        "- AccuracyReviewer: Checks facts and promises (reviews second)\n",
        "- ToneReviewer: Final editor who produces the revised email (reviews last)\n",
        "\n",
        "YOUR PROCESS:\n",
        "1. Start with SecurityReviewer to check data safety and PII\n",
        "2. Then AccuracyReviewer to verify claims and timelines\n",
        "3. **Finally, ToneReviewer to produce the FINAL REVISED EMAIL** incorporating all feedback\n",
        "4. If needed, you may ask follow-up questions to any reviewer\n",
        "5. End when ToneReviewer delivers the complete revised email\n",
        "\n",
        "Select speakers intelligently. CRITICAL: ToneReviewer must go last and produce the final email.\"\"\",\n",
        "    chat_client=chat_client,\n",
        ")\n",
        "\n",
        "# Build group chat with agent-based orchestration\n",
        "# ORDER: Security \u2192 Accuracy \u2192 Tone (final editor)\n",
        "intelligent_review_chat = (\n",
        "    GroupChatBuilder()\n",
        "    .with_orchestrator(agent=orchestrator_agent)\n",
        "    .participants([security_reviewer, accuracy_reviewer, tone_reviewer])\n",
        "    .with_termination_condition(lambda msgs: len([m for m in msgs if m.role.value == \"assistant\"]) >= 5)\n",
        "    .build()\n",
        ")\n",
        "\n",
        "# Run with detailed logging\n",
        "async def test_agent_orchestrated_group_chat():\n",
        "    print(\"\ud83d\udcdd DRAFT TO REVIEW:\")\n",
        "    print(draft_to_review)\n",
        "    print(\"-\" * 60)\n",
        "    print(\"\\n\ud83e\udde0 AGENT-ORCHESTRATED GROUP CHAT (intelligent speaker selection):\\n\")\n",
        "    \n",
        "    last_executor_id: str | None = None\n",
        "    agent_calls: dict[str, int] = {}\n",
        "    \n",
        "    async for event in intelligent_review_chat.run_stream(\"Review this support response. Security and Accuracy reviewers identify issues, then ToneReviewer produces the final revised email.\"):\n",
        "        if isinstance(event, AgentRunUpdateEvent):\n",
        "            eid = event.executor_id\n",
        "            if eid != last_executor_id:\n",
        "                if last_executor_id is not None:\n",
        "                    print(\"\\n\")\n",
        "                agent_calls[eid] = agent_calls.get(eid, 0) + 1\n",
        "                print(f\"\\n\ud83e\udd16 [{eid}] (Call #{agent_calls[eid]}):\", end=\" \", flush=True)\n",
        "                last_executor_id = eid\n",
        "            print(event.data, end=\"\", flush=True)\n",
        "        \n",
        "        elif isinstance(event, WorkflowOutputEvent):\n",
        "            output_messages = cast(list[ChatMessage], event.data)\n",
        "            \n",
        "            print(\"\\n\\n\" + \"=\" * 60)\n",
        "            print(\"\ud83d\udcca EXECUTION SUMMARY\")\n",
        "            print(\"=\" * 60)\n",
        "            print(f\"   Total calls: {sum(agent_calls.values())}\")\n",
        "            print(\"\\n   Calls per agent:\")\n",
        "            for agent, count in sorted(agent_calls.items()):\n",
        "                print(f\"      {agent}: {count} call(s)\")\n",
        "            \n",
        "            print(\"\\n   \ud83d\udca1 The orchestrator dynamically selected speakers\")\n",
        "            print(\"      based on what was needed at each step\")\n",
        "            \n",
        "            print(\"\\n\" + \"=\" * 60)\n",
        "            print(\"\ud83d\udce7 FINAL REVISED EMAIL (from ToneReviewer)\")\n",
        "            print(\"=\" * 60)\n",
        "            for msg in reversed(output_messages):\n",
        "                if msg.role.value == \"assistant\" and \"ToneReviewer\" in str(msg):\n",
        "                    print(msg.text)\n",
        "                    break\n",
        "\n",
        "await test_agent_orchestrated_group_chat()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fff4e052",
      "metadata": {},
      "source": [
        "# 12. Workflow Pattern #5 \u2014 Magentic Orchestration (Dynamic Planning)\n",
        "\n",
        "![Magentic Pattern](images/magentic-workflow.png)\n",
        "\n",
        "InboxOps eventually expanded beyond emails.\n",
        "\n",
        "They wanted an AI system that can:\n",
        "- research patterns in customer complaints\n",
        "- identify recurring issues\n",
        "- propose operational improvements\n",
        "- generate executive summaries\n",
        "\n",
        "That's not a fixed pipeline anymore.\n",
        "\n",
        "Magentic orchestration introduces a **manager agent** that:\n",
        "\u2705 plans dynamically  \n",
        "\u2705 delegates to specialists  \n",
        "\u2705 iterates until the task is complete  \n",
        "\n",
        "This is the most powerful orchestration mode for open-ended problems."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "19b0d883",
      "metadata": {},
      "source": [
        "## Use Case: InboxOps Weekly Support Intelligence Report\n",
        "\n",
        "A complex task requiring:\n",
        "1. **Research Agent** - Gather complaint patterns and data\n",
        "2. **Analyst Agent** - Process and analyze the data\n",
        "3. **Manager** - Dynamic planning and synthesis\n",
        "\n",
        "The manager autonomously decides which agent to call and when based on progress."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9f64fd4a",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Magentic Orchestration: Research + Analysis workflow\n",
        "import json\n",
        "from typing import cast\n",
        "from agent_framework import (\n",
        "    AgentRunUpdateEvent,\n",
        "    MagenticOrchestratorEvent,\n",
        "    MagenticProgressLedger,\n",
        ")\n",
        "\n",
        "# Research Agent - gathers data and patterns from support tickets\n",
        "# Note: In production, this would connect to your ticketing system\n",
        "researcher_agent = ChatAgent(\n",
        "    name=\"ResearcherAgent\",\n",
        "    description=\"Specialist in research and information gathering about support patterns and customer complaints\",\n",
        "    instructions=\"\"\"You are an InboxOps Support Research Specialist. Your job is to:\n",
        "- Gather information about customer complaint patterns\n",
        "- Identify recurring issues and trends\n",
        "- Provide realistic example data based on common e-commerce support scenarios\n",
        "\n",
        "When asked about support data, provide realistic example data for categories like:\n",
        "shipping issues, refund requests, product defects, billing disputes, account access.\n",
        "Be concise and factual. Format data clearly for analysis.\"\"\",\n",
        "    chat_client=chat_client,\n",
        ")\n",
        "\n",
        "# Analyst Agent - processes and analyzes data\n",
        "# Note: In production, add HostedCodeInterpreterTool for real code execution\n",
        "analyst_agent = ChatAgent(\n",
        "    name=\"AnalystAgent\",\n",
        "    description=\"Data analyst who processes support data and creates operational insights\",\n",
        "    instructions=\"\"\"You are an InboxOps Data Analyst. Your job is to:\n",
        "- Process and analyze support ticket data\n",
        "- Calculate metrics (volume trends, resolution times, escalation rates)\n",
        "- Create clear tables and visualizations descriptions\n",
        "- Identify operational improvement opportunities\n",
        "\n",
        "Show your calculations step by step. Format results in clear tables.\"\"\",\n",
        "    chat_client=chat_client,\n",
        ")\n",
        "\n",
        "# Manager Agent - orchestrates the research workflow\n",
        "manager_agent = ChatAgent(\n",
        "    name=\"ResearchManager\",\n",
        "    description=\"Orchestrator that coordinates support intelligence workflows\",\n",
        "    instructions=\"\"\"You manage an InboxOps research team to complete support intelligence reports.\n",
        "\n",
        "YOUR TEAM:\n",
        "- ResearcherAgent: Gathers information about support patterns and customer complaints\n",
        "- AnalystAgent: Processes data, performs calculations, creates operational insights\n",
        "\n",
        "YOUR PROCESS:\n",
        "1. Break down the intelligence request into subtasks\n",
        "2. Delegate to ResearcherAgent to gather relevant support data\n",
        "3. Delegate to AnalystAgent to process and analyze the data\n",
        "4. Continue iterating until you have comprehensive insights\n",
        "5. Synthesize all findings into a final report\n",
        "\n",
        "You dynamically decide who to call based on what's needed. You may call agents multiple times.\"\"\",\n",
        "    chat_client=chat_client,\n",
        ")\n",
        "\n",
        "print(\"\u2705 Magentic agents defined: ResearcherAgent, AnalystAgent, ResearchManager\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "879ddaa3",
      "metadata": {},
      "source": [
        "## Build & Run Magentic Workflow\n",
        "\n",
        "The manager dynamically plans and delegates. Watch how it calls different agents based on the evolving task."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "919845da",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Build Magentic workflow\n",
        "magentic_research_workflow = (\n",
        "    MagenticBuilder()\n",
        "    .participants([researcher_agent, analyst_agent])\n",
        "    .with_manager(\n",
        "        agent=manager_agent,\n",
        "        max_round_count=10,  # Maximum delegation rounds\n",
        "        max_stall_count=2,   # Replan after 2 stalls\n",
        "    )\n",
        "    .build()\n",
        ")\n",
        "\n",
        "# Research task - InboxOps Weekly Support Intelligence Report\n",
        "research_task = \"\"\"\n",
        "InboxOps wants an internal weekly support intelligence report:\n",
        "1. Identify top 5 complaint categories from incoming emails\n",
        "2. Estimate urgency and business impact for each category\n",
        "3. Calculate resolution time trends and escalation rates\n",
        "4. Suggest operational improvements\n",
        "5. Output a clean summary table + executive summary\n",
        "\"\"\"\n",
        "\n",
        "async def run_magentic_research():\n",
        "    print(\"\ud83d\udd2c INBOXOPS SUPPORT INTELLIGENCE WORKFLOW\")\n",
        "    print(\"=\" * 60)\n",
        "    print(f\"\ud83d\udccb TASK:\\n{research_task}\")\n",
        "    print(\"=\" * 60)\n",
        "    \n",
        "    last_message_id: str | None = None\n",
        "    agent_calls: dict[str, int] = {}\n",
        "    \n",
        "    async for event in magentic_research_workflow.run_stream(research_task):\n",
        "        # Track streaming from agents\n",
        "        if isinstance(event, AgentRunUpdateEvent):\n",
        "            message_id = event.data.message_id\n",
        "            executor_id = event.executor_id\n",
        "            \n",
        "            if message_id != last_message_id:\n",
        "                if last_message_id is not None:\n",
        "                    print(\"\\n\")\n",
        "                agent_calls[executor_id] = agent_calls.get(executor_id, 0) + 1\n",
        "                print(f\"\\n\ud83e\udd16 [{executor_id}] (Call #{agent_calls[executor_id]}):\", end=\" \", flush=True)\n",
        "                last_message_id = message_id\n",
        "            \n",
        "            print(event.data, end=\"\", flush=True)\n",
        "        \n",
        "        # Track orchestration events\n",
        "        elif isinstance(event, MagenticOrchestratorEvent):\n",
        "            print(f\"\\n\\n{'='*55}\")\n",
        "            print(f\"\ud83d\udccb ORCHESTRATOR: {event.event_type.name}\")\n",
        "            print(f\"{'='*55}\")\n",
        "            \n",
        "            if isinstance(event.data, MagenticProgressLedger):\n",
        "                ledger = event.data.to_dict()\n",
        "                if \"next_speaker\" in ledger:\n",
        "                    next_info = ledger.get('next_speaker', {})\n",
        "                    if isinstance(next_info, dict):\n",
        "                        print(f\"   \u27a1\ufe0f Next: {next_info.get('answer', 'N/A')}\")\n",
        "                        reason = next_info.get('reason', '')\n",
        "                        if reason:\n",
        "                            print(f\"   \ud83d\udcad Why: {reason[:100]}...\")\n",
        "                    else:\n",
        "                        print(f\"   \u27a1\ufe0f Next: {next_info}\")\n",
        "        \n",
        "        # Final output\n",
        "        elif isinstance(event, WorkflowOutputEvent):\n",
        "            output_messages = cast(list[ChatMessage], event.data)\n",
        "            \n",
        "            print(\"\\n\\n\" + \"=\" * 60)\n",
        "            print(\"\ud83d\udcca EXECUTION SUMMARY\")\n",
        "            print(\"=\" * 60)\n",
        "            print(f\"   Total agent calls: {sum(agent_calls.values())}\")\n",
        "            print(\"\\n   Calls per agent:\")\n",
        "            for agent, count in sorted(agent_calls.items()):\n",
        "                print(f\"      {agent}: {count} call(s)\")\n",
        "            \n",
        "            print(\"\\n   \u2728 Manager dynamically orchestrated:\")\n",
        "            print(f\"      - Broke down complex task into subtasks\")\n",
        "            print(f\"      - Called ResearcherAgent for data gathering\")\n",
        "            print(f\"      - Called AnalystAgent for processing\")\n",
        "            print(f\"      - Synthesized into final report\")\n",
        "            \n",
        "            print(\"\\n\" + \"=\" * 60)\n",
        "            print(\"\ud83d\udcd1 FINAL INBOXOPS INTELLIGENCE REPORT\")\n",
        "            print(\"=\" * 60)\n",
        "            for msg in reversed(output_messages):\n",
        "                if msg.role.value == \"assistant\":\n",
        "                    print(msg.text)\n",
        "                    break\n",
        "\n",
        "await run_magentic_research()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "86c54928",
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "eb8353be",
      "metadata": {},
      "source": [
        "# 13. V4 \u2014 Evaluation & Testing (InboxOps Quality Metrics)\n",
        "\n",
        "## The Problem: How Do We Know the Agent Works Well?\n",
        "\n",
        "After deploying the InboxOps Support Email Copilot, stakeholders ask:\n",
        "\n",
        "- \ud83d\udcca **What's our response accuracy rate?**\n",
        "- \u23f1\ufe0f **How fast are we resolving tickets?**\n",
        "- \ud83d\ude0a **Are customers satisfied?**\n",
        "- \ud83d\udcb0 **What's the ROI vs. human agents?**\n",
        "\n",
        "**\"Deploy and hope\" is not a strategy.**\n",
        "\n",
        "## Solution: Agent Evaluation Framework\n",
        "\n",
        "Systematically measure agent performance:\n",
        "\n",
        "```python\n",
        "# Evaluation metrics\n",
        "metrics = {\n",
        "    \"accuracy\": measure_correct_responses(),\n",
        "    \"response_time\": measure_avg_latency(),\n",
        "    \"customer_satisfaction\": measure_csat_score(),\n",
        "    \"cost_per_ticket\": calculate_cost(),\n",
        "    \"human_escalation_rate\": measure_escalations()\n",
        "}\n",
        "\n",
        "# Automated testing\n",
        "for test_case in test_dataset:\n",
        "    prediction = agent.run(test_case.input)\n",
        "    score = evaluate(prediction, test_case.expected_output)\n",
        "    results.append(score)\n",
        "```\n",
        "\n",
        "Let's build a comprehensive evaluation system for InboxOps.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6cc438dd",
      "metadata": {},
      "outputs": [],
      "source": [
        "from typing import List, Dict, Any\n",
        "from dataclasses import dataclass\n",
        "import time\n",
        "from datetime import datetime\n",
        "\n",
        "# Define test cases for InboxOps agents\n",
        "@dataclass\n",
        "class TestCase:\n",
        "    \"\"\"Test case for agent evaluation\"\"\"\n",
        "    id: str\n",
        "    input: str\n",
        "    expected_output: Dict[str, Any]\n",
        "    category: str\n",
        "\n",
        "# Create test dataset\n",
        "test_cases = [\n",
        "    TestCase(\n",
        "        id=\"TEST-001\",\n",
        "        input=\"Where is my order #12345? It's been 3 weeks!\",\n",
        "        expected_output={\n",
        "            \"category\": \"order_status\",\n",
        "            \"priority\": \"high\",\n",
        "            \"sentiment\": \"negative\",\n",
        "            \"requires_tool\": True,\n",
        "            \"tool_name\": \"get_order_status\"\n",
        "        },\n",
        "        category=\"order_inquiry\"\n",
        "    ),\n",
        "    TestCase(\n",
        "        id=\"TEST-002\",\n",
        "        input=\"Thank you for the quick refund! Great service!\",\n",
        "        expected_output={\n",
        "            \"category\": \"feedback\",\n",
        "            \"priority\": \"low\",\n",
        "            \"sentiment\": \"positive\",\n",
        "            \"requires_tool\": False\n",
        "        },\n",
        "        category=\"positive_feedback\"\n",
        "    ),\n",
        "    TestCase(\n",
        "        id=\"TEST-003\",\n",
        "        input=\"I need to cancel ticket TKT-789 immediately.\",\n",
        "        expected_output={\n",
        "            \"category\": \"ticket_management\",\n",
        "            \"priority\": \"urgent\",\n",
        "            \"sentiment\": \"neutral\",\n",
        "            \"requires_tool\": True,\n",
        "            \"tool_name\": \"cancel_ticket\"\n",
        "        },\n",
        "        category=\"urgent_request\"\n",
        "    ),\n",
        "]\n",
        "\n",
        "# Evaluation metrics\n",
        "class AgentEvaluator:\n",
        "    def __init__(self):\n",
        "        self.results = []\n",
        "    \n",
        "    def evaluate_response_accuracy(self, prediction: str, expected: Dict) -> float:\n",
        "        \"\"\"Evaluate if response addresses the correct category\"\"\"\n",
        "        # Simplified accuracy check (in production, use more sophisticated NLP)\n",
        "        score = 0.0\n",
        "        \n",
        "        # Check category keywords\n",
        "        category_keywords = {\n",
        "            \"order_status\": [\"order\", \"shipment\", \"tracking\", \"delivery\"],\n",
        "            \"feedback\": [\"thank\", \"appreciate\", \"great\"],\n",
        "            \"ticket_management\": [\"ticket\", \"cancel\", \"close\"],\n",
        "        }\n",
        "        \n",
        "        expected_category = expected.get(\"category\", \"\")\n",
        "        keywords = category_keywords.get(expected_category, [])\n",
        "        \n",
        "        if any(keyword in prediction.lower() for keyword in keywords):\n",
        "            score += 0.5\n",
        "        \n",
        "        # Check sentiment alignment\n",
        "        sentiment = expected.get(\"sentiment\", \"\")\n",
        "        if sentiment == \"positive\" and any(word in prediction.lower() for word in [\"glad\", \"happy\", \"great\"]):\n",
        "            score += 0.25\n",
        "        elif sentiment == \"negative\" and any(word in prediction.lower() for word in [\"sorry\", \"apologize\", \"unfortunately\"]):\n",
        "            score += 0.25\n",
        "        \n",
        "        # Check priority handling\n",
        "        priority = expected.get(\"priority\", \"\")\n",
        "        if priority == \"urgent\" and any(word in prediction.lower() for word in [\"immediately\", \"right away\", \"asap\"]):\n",
        "            score += 0.25\n",
        "        \n",
        "        return min(score, 1.0)\n",
        "    \n",
        "    def evaluate_response_time(self, latency_ms: float) -> Dict[str, Any]:\n",
        "        \"\"\"Evaluate response time performance\"\"\"\n",
        "        # SLA targets for InboxOps\n",
        "        if latency_ms < 1000:\n",
        "            grade = \"excellent\"\n",
        "            score = 1.0\n",
        "        elif latency_ms < 3000:\n",
        "            grade = \"good\"\n",
        "            score = 0.8\n",
        "        elif latency_ms < 5000:\n",
        "            grade = \"acceptable\"\n",
        "            score = 0.6\n",
        "        else:\n",
        "            grade = \"poor\"\n",
        "            score = 0.3\n",
        "        \n",
        "        return {\n",
        "            \"latency_ms\": latency_ms,\n",
        "            \"grade\": grade,\n",
        "            \"score\": score,\n",
        "            \"meets_sla\": latency_ms < 5000\n",
        "        }\n",
        "    \n",
        "    def run_evaluation(self, agent: ChatAgent, test_cases: List[TestCase]) -> Dict[str, Any]:\n",
        "        \"\"\"Run comprehensive evaluation on test dataset\"\"\"\n",
        "        results = []\n",
        "        total_latency = 0\n",
        "        \n",
        "        print(\"\ud83e\uddea RUNNING AGENT EVALUATION\")\n",
        "        print(\"=\"*60)\n",
        "        \n",
        "        for test_case in test_cases:\n",
        "            print(f\"\\n\ud83d\udcdd Test Case: {test_case.id}\")\n",
        "            print(f\"   Input: {test_case.input[:60]}...\")\n",
        "            \n",
        "            # Measure response time\n",
        "            start_time = time.time()\n",
        "            response = agent.run(messages=[{\"role\": \"user\", \"content\": test_case.input}])\n",
        "            latency_ms = (time.time() - start_time) * 1000\n",
        "            \n",
        "            # Evaluate accuracy\n",
        "            accuracy_score = self.evaluate_response_accuracy(\n",
        "                response.output,\n",
        "                test_case.expected_output\n",
        "            )\n",
        "            \n",
        "            # Evaluate response time\n",
        "            timing_result = self.evaluate_response_time(latency_ms)\n",
        "            \n",
        "            result = {\n",
        "                \"test_id\": test_case.id,\n",
        "                \"category\": test_case.category,\n",
        "                \"accuracy_score\": accuracy_score,\n",
        "                \"latency_ms\": latency_ms,\n",
        "                \"timing_grade\": timing_result[\"grade\"],\n",
        "                \"meets_sla\": timing_result[\"meets_sla\"],\n",
        "                \"response_preview\": response.output[:100] + \"...\" if len(response.output) > 100 else response.output\n",
        "            }\n",
        "            \n",
        "            results.append(result)\n",
        "            print(f\"   \u2705 Accuracy: {accuracy_score:.2f}\")\n",
        "            print(f\"   \u23f1\ufe0f  Latency: {latency_ms:.0f}ms ({timing_result['grade']})\")\n",
        "        \n",
        "        # Calculate aggregate metrics\n",
        "        avg_accuracy = sum(r[\"accuracy_score\"] for r in results) / len(results)\n",
        "        avg_latency = sum(r[\"latency_ms\"] for r in results) / len(results)\n",
        "        sla_compliance = sum(1 for r in results if r[\"meets_sla\"]) / len(results) * 100\n",
        "        \n",
        "        summary = {\n",
        "            \"total_tests\": len(results),\n",
        "            \"avg_accuracy\": avg_accuracy,\n",
        "            \"avg_latency_ms\": avg_latency,\n",
        "            \"sla_compliance_rate\": sla_compliance,\n",
        "            \"timestamp\": datetime.now().isoformat(),\n",
        "            \"detailed_results\": results\n",
        "        }\n",
        "        \n",
        "        return summary\n",
        "\n",
        "# Create evaluator\n",
        "evaluator = AgentEvaluator()\n",
        "\n",
        "# Run evaluation on our support agent\n",
        "evaluation_results = evaluator.run_evaluation(support_agent_with_tools, test_cases)\n",
        "\n",
        "# Display results\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"\ud83d\udcca EVALUATION SUMMARY\")\n",
        "print(\"=\"*60)\n",
        "print(f\"Total Test Cases:      {evaluation_results['total_tests']}\")\n",
        "print(f\"Average Accuracy:      {evaluation_results['avg_accuracy']:.2%}\")\n",
        "print(f\"Average Latency:       {evaluation_results['avg_latency_ms']:.0f}ms\")\n",
        "print(f\"SLA Compliance:        {evaluation_results['sla_compliance_rate']:.1f}%\")\n",
        "print(f\"Timestamp:             {evaluation_results['timestamp']}\")\n",
        "\n",
        "print(\"\\n\ud83d\udcc8 DETAILED RESULTS\")\n",
        "print(\"-\"*60)\n",
        "for result in evaluation_results['detailed_results']:\n",
        "    status = \"\u2705\" if result['accuracy_score'] >= 0.7 else \"\u26a0\ufe0f\"\n",
        "    print(f\"{status} {result['test_id']}: Accuracy={result['accuracy_score']:.2f}, Latency={result['latency_ms']:.0f}ms\")\n",
        "\n",
        "# Calculate ROI metrics\n",
        "print(\"\\n\ud83d\udcb0 ROI ANALYSIS\")\n",
        "print(\"-\"*60)\n",
        "human_cost_per_email = 2.50  # $2.50 per email with human agent\n",
        "ai_cost_per_email = 0.02     # $0.02 per email with AI agent\n",
        "monthly_volume = 50000       # 50K emails/month\n",
        "\n",
        "monthly_human_cost = monthly_volume * human_cost_per_email\n",
        "monthly_ai_cost = monthly_volume * ai_cost_per_email\n",
        "monthly_savings = monthly_human_cost - monthly_ai_cost\n",
        "annual_savings = monthly_savings * 12\n",
        "\n",
        "print(f\"Monthly Email Volume:   {monthly_volume:,}\")\n",
        "print(f\"Human Agent Cost:       ${monthly_human_cost:,.2f}/month\")\n",
        "print(f\"AI Agent Cost:          ${monthly_ai_cost:,.2f}/month\")\n",
        "print(f\"Monthly Savings:        ${monthly_savings:,.2f}\")\n",
        "print(f\"Annual Savings:         ${annual_savings:,.2f}\")\n",
        "print(f\"Cost Reduction:         {(1 - ai_cost_per_email/human_cost_per_email)*100:.1f}%\")\n",
        "\n",
        "print(\"\\n\u2705 Evaluation complete! Use these metrics to:\")\n",
        "print(\"   \u2022 Track agent performance over time\")\n",
        "print(\"   \u2022 Identify areas for improvement\")\n",
        "print(\"   \u2022 Justify ROI to stakeholders\")\n",
        "print(\"   \u2022 Set SLAs and quality benchmarks\")\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.18"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}